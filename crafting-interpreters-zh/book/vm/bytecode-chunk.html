<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4717236929129160"
     crossorigin="anonymous"></script>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>å­—èŠ‚ç å— - crafting-interpreters-zh</title>


        <!-- Custom HTML head -->
	<script src="https://static.guance.com/browser-sdk/v2/dataflux-rum.js" type="text/javascript"></script>
	<script>
	window.DATAFLUX_RUM &&
	window.DATAFLUX_RUM.init({
	applicationId: 'thewind_blog',
	datakitOrigin: 'https://www.poetries.cn/rum', 
	env: 'production',
	version: '1.0.0',
	trackInteractions: true,
	traceType: 'ddtrace',
	allowedTracingOrigins: [/https:\/\/.*\.poetries\.cn/, "https://poetries.cn"], 
	})
	</script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MMN1K84KRS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-MMN1K84KRS');
</script>


        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item affix "><a href="../index.html">å‰è¨€</a></li><li class="spacer"></li><li class="chapter-item affix "><li class="part-title">æ¬¢è¿</li><li class="chapter-item "><a href="../welcome/welcome.html"><strong aria-hidden="true">1.</strong> æ¬¢è¿</a></li><li class="chapter-item "><a href="../welcome/introduction.html"><strong aria-hidden="true">2.</strong> ä»‹ç»</a></li><li class="chapter-item "><a href="../welcome/a-map-of-the-territory.html"><strong aria-hidden="true">3.</strong> æ€»è§ˆå›¾</a></li><li class="chapter-item "><a href="../welcome/the-lox-language.html"><strong aria-hidden="true">4.</strong> Loxè¯­è¨€</a></li><li class="chapter-item affix "><li class="part-title">è§£ææ ‘</li><li class="chapter-item "><a href="../tree/tree.html"><strong aria-hidden="true">5.</strong> è§£ææ ‘</a></li><li class="chapter-item "><a href="../tree/scanning.html"><strong aria-hidden="true">6.</strong> æ‰«æ</a></li><li class="chapter-item "><a href="../tree/representing-code.html"><strong aria-hidden="true">7.</strong> ä»£ç è¡¨ç¤º</a></li><li class="chapter-item "><a href="../tree/parsing-expression.html"><strong aria-hidden="true">8.</strong> è§£æè¡¨è¾¾å¼</a></li><li class="chapter-item "><a href="../tree/evaluating-expression.html"><strong aria-hidden="true">9.</strong> è®¡ç®—è¡¨è¾¾å¼</a></li><li class="chapter-item "><a href="../tree/statements-and-state.html"><strong aria-hidden="true">10.</strong> è¯­å¥å’ŒçŠ¶æ€</a></li><li class="chapter-item "><a href="../tree/control-flow.html"><strong aria-hidden="true">11.</strong> æ§åˆ¶æµç¨‹</a></li><li class="chapter-item "><a href="../tree/functions.html"><strong aria-hidden="true">12.</strong> å‡½æ•°</a></li><li class="chapter-item "><a href="../tree/resolving-and-binding.html"><strong aria-hidden="true">13.</strong> è§£æä¸ç»‘å®š</a></li><li class="chapter-item "><a href="../tree/classes.html"><strong aria-hidden="true">14.</strong> ç±»</a></li><li class="chapter-item "><a href="../tree/inheritance.html"><strong aria-hidden="true">15.</strong> ç»§æ‰¿</a></li><li class="chapter-item affix "><li class="part-title">è™šæ‹Ÿæœº</li><li class="chapter-item "><a href="../vm/bytecode-vm.html"><strong aria-hidden="true">16.</strong> è™šæ‹Ÿæœº</a></li><li class="chapter-item expanded "><a href="../vm/bytecode-chunk.html" class="active"><strong aria-hidden="true">17.</strong> å­—èŠ‚ç å—</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">crafting-interpreters-zh</h1>

                    <div class="right-buttons">
                        <a href="https://github.com/Kua-Fu/blog-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>


                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="å­—èŠ‚ç å—"><a class="header" href="#å­—èŠ‚ç å—">å­—èŠ‚ç å—</a></h1>
<blockquote>
<p>If you find that youâ€™re spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that youâ€™re spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice.</p>
<p>å¦‚ä½•ä½ å‘ç°è‡ªå·±ç»å¤§éƒ¨åˆ†æ—¶é—´ï¼Œéƒ½èŠ±åœ¨ç†è®ºä¸Šï¼Œé‚£ä¹ˆå¼€å§‹æŠŠä¸€äº›æ³¨æ„åŠ›æ”¾åœ¨å®è·µä¸Šï¼Œè¿™å°†æœ‰åŠ©äºæé«˜ä½ çš„ç†è®ºæ°´å¹³ï¼›</p>
<p>å¦‚æœä½ å‘ç°è‡ªå·±å‡ ä¹æŠŠæ‰€æœ‰æ—¶é—´éƒ½ç”¨åœ¨å®è·µä¸­ï¼Œé‚£å°±å¼€å§‹å…³æ³¨ä¸€äº›ç†è®ºæ€§çš„ä¸œè¥¿ï¼Œè¿™ä¼šæé«˜ä½ çš„å®è·µèƒ½åŠ›ã€‚</p>
</blockquote>
<blockquote>
<p align=right> â€”â€” Donald Knuth </p>
</blockquote>
<p>We already have ourselves a complete implementation of Lox with jlox, so why isnâ€™t the book over yet? Part of this is because jlox relies on the JVM to do lots of things for us. If we want to understand how an interpreter works all the way down to the metal, we need to build those bits and pieces ourselves.</p>
<p>æˆ‘ä»¬å·²ç»ä½¿ç”¨jlox å®ç°äº†å®Œæ•´çš„loxï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆæœ¬ä¹¦è¿˜æ²¡æœ‰ç»“æŸå‘¢ï¼Ÿéƒ¨åˆ†åŸå› æ˜¯å› ä¸ºjloxä¾èµ–äº JVMæ¥å®Œæˆå¾ˆå¤šå·¥ä½œï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å®Œå…¨ç†è§£è§£é‡Šå™¨çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå·±æ„å»ºè¿™äº›éƒ¨åˆ†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦ä»åº•å±‚å¼€å§‹ä¸€æ­¥æ­¥æ„å»ºè§£é‡Šå™¨ï¼Œä»¥æ·±å…¥äº†è§£å…¶å·¥ä½œåŸç†ã€‚</p>
<blockquote>
<p>Of course, our second interpreter relies on the C standard library for basics like memory allocation, and the C compiler frees us from details of the underlying machine code weâ€™re running it on. Heck, that machine code is probably implemented in terms of microcode on the chip. And the C runtime relies on the operating system to hand out pages of memory. But we have to stop somewhere if this book is going to fit on your bookshelf.</p>
<p>å½“ç„¶ï¼Œæˆ‘ä»¬çš„ç¬¬äºŒä¸ªè§£é‡Šå™¨ä½¿ç”¨C æ ‡å‡†åº“æ¥è¿›è¡ŒåŸºæœ¬çš„å†…å­˜åˆ†é…æ“ä½œï¼Œè€ŒCç¼–è¯‘å™¨åˆ™ä¸ºæˆ‘ä»¬é¿å…äº†è¿è¡Œæœºå™¨ç æ—¶å€™çš„å†…éƒ¨æ‰§è¡Œç»†èŠ‚ï¼Œå®é™…ä¸Šï¼Œè¿™äº›æœºå™¨ç å¯èƒ½æ˜¯åŸºäºèŠ¯ç‰‡ä¸Šçš„å¾®ç å®ç°ï¼Œè€ŒC è¿è¡Œæ—¶å€™ï¼Œä¾èµ–äºæ“ä½œç³»ç»Ÿæ¥åˆ†é…å†…å­˜é¡µã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›è¿™æœ¬ä¹¦é€‚åˆæ”¾å…¥ä½ çš„ä¹¦æ¶ï¼Œå¿…é¡»åœ¨æŸäº›åœ°æ–¹åœä¸‹æ¥ã€‚</p>
</blockquote>
<p>An even more fundamental reason that jlox isnâ€™t sufficient is that itâ€™s too damn slow. A tree-walk interpreter is fine for some kinds of high-level, declarative languages. But for a general-purpose, imperative languageâ€”even a â€œscriptingâ€ language like Loxâ€”it wonâ€™t fly. Take this little script:</p>
<p>è¿˜æœ‰ä¸€ä¸ªæ›´åŠ å®é™…çš„åŸå› ï¼Œæ˜¯jlox æ‰§è¡Œå¤ªæ…¢äº†ã€‚å¯¹äºæŸäº›é«˜çº§ã€å£°æ˜å¼çš„è¯­è¨€ï¼ŒåŸºäºè¯­æ³•æ ‘éå†çš„è§£é‡Šå™¨æ˜¯å¯ä»¥æ¥å—çš„ã€‚ä½†æ˜¯ï¼Œå¯¹äºé€šç”¨çš„ã€å‘½ä»¤å¼è¯­è¨€â€”â€”ä¾‹å¦‚ï¼šloxï¼Œè¿™ç§æ–¹å¼å®ç°çš„è§£é‡Šå™¨ï¼Œå°±ä¸å¤Ÿç”¨äº†ï¼Œæ‰§è¡Œä¸‹é¢çš„è¿™ä¸ªç¨‹åº</p>
<pre><code class="language-python">

fun fib(n) {
  if (n &lt; 2) return n;
  return fib(n - 1) + fib(n - 2); 
}

var before = clock();
print fib(40);
var after = clock();
print after - before;

</code></pre>
<p>On my laptop, that takes jlox about 72 seconds to execute. An equivalent C program finishes in half a second. Our dynamically typed scripting language is never going to be as fast as a statically typed language with manual memory management, but we donâ€™t need to settle for more than two orders of magnitude slower.</p>
<p>We could take jlox and run it in a profiler and start tuning and tweaking hotspots, but that will only get us so far. The execution modelâ€”walking the ASTâ€”is fundamentally the wrong design. We canâ€™t micro-optimize that to the performance we want any more than you can polish an AMC Gremlin into an SR-71 Blackbird.</p>
<p>We need to rethink the core model. This chapter introduces that model, bytecode, and begins our new interpreter, clox.</p>
<p>åœ¨æˆ‘çš„ç¬”è®°æœ¬ä¸Šï¼Œæ‰§è¡Œä¸Šé¢çš„lox ç¨‹åºè€—æ—¶ 72ç§’ï¼Œè€Œä¸€ä¸ªç­‰æ•ˆçš„C ç¨‹åºåªéœ€è¦åŠç§’é’Ÿå°±å¯ä»¥æ‰§è¡ŒåŒæ ·åŠŸèƒ½ã€‚æˆ‘ä»¬çš„åŠ¨æ€ç±»å‹è„šæœ¬è¯­è¨€ï¼Œå¯èƒ½æ°¸è¿œæ— æ³•åƒå¯ä»¥è‡ªå·±ç®¡ç†å†…å­˜çš„é™æ€ç±»å‹è¯­è¨€é‚£æ ·é«˜æ•ˆï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿä¸æ¥å—ä¸¤ä¸ªæ•°é‡çº§çš„å·®è·ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åˆ†æå™¨åˆ†æloxç¨‹åºï¼Œæ‰¾åˆ°ã€è°ƒæ•´çƒ­ç‚¹ä»£ç ï¼Œä½†æ˜¯ï¼Œè¿™åªèƒ½å¾ˆæœ‰é™çš„æé«˜æ€§èƒ½ã€‚jloxçš„æ‰§è¡Œæ¨¡å‹â€”â€”éå†ASTï¼Œå¯¹æˆ‘ä»¬æ¥è¯´ï¼Œæ˜¯ä¸€ä¸ªé”™è¯¯çš„è®¾è®¡æ–¹å‘ï¼Œæˆ‘ä»¬æ— æ³•é€šè¿‡å¾®è§‚ä¼˜åŒ–æ¥è¾¾åˆ°æˆ‘ä»¬æƒ³è¦çš„æ€§èƒ½ï¼Œå°±åƒæˆ‘ä»¬æ— æ³•æŠŠ AMC Gremlin ï¼ˆæ±½è½¦ï¼‰å˜æˆé«˜æ€§èƒ½çš„ SR-71ï¼ˆé£æœº)</p>
<p>æˆ‘ä»¬éœ€è¦é‡æ–°æ€è€ƒæ ¸å¿ƒæ¨¡å‹ï¼Œæœ¬ç« ä»‹ç»äº†è¿™ä¸ªæ¨¡å‹â€”â€”å­—èŠ‚ç ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ–°çš„è§£é‡Šå™¨ clox</p>
<h2 id="ä¸€bytecode"><a class="header" href="#ä¸€bytecode">ä¸€ã€Bytecode?</a></h2>
<p>In engineering, few choices are without trade-offs. To best understand why weâ€™re going with bytecode, letâ€™s stack it up against a couple of alternatives.</p>
<p>åœ¨å·¥ç¨‹é¢†åŸŸï¼Œå¾ˆå°‘æœ‰é€‰æ‹©ï¼Œå¯ä»¥ä¸ç»è¿‡æƒè¡¡ï¼Œä¸ºäº†æ›´å¥½çš„ç†è§£æˆ‘ä»¬ä¸ºä»€ä¹ˆé€‰æ‹©å­—èŠ‚ç ï¼Œè®©æˆ‘ä»¬æŠŠå®ƒå’Œä¸€äº›æ›¿ä»£æ–¹æ¡ˆè¿›è¡Œæ¯”è¾ƒã€‚</p>
<h3 id="11-why-not-walk-the-ast"><a class="header" href="#11-why-not-walk-the-ast">1.1 Why not walk the AST?</a></h3>
<p>Our existing interpreter has a couple of things going for it:</p>
<ul>
<li>
<p>Well, first, we already wrote it. Itâ€™s done. And the main reason itâ€™s done is because this style of interpreter is really simple to implement. The runtime representation of the code directly maps to the syntax. Itâ€™s virtually effortless to get from the parser to the data structures we need at runtime.</p>
</li>
<li>
<p>Itâ€™s portable. Our current interpreter is written in Java and runs on any platform Java supports. We could write a new implementation in C using the same approach and compile and run our language on basically every platform under the sun.</p>
</li>
</ul>
<p>æˆ‘ä»¬ç°æœ‰çš„è§£é‡Šå™¨æœ‰ä¸€äº›ä¼˜ç‚¹ï¼š</p>
<ul>
<li>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬ç¼–å†™äº†å®ƒï¼Œå®ƒå·²ç»èƒ½ä½¿ç”¨äº†ã€‚è¿™ä¸ªè§£é‡Šå™¨ä¹‹æ‰€ä»¥èƒ½å®Œæˆï¼Œä¸»è¦æ˜¯å› ä¸ºè¿™ç§è§£é‡Šå™¨çš„å®ç°éå¸¸ç®€å•ã€‚ä»£ç çš„è¿è¡Œæ—¶è¡¨ç¤ºç›´æ¥æ˜ å°„åˆ°è¯­æ³•ï¼Œä»è§£é‡Šå™¨åˆ°æˆ‘ä»¬åœ¨è¿è¡Œæ—¶æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼Œå‡ ä¹æ²¡æœ‰ä»€ä¹ˆéš¾åº¦ã€‚</p>
</li>
<li>
<p>å®ƒæ˜¯å¯ç§»æ¤çš„ï¼Œæˆ‘ä»¬å½“å‰çš„è§£é‡Šå™¨æ˜¯ç”¨Javaç¼–å†™çš„ï¼Œå¯ä»¥åœ¨Javaæ”¯æŒçš„ä»»ä½•å¹³å°ä¸Šè¿è¡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ–¹æ³•åœ¨Cä¸­ç¼–å†™ä¸€ä¸ªæ–°çš„å®ç°ï¼Œå¹¶ä¸”åœ¨å‡ ä¹æ‰€æœ‰å¹³å°ä¸Šç¼–è¯‘å’Œè¿è¡Œæˆ‘ä»¬çš„è¯­è¨€ã€‚</p>
</li>
</ul>
<p>Those are real advantages. But, on the other hand, itâ€™s not memory-efficient. Each piece of syntax becomes an AST node. A tiny Lox expression like 1 + 2 turns into a slew of objects with lots of pointers between them, something like:</p>
<p>è¿™äº›çš„ç¡®æ˜¯çœŸæ­£çš„ä¼˜ç‚¹ï¼Œä½†æ˜¯ï¼Œå¦ä¸€æ–¹é¢ï¼Œå®ƒå¹¶ä¸æ˜¯å†…å­˜æ•ˆç‡é«˜çš„å®ç°æ–¹å¼ï¼Œæ¯ä¸ªè¯­æ³•ç‰‡æ®µéƒ½å˜æˆäº†ä¸€ä¸ªAST èŠ‚ç‚¹ï¼Œä¸€ä¸ªå°å°çš„Loxè¡¨è¾¾å¼ï¼Œä¾‹å¦‚: 1+2 å°±ä¼šå˜ä¸ºä¸€å †å¯¹è±¡ï¼Œå®ƒä»¬ä¹‹é—´æœ‰å¾ˆå¤šæŒ‡é’ˆï¼Œå¤§æ¦‚æ˜¯è¿™æ ·çš„ï¼Œ</p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/ast1.png?raw=true" alt="ast" /></p>
<blockquote>
<p>The â€œ(header)â€ parts are the bookkeeping information the Java virtual machine uses to support memory management and store the objectâ€™s type. Those take up space too!</p>
<p>header éƒ¨åˆ†æ˜¯Java è™šæ‹Ÿæœºç”¨äºæ”¯æŒå†…å­˜ç®¡ç†å’Œå­˜å‚¨å¯¹è±¡ç±»å‹çš„è®°å½•ä¿¡æ¯ï¼Œè¿™äº›ä¹Ÿä¼šå ç”¨ç©ºé—´ï¼</p>
</blockquote>
<p>Each of those pointers adds an extra 32 or 64 bits of overhead to the object. Worse, sprinkling our data across the heap in a loosely connected web of objects does bad things for spatial locality.</p>
<p>æ¯ä¸ªæŒ‡é’ˆéƒ½ä¼šç»™å¯¹è±¡å¢åŠ é¢å¤–çš„32ä½ æˆ–è€… 64ä½çš„å¼€é”€ï¼Œæ›´ç³Ÿç³•çš„æ˜¯ï¼Œå°†æˆ‘ä»¬çš„æ•°æ®æ•£å¸ƒåˆ°å †ä¸­ï¼Œå½¢æˆæ¾æ•£é“¾æ¥çš„å¯¹è±¡ç½‘ç»œï¼Œå¯¹ç©ºé—´å±€éƒ¨æ€§äº§ç”Ÿä¸è‰¯å½±å“ã€‚</p>
<blockquote>
<p>I wrote an entire chapter about this exact problem in my first book, Game Programming Patterns, if you want to really dig in.</p>
<p>å¦‚æœä½ æƒ³è¦æ·±å…¥äº†è§£è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥åœ¨æˆ‘å†™çš„ç¬¬ä¸€æœ¬ä¹¦ã€Šæ¸¸æˆç¼–ç¨‹æ¨¡å¼ã€‹ä¸­å‘ç°æ›´å¤šçš„è§£é‡Šã€‚</p>
</blockquote>
<p>Modern CPUs process data way faster than they can pull it from RAM. To compensate for that, chips have multiple layers of caching. If a piece of memory it needs is already in the cache, it can be loaded more quickly. Weâ€™re talking upwards of 100 times faster.</p>
<p>How does data get into that cache? The machine speculatively stuffs things in there for you. Its heuristic is pretty simple. Whenever the CPU reads a bit of data from RAM, it pulls in a whole little bundle of adjacent bytes and stuffs them in the cache.</p>
<p>If our program next requests some data close enough to be inside that cache line, our CPU runs like a well-oiled conveyor belt in a factory. We really want to take advantage of this. To use the cache effectively, the way we represent code in memory should be dense and ordered like itâ€™s read.</p>
<p>Now look up at that tree. Those sub-objects could be anywhere. Every step the tree-walker takes where it follows a reference to a child node may step outside the bounds of the cache and force the CPU to stall until a new lump of data can be slurped in from RAM. Just the overhead of those tree nodes with all of their pointer fields and object headers tends to push objects away from each other and out of the cache.</p>
<p>Our AST walker has other overhead too around interface dispatch and the Visitor pattern, but the locality issues alone are enough to justify a better code representation.</p>
<p>ç°ä»£CPU å¤„ç†æ•°æ®çš„é€Ÿåº¦ï¼Œè¿œå¿«äºä»RAM ä¸­è¯»å–æ•°æ®çš„é€Ÿåº¦ï¼Œä¸ºäº†å¼¥è¡¥è¿™ä¸€ç‚¹ï¼ŒèŠ¯ç‰‡ä¸­æœ‰å¤šçº§ç¼“å­˜ï¼Œå¦‚æœå®ƒéœ€è¦çš„ä¸€å—å†…å­˜å·²ç»å­˜åœ¨äºå¤šçº§ç¼“å­˜ä¸­ï¼Œé‚£ä¹ˆå®ƒå¯ä»¥æ›´å¿«çš„åŠ è½½æ•°æ®ï¼Œè¿™ä¸ªé€Ÿåº¦å¯ä»¥å¿«äº†100å€ã€‚</p>
<p>æ•°æ®æ˜¯å¦‚ä½•è¿›å…¥ç¼“å­˜ä¸­çš„å‘¢ï¼Ÿæœºå™¨ä¼šè‡ªåŠ¨å°†æ•°æ®æ”¾å…¥ç¼“å­˜ï¼Œå®ƒçš„ç®—æ³•éå¸¸ç®€å•ï¼Œæ¯å½“CPU è¯»å–RAMçš„ä¸€äº›æ•°æ®æ—¶å€™ï¼Œå®ƒä¼šå°†ç›¸é‚»çš„ä¸€ç»„å­—èŠ‚ä¸€èµ·æ‹‰å…¥åˆ°ç¼“å­˜ä¸­ã€‚</p>
<p>å¦‚æœæˆ‘ä»¬çš„ç¨‹åºæ¥ä¸‹æ¥è¯·æ±‚çš„æ•°æ®æ¥è¿‘ç¼“å­˜è¡Œï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„CPUå°±ä¼šåƒå·¥å‚é‡Œé¢çš„ä¼ é€å¸¦ä¸€æ ·å¹³æ»‘çš„è¿è¡Œã€‚æˆ‘ä»¬çœŸçš„æƒ³è¦åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œä¸ºäº†æœ‰æ•ˆçš„åˆ©ç”¨ç¼“å­˜ï¼Œæˆ‘ä»¬åœ¨å†…å­˜ä¸­è¡¨ç¤ºä»£ç çš„æ–¹å¼åº”è¯¥æ˜¯å¯†é›†æœ‰åºçš„ã€‚</p>
<p>ç°åœ¨çœ‹çœ‹ä¸Šé¢çš„é‚£æ£µæ ‘ï¼Œè¿™äº›å­å¯¹è±¡å¯èƒ½åœ¨ä»»ä½•åœ°æ–¹ï¼Œæ¯ä¸€æ¬¡éå†è¯­æ³•æ ‘æ‰§è¡Œæ“ä½œæ—¶å€™ï¼Œéƒ½æœ‰å¯èƒ½è¶…è¿‡ç¼“å­˜çš„è¾¹ç•Œï¼Œè¿«ä½¿CPUåœé¡¿ï¼Œä¸€ç›´åˆ°å¯ä»¥ä»RAMä¸­è¯»å–æ–°çš„æ•°æ®ã€‚è¿™äº›è¯­æ³•æ ‘èŠ‚ç‚¹çš„å¼€é”€ï¼ŒåŒ…æ‹¬å®ƒä»¬æ‰€æœ‰çš„æŒ‡é’ˆå­—æ®µå’Œå¯¹è±¡å¤´ï¼Œå¾€å¾€ä¼šå°†å¯¹è±¡æ¨è¿œå¹¶å°†å®ƒä»¬ç§»å‡ºç¼“å­˜ã€‚</p>
<p>æˆ‘ä»¬çš„ASTéå†è¿˜æœ‰å…¶ä»–å¼€é”€ï¼Œæ¯”å¦‚: æ¥å£è°ƒç”¨å’Œè®¿é—®è€…æ¨¡å¼ï¼Œä½†æ˜¯ï¼Œä»…ä»…å±€éƒ¨æ€§é—®é¢˜ï¼Œå°±è¶³ä»¥éœ€è¦æˆ‘ä»¬æ›´å¥½çš„ä»£ç è¡¨è¾¾æ–¹å¼ã€‚</p>
<blockquote>
<p>Even if the objects happened to be allocated in sequential memory when the parser first produced them, after a couple of rounds of garbage collectionâ€”which may move objects around in memoryâ€”thereâ€™s no telling where theyâ€™ll be.</p>
<p>å³ä½¿å¯¹è±¡åœ¨è§£é‡Šå™¨ç¬¬ä¸€æ¬¡ç”Ÿæˆæ—¶å€™ï¼Œæ˜¯æŒ‰ç…§é¡ºåºåˆ†é…çš„ï¼Œç»è¿‡å‡ è½®åƒåœ¾å›æ”¶åï¼ˆå¯èƒ½ä¼šç§»åŠ¨å†…å­˜ä¸­çš„å¯¹è±¡ï¼‰ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šå®ƒä¼šè¢«ç§»åŠ¨åˆ°å“ªé‡Œã€‚</p>
</blockquote>
<h3 id="12-why-not-compile-to-native-code"><a class="header" href="#12-why-not-compile-to-native-code">1.2 Why not compile to native code?</a></h3>
<p>If you want to go real fast, you want to get all of those layers of indirection out of the way. Right down to the metal. Machine code. It even sounds fast. Machine code.</p>
<p>Compiling directly to the native instruction set the chip supports is what the fastest languages do. Targeting native code has been the most efficient option since way back in the early days when engineers actually handwrote programs in machine code.</p>
<p>å¦‚æœä½ æƒ³è¦çœŸæ­£å¿«é€Ÿï¼Œä½ éœ€è¦æ‘†è„±æ‰€æœ‰çš„é—´æ¥å±‚çº§ã€‚ç›´æ¥åˆ°æœºå™¨å±‚é¢ï¼Œæœºå™¨ç ã€‚å®ƒç”šè‡³å¬èµ·æ¥å°±å¾ˆå¿« ğŸ˜„</p>
<p>ç›´æ¥ç¼–è¯‘ä¸ºèŠ¯ç‰‡æ”¯æŒçš„æœ¬åœ°æŒ‡ä»¤é›†æ˜¯æœ€å¿«çš„è¯­è¨€æ‰€åšçš„ï¼Œè‡ªä»æ—©æœŸå·¥ç¨‹å¸ˆæ‰‹å†™æœºå™¨ç ä»¥æ¥ï¼Œé’ˆå¯¹æœ¬åœ°ä»£ç ä¸€ç›´æ˜¯æœ€æœ‰æ•ˆçš„é€‰æ‹©ã€‚</p>
<p>If youâ€™ve never written any machine code, or its slightly more human-palatable cousin assembly code before, Iâ€™ll give you the gentlest of introductions. Native code is a dense series of operations, encoded directly in binary. Each instruction is between one and a few bytes long, and is almost mind-numbingly low level. â€œMove a value from this address to this register.â€ â€œAdd the integers in these two registers.â€ Stuff like that.</p>
<p>The CPU cranks through the instructions, decoding and executing each one in order. There is no tree structure like our AST, and control flow is handled by jumping from one point in the code directly to another. No indirection, no overhead, no unnecessary skipping around or chasing pointers.</p>
<p>Lightning fast, but that performance comes at a cost. First of all, compiling to native code ainâ€™t easy. Most chips in wide use today have sprawling Byzantine architectures with heaps of instructions that accreted over decades. They require sophisticated register allocation, pipelining, and instruction scheduling.</p>
<p>And, of course, youâ€™ve thrown portability out. Spend a few years mastering some architecture and that still only gets you onto one of the several popular instruction sets out there. To get your language on all of them, you need to learn all of their instruction sets and write a separate back end for each one.</p>
<p>å¦‚æœä½ ä»¥å‰æ²¡æœ‰å†™è¿‡ä»»ä½•æœºå™¨ç æˆ–è€…ç¨å¾®å®¹æ˜“ç†è§£çš„æ±‡ç¼–ä»£ç ï¼Œæˆ‘ä¼šç»™ä½ ä¸€ä¸ªæœ€æ¸©å’Œçš„ä»‹ç»ï¼Œæœ¬åœ°ä»£ç æ˜¯ä¸€ç³»åˆ—ç›´æ¥ç¼–ç ä¸ºäºŒè¿›åˆ¶çš„æ“ä½œï¼Œæ¯æ¡æŒ‡ä»¤çš„é•¿åº¦æ˜¯1ä¸ªæˆ–è€…å‡ ä¸ªå­—èŠ‚ä¹‹é—´ï¼Œå‡ ä¹è®©äººæ„ŸåŠ¨æ— èŠçš„ä½çº§ã€‚æ¯”å¦‚ï¼šå°†ä¸€ä¸ªå€¼ä»è¿™ä¸ªåœ°å€ç§»åŠ¨åˆ°è¿™ä¸ªå¯„å­˜å™¨ã€‚å°†ä¸¤ä¸ªå¯„å­˜å™¨ä¸­çš„å€¼ç›¸åŠ ï¼Œç±»ä¼¼è¿™æ ·çš„æ“çºµã€‚</p>
<p>CPUè¿è¡Œè¿™äº›æŒ‡ä»¤ï¼ŒæŒ‰ç…§é¡ºåºè§£ç å’Œæ‰§è¡Œå®ƒä»¬ï¼Œæ²¡æœ‰åƒä¹‹å‰æåˆ°çš„è¯­æ³•æ ‘ç»“æ„ï¼Œæ§åˆ¶æµç›´æ¥ä»ä»£ç ä¸­çš„ä¸€ä¸ªç‚¹è·³è½¬åˆ°å¦ä¸€ä¸ªç‚¹æ¥å¤„ç†ã€‚æ²¡æœ‰é—´æ¥å¯»å€ï¼Œæ²¡æœ‰å¼€é”€ï¼Œæ²¡æœ‰ä¸å¿…è¦çš„è·³è·ƒï¼Œæˆ–è€…æŒ‡é’ˆè¿½è¸ªã€‚</p>
<p>è¿è¡Œé€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯è¿™ç§æ€§èƒ½æ˜¯æœ‰ä»£ä»·çš„ã€‚é¦–å…ˆï¼Œç¼–è¯‘ä¸ºæœºå™¨ç å¹¶ä¸å®¹æ˜“ï¼Œä»Šå¤©å¹¿æ³›ä½¿ç”¨çš„å¤§å¤šæ•°èŠ¯ç‰‡ï¼Œéƒ½æœ‰åºå¤§çš„æ‹œå åº­å¼ç»“æ„ï¼Œæœ‰æ•°åå¹´çš„æŒ‡ä»¤é›†ç§¯ç´¯ã€‚å®ƒä»¬éœ€è¦å¤æ‚çš„å¯„å­˜å™¨åˆ†é…ã€æµæ°´çº¿å’ŒæŒ‡ä»¤è°ƒåº¦ã€‚</p>
<p>å½“ç„¶ï¼Œä½ ä¹Ÿæ”¾å¼ƒäº†å¯ç§»æ¤æ€§ã€‚èŠ±è´¹å‡ å¹´æ—¶é—´æŒæ¡æŸä¸ªä½“ç³»ç»“æ„ï¼Œä»ç„¶åªèƒ½è®©ä½ ä½¿ç”¨å‡ ç§æµè¡Œçš„æŒ‡ä»¤é›†ä¸­çš„ä¸€ç§ã€‚è¦åœ¨æ‰€æœ‰çš„æŒ‡ä»¤é›†ä¸Šè¿è¡Œä½ çš„è¯­è¨€ï¼Œä½ éœ€è¦å­¦ä¹ æ‰€æœ‰çš„æŒ‡ä»¤é›†å¹¶ä¸”ä¸ºæ¯ä¸ªæŒ‡ä»¤é›†ç¼–å†™ä¸€ä¸ªå•ç‹¬çš„åç«¯ã€‚</p>
<blockquote>
<p>Yes, they actually wrote machine code by hand. On punched cards. Which, presumably, they punched with their fists.</p>
<p>æ˜¯çš„ï¼Œä»–ä»¬å®é™…ä¸Šæ˜¯æ‰‹å†™æœºå™¨ç ï¼Œåœ¨æ‰“å­”å¡ä¸Šï¼Œæˆ‘æƒ³ä»–ä»¬å¯èƒ½æ˜¯ç”¨æ‹³å¤´æ‰“å­”çš„å§ ğŸ˜ </p>
</blockquote>
<blockquote>
<p>The situation isnâ€™t entirely dire. A well-architected compiler lets you share the front end and most of the middle layer optimization passes across the different architectures you support. Itâ€™s mainly the code generation and some of the details around instruction selection that youâ€™ll need to write afresh each time.</p>
<p>The LLVM project gives you some of this out of the box. If your compiler outputs LLVMâ€™s own special intermediate language, LLVM in turn compiles that to native code for a plethora of architectures.</p>
<p>æƒ…å†µå¹¶éå®Œå…¨ç»æœ›ï¼Œä¸€ä¸ªè‰¯å¥½è®¾è®¡çš„ç¼–è¯‘å™¨å¯ä»¥è®©ä½ åœ¨ï¼Œæ”¯æŒçš„ä¸åŒä½“ç³»ç»“æ„ä¹‹é—´å…±äº«å‰ç«¯å’Œå¤§å¤šæ•°ä¸­é—´å±‚ä¼˜åŒ–å¤„ç†ã€‚ä¸»è¦æ˜¯ï¼Œä»£ç ç”Ÿæˆå’Œä¸€äº›å…³äºæŒ‡ä»¤é€‰æ‹©çš„ç»†èŠ‚éœ€è¦æ¯æ¬¡é‡æ–°ç¼–å†™ã€‚</p>
<p><a href="https://llvm.org/">LLVM é¡¹ç›®</a>å¯ä»¥ä¸ºä½ æä¾›ä¸€äº›è¿™æ–¹é¢çš„æ”¯æŒï¼Œå¦‚æœä½ çš„ç¼–è¯‘å™¨è¾“å‡ºLLVM çš„ç‰¹æ®Šä¸­é—´è¯­è¨€ï¼ŒLLVMå¯ä»¥å°†å…¶ç¼–è¯‘ä¸ºä¼—å¤šä½“ç³»ç»“æ„çš„æœºå™¨ç ã€‚</p>
</blockquote>
<h3 id="13-what-is-bytecode"><a class="header" href="#13-what-is-bytecode">1.3 What is bytecode?</a></h3>
<p>Fix those two points in your mind. On one end, a tree-walk interpreter is simple, portable, and slow. On the other, native code is complex and platform-specific but fast. Bytecode sits in the middle. It retains the portability of a tree-walkerâ€”we wonâ€™t be getting our hands dirty with assembly code in this book. It sacrifices some simplicity to get a performance boost in return, though not as fast as going fully native.</p>
<p>è¯·è®°ä½è¿™ä¸¤ä¸ªè§‚ç‚¹ï¼Œ</p>
<ul>
<li>
<p>ä¸€æ–¹é¢ï¼Œè¯­æ³•æ ‘éå†æ–¹å¼çš„è§£é‡Šå™¨ç®€å•ã€å¯ç§»æ¤ï¼Œä½†æ˜¯è¿è¡Œé€Ÿåº¦æ…¢</p>
</li>
<li>
<p>å¦ä¸€æ–¹é¢ï¼Œç¼–è¯‘ä¸ºæœºå™¨ç æ–¹å¼ï¼Œå¤æ‚ã€ä¸å¹³å°æœ‰å…³ï¼Œä½†æ˜¯è¿è¡Œé€Ÿåº¦å¿«</p>
</li>
</ul>
<p>å­—èŠ‚ç å¤„äºä¸¤è€…ä¹‹é—´ã€‚</p>
<p>å®ƒä¿ç•™äº†ç¬¬ä¸€ç§æ–¹å¼çš„å¯ç§»æ¤æ€§â€”â€”åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šæ¶‰åŠåˆ°æ±‡ç¼–ä»£ç ã€‚ä½†æ˜¯ï¼Œå®ƒä¹Ÿç‰ºç‰²äº†ä¸€äº›ç®€å•æ€§ï¼Œæ¢å–æ€§èƒ½æå‡ï¼Œå°½ç®¡ä¸å¦‚å®Œå…¨çš„æœºå™¨ç é‚£ä¹ˆå¿«ã€‚</p>
<p>Structurally, bytecode resembles machine code. Itâ€™s a dense, linear sequence of binary instructions. That keeps overhead low and plays nice with the cache. However, itâ€™s a much simpler, higher-level instruction set than any real chip out there. (In many bytecode formats, each instruction is only a single byte long, hence â€œbytecodeâ€.)</p>
<p>Imagine youâ€™re writing a native compiler from some source language and youâ€™re given carte blanche to define the easiest possible architecture to target. Bytecode is kind of like that. Itâ€™s an idealized fantasy instruction set that makes your life as the compiler writer easier.</p>
<p>åœ¨ç»“æ„ä¸Šï¼Œå­—èŠ‚ç ç±»ä¼¼äºæœºå™¨ç ã€‚å®ƒæ˜¯ä¸€ä¸ªå¯†é›†çš„ã€çº¿æ€§çš„äºŒè¿›åˆ¶æŒ‡ä»¤åºåˆ—ã€‚è¿™ä½¿å¾—å¼€é”€æ¯”è¾ƒä½ï¼Œèƒ½å¤Ÿå¾ˆå¥½çš„å’Œç¼“å­˜é…åˆã€‚ç„¶è€Œï¼Œå®ƒæ¯”ä»»ä½•çœŸå®èŠ¯ç‰‡ä¸Šçš„æŒ‡ä»¤é›†è¦ç®€ç­”å¾ˆå¤šï¼Œå±äºæ›´é«˜å±‚æ¬¡çš„æŒ‡ä»¤é›†ã€‚ï¼ˆåœ¨å¾ˆå¤šå­—èŠ‚ç æ ¼å¼ä¸­ï¼Œæ¯ä¸ªæŒ‡ä»¤åªæœ‰ä¸€ä¸ªå­—èŠ‚é•¿ï¼Œå› æ­¤ç§°ä¸ºå­—èŠ‚ç ï¼‰</p>
<p>æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ­£åœ¨ä»æºè¯­è¨€ç¼–å†™ä¸€ä¸ªæœºå™¨ç ç¼–è¯‘å™¨ï¼Œä½ è¢«æˆæƒå®šä¹‰ä¸€ä¸ªæœ€ç®€å•çš„æ¶æ„ï¼Œå­—èŠ‚ç å°±æœ‰ç‚¹åƒæ˜¯è¿™æ ·ï¼Œå®ƒæ˜¯ä¸€ä¸ªç†æƒ³åŒ–çš„å‡æƒ³çš„æŒ‡ä»¤é›†ï¼Œä½¿å¾—ï¼Œæˆ‘ä»¬ç¼–å†™ç¼–è¯‘å™¨æ›´åŠ å®¹æ˜“ã€‚</p>
<p>The problem with a fantasy architecture, of course, is that it doesnâ€™t exist. We solve that by writing an emulatorâ€”a simulated chip written in software that interprets the bytecode one instruction at a time. A virtual machine (VM), if you will.</p>
<p>That emulation layer adds overhead, which is a key reason bytecode is slower than native code. But in return, it gives us portability. Write our VM in a language like C that is already supported on all the machines we care about, and we can run our emulator on top of any hardware we like.</p>
<p>å½“ç„¶ï¼Œå‡æƒ³çš„æ¶æ„çš„é—®é¢˜æ˜¯å®ƒå¹¶ä¸å­˜åœ¨ï¼Œæˆ‘ä»¬é€šè¿‡ç¼–å†™æ¨¡æ‹Ÿå™¨â€”â€”ä¸€ç§ä»¥è½¯ä»¶å½¢å¼ç¼–å†™çš„æ¨¡æ‹ŸèŠ¯ç‰‡ï¼Œé€æ¡è§£é‡Šå­—èŠ‚ç æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸€ä¸ªè™šæ‹Ÿæœº VMï¼Œå¦‚æœæˆ‘ä»¬è¦ç§°å‘¼å®ƒã€‚</p>
<p>è¿™ä¸ªä»¿çœŸå±‚å¢åŠ äº†ä¸€äº›å¼€é”€ï¼Œè¿™ä¹Ÿæ˜¯å­—èŠ‚ç æ¯”æœºå™¨ç æ…¢çš„ä¸€ä¸ªé‡è¦åŸå› ï¼Œä½†æ˜¯ï¼Œä½œä¸ºå›æŠ¥ï¼Œå®ƒç»™äº†æˆ‘ä»¬å¯ç§»æ¤æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨ç±»ä¼¼C çš„è¯­è¨€ç¼–å†™VMï¼Œè€Œè¿™åœ¨æ‰€æœ‰çš„æœºå™¨ä¸Šéƒ½æ˜¯æ”¯æŒçš„ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä»»ä½•æˆ‘ä»¬å–œæ¬¢çš„ç¡¬ä»¶ä¸Šï¼Œè¿è¡Œæˆ‘ä»¬çš„æ¨¡æ‹Ÿå™¨ã€‚</p>
<p>This is the path weâ€™ll take with our new interpreter, clox. Weâ€™ll follow in the footsteps of the main implementations of Python, Ruby, Lua, OCaml, Erlang, and others. In many ways, our VMâ€™s design will parallel the structure of our previous interpreter:</p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/phases.png?raw=true" alt="phrases" /></p>
<p>Of course, we wonâ€™t implement the phases strictly in order. Like our previous interpreter, weâ€™ll bounce around, building up the implementation one language feature at a time. In this chapter, weâ€™ll get the skeleton of the application in place and create the data structures needed to store and represent a chunk of bytecode.</p>
<p>è¿™å°±æ˜¯æˆ‘ä»¬æ–°çš„è§£é‡Šå™¨ cloxï¼Œæ‰€è¦ä½¿ç”¨çš„è·¯å¾„ã€‚æˆ‘ä»¬å°†è·Ÿéšç€ Pythonã€Rubyã€Luaã€OCamlã€Erlangå’Œå…¶ä»–è¯­è¨€çš„å®ç°æ–¹å¼ã€‚åœ¨å¾ˆå¤šæ–¹é¢ï¼Œæˆ‘ä»¬çš„è™šæ‹Ÿæœºè®¾è®¡å°†ä¸æˆ‘ä»¬ä¹‹å‰çš„è§£é‡Šå™¨ç»“æ„ç›¸å¯¹åº”ã€‚</p>
<p>å½“ç„¶ï¼Œæˆ‘ä»¬ä¸ä¼šæŒ‰ç…§é¡ºåºä¸¥æ ¼å®ç°å„ä¸ªé˜¶æ®µã€‚å°±åƒæ˜¯ä»¥å‰çš„è§£é‡Šå™¨ä¸€æ ·ï¼Œæˆ‘ä»¬å°†è·³è½¬ï¼Œæœ€ç»ˆå®ç°ä¸€ä¸ªè§£é‡Šå™¨ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è·å–è¯¥è§£é‡Šå™¨çš„æ¶æ„ï¼Œå¹¶ä¸”åˆ›å»ºæ•°æ®ç»“æ„ï¼Œè¯¥ç»“æ„å­˜å‚¨ç€å­—èŠ‚ç ã€‚</p>
<blockquote>
<p>One of the first bytecode formats was <a href="https://en.wikipedia.org/wiki/P-code_machine">p-code</a>, developed for Niklaus Wirthâ€™s Pascal language. You might think a PDP-11 running at 15MHz couldnâ€™t afford the overhead of emulating a virtual machine. But back then, computers were in their Cambrian explosion and new architectures appeared every day. Keeping up with the latest chips was worth more than squeezing the maximum performance from each one. Thatâ€™s why the â€œpâ€ in p-code doesnâ€™t stand for â€œPascalâ€, but â€œportableâ€.</p>
<p>æœ€æ—©çš„ä¸€ç§å­—èŠ‚ç æ˜¯ï¼ŒNiklaus Wirth ä¸ºPascalè¯­è¨€å¼€å‘çš„ p-code. ä½ å¯èƒ½ä¼šè®¤ä¸ºï¼ŒPDP-11 ä»¥15MHz çš„è¿è¡Œé¢‘ç‡æ— æ³•æ‰¿å—ä¸€ä¸ªè™šæ‹Ÿæœºçš„è¿è¡Œã€‚ä½†å½“æ—¶ï¼Œè®¡ç®—æœºæ­£å¤„äºå¯’æ­¦çºªçˆ†å‘æœŸï¼Œæ¯å¤©éƒ½ä¼šå‡ºç°æ–°çš„ä½“ç³»ç»“æ„ã€‚è·Ÿä¸Šæœ€æ–°èŠ¯ç‰‡çš„æ­¥ä¼ï¼Œæ€»æ¯”ä»æ¯ç§èŠ¯ç‰‡ä¸­æŒ¤å‡ºæ›´å¤§çš„æ€§èƒ½æ›´å€¼å¾—ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆï¼Œp-codeä¸­çš„p è¡¨ç¤ºä¸º protableï¼ˆå¯ç§»æ¤æ€§ï¼‰ï¼Œè€Œä¸æ˜¯Pascal çš„åŸå› ã€‚</p>
</blockquote>
<h2 id="äºŒgetting-started"><a class="header" href="#äºŒgetting-started">äºŒã€Getting Started</a></h2>
<p>Where else to begin, but at main()? Fire up your trusty text editor and start typing.</p>
<p>æ²¡ä»€ä¹ˆæ¯”ä» main() å¼€å§‹æ›´å¥½çš„èµ·ç‚¹äº†å§ï¼Œæ‰“å¼€ç¼–è¾‘å™¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹ç¼–ç¨‹å§</p>
<pre><code class="language-c">
// main.c, create new file

#include &quot;common.h&quot;

int main(int argc, const char* argv[]) {
  return 0;
}

</code></pre>
<p>From this tiny seed, we will grow our entire VM. Since C provides us with so little, we first need to spend some time amending the soil. Some of that goes into this header:</p>
<p>ä»è¿™æ£µå¾®å°çš„ç§å­å¼€å§‹ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ•´ä¸ªè™šæ‹Ÿæœºçš„ç¼–å†™ã€‚ç”±äºCè¯­è¨€æä¾›çš„å†…å®¹å¾ˆå°‘ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦èŠ±è´¹ä¸€äº›æ—¶é—´ï¼Œæ”¹å–„ä¸€ä¸‹åœŸå£¤ã€‚å…¶ä¸­ï¼Œä¸€éƒ¨åˆ†å·¥ä½œæ¶‰åŠè¿™ä¸ªå¤´æ–‡ä»¶ã€‚</p>
<pre><code class="language-c">
# common.h, create new file

#ifndef clox_common_h
#define clox_common_h

#include &lt;stdbool.h&gt;
#include &lt;stddef.h&gt;
#include &lt;stdint.h&gt;

#endif

</code></pre>
<p>There are a handful of types and constants weâ€™ll use throughout the interpreter, and this is a convenient place to put them. For now, itâ€™s the venerable NULL, size_t, the nice C99 Boolean bool, and explicit-sized integer typesâ€”uint8_t and friends.</p>
<p>åœ¨è§£é‡Šå™¨ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›ç±»å‹å’Œå¸¸é‡ï¼Œå¹¶ä¸”åœ¨common.h ä¸­æ”¾ç½®å®ƒä»¬ã€‚ç›®å‰ï¼Œè¿™äº›åŒ…å« NULLï¼Œsize_t ï¼ŒC99è§„èŒƒä¸­å®šä¹‰çš„å¸ƒå°”ç±»å‹ boolï¼Œä»¥åŠæ˜¾å¼å¤§å°çš„æ•´æ•°ç±»å‹ unit8_t ç­‰</p>
<h2 id="ä¸‰-chunks-of-instructions"><a class="header" href="#ä¸‰-chunks-of-instructions">ä¸‰ã€ Chunks of Instructions</a></h2>
<p>Next, we need a module to define our code representation. Iâ€™ve been using â€œchunkâ€ to refer to sequences of bytecode, so letâ€™s make that the official name for that module.</p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¨¡å—æ¥å®šä¹‰æˆ‘ä»¬çš„ä»£ç è¡¨ç¤ºå½¢å¼ï¼Œæˆ‘ä¸€ç›´ä½¿ç”¨ chunkæ¥æŒ‡ä»£å­—èŠ‚ç åºåˆ—ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬å°†å…¶ä½œä¸ºæ¨¡å—çš„åç§°ã€‚</p>
<pre><code class="language-c">
// chunk.h, create new file

#ifndef clox_chunk_h
#define clox_chunk_h

#include &quot;common.h&quot;

#endif


</code></pre>
<p>In our bytecode format, each instruction has a one-byte operation code (universally shortened to opcode). That number controls what kind of instruction weâ€™re dealing withâ€”add, subtract, look up variable, etc. We define those here:</p>
<p>åœ¨æˆ‘ä»¬çš„å­—èŠ‚ç æ ¼å¼ä¸­ï¼Œæ¯ä¸€ä¸ªæŒ‡ä»¤éƒ½æœ‰ä¸€ä¸ªä¸€å­—èŠ‚é•¿åº¦çš„æ“ä½œç ï¼ˆé€šå¸¸ç¼©å†™ä¸ºopcode), è¯¥æ•°å­—æ§åˆ¶æˆ‘ä»¬æ­£åœ¨å¤„ç†çš„æŒ‡ä»¤ç±»å‹â€”â€”åŠ ã€å‡ã€æŸ¥æ‰¾å˜é‡ç­‰ç­‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰:</p>
<pre><code class="language-c">
// chunk.h

#include &quot;common.h&quot;

typedef enum {
  OP_RETURN,
} OpCode;

#endif

</code></pre>
<p>For now, we start with a single instruction, OP_RETURN. When we have a full-featured VM, this instruction will mean â€œreturn from the current functionâ€. I admit this isnâ€™t exactly useful yet, but we have to start somewhere, and this is a particularly simple instruction, for reasons weâ€™ll get to later.</p>
<p>ç›®å‰ï¼Œæˆ‘ä»¬åªæ˜¯ç”¨ä¸€ä¸ªæŒ‡ä»¤ OP_RETURN ,å½“æˆ‘ä»¬æ‹¥æœ‰ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„è™šæ‹Ÿæœºæ—¶å€™ï¼Œè¿™ä¸ªæŒ‡ä»¤å°†æ„å‘³ç€ ä»å½“å‰å‡½æ•°è¿”å›ï¼Œæˆ‘æ‰¿è®¤ç°åœ¨è¿™å¹¶ä¸æ˜¯éå¸¸æœ‰ç”¨ï¼Œä½†æ˜¯æˆ‘ä»¬å¿…é¡»ä»æŸä¸ªåœ°æ–¹å¼€å§‹ï¼Œè€Œè¿™æ˜¯ä¸€ä¸ªç‰¹åˆ«ç®€å•çš„æŒ‡ä»¤ï¼ŒåŸå› ç¨åæˆ‘ä»¬ä¼šè®²åˆ°ã€‚</p>
<h3 id="31-a-dynamic-array-of-instructions"><a class="header" href="#31-a-dynamic-array-of-instructions">3.1 A dynamic array of instructions</a></h3>
<p>Bytecode is a series of instructions. Eventually, weâ€™ll store some other data along with the instructions, so letâ€™s go ahead and create a struct to hold it all.</p>
<p>å­—èŠ‚ç æ˜¯ä¸€ç³»åˆ—æŒ‡ä»¤ï¼Œæœ€ç»ˆï¼Œæˆ‘ä»¬å°†å­˜å‚¨ä¸€äº›å’ŒæŒ‡ä»¤ä¸€èµ·çš„å…¶ä»–æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç»“æ„ä½“æ¥ä¿å­˜å®ƒä»¬ã€‚</p>
<pre><code class="language-c">
// chunk.h, add after enum OpCode

} OpCode;

typedef struct {
  uint8_t* code;
} Chunk;

#endif

</code></pre>
<p>At the moment, this is simply a wrapper around an array of bytes. Since we donâ€™t know how big the array needs to be before we start compiling a chunk, it must be dynamic. Dynamic arrays are one of my favorite data structures. That sounds like claiming vanilla is my favorite ice cream flavor, but hear me out. Dynamic arrays provide:</p>
<ul>
<li>
<p>Cache-friendly, dense storage</p>
</li>
<li>
<p>Constant-time indexed element lookup</p>
</li>
<li>
<p>Constant-time appending to the end of the array</p>
</li>
</ul>
<blockquote>
<p>Butter pecan is actually my favorite.</p>
<p>ç‰›æ²¹å±±æ ¸æ¡ƒå†°æ·‡æ·‹å®é™…ä¸Šæ˜¯æˆ‘çš„æœ€çˆ±</p>
</blockquote>
<p>Those features are exactly why we used dynamic arrays all the time in jlox under the guise of Javaâ€™s ArrayList class. Now that weâ€™re in C, we get to roll our own. If youâ€™re rusty on dynamic arrays, the idea is pretty simple. In addition to the array itself, we keep two numbers: the number of elements in the array we have allocated (â€œcapacityâ€) and how many of those allocated entries are actually in use (â€œcountâ€).</p>
<p>ç›®å‰ï¼Œè¿™åªæ˜¯ä¸€ä¸ªåŒ…è£…åœ¨å­—èŠ‚æ•°ç»„å‘¨å›´çš„ç»“æ„ä½“ï¼Œç”±äºåœ¨ç¼–è¯‘å—ä¹‹å‰ï¼Œæˆ‘ä»¬ä¸çŸ¥é“æ•°ç»„æœ‰å¤šå¤§ï¼Œå› æ­¤å®ƒå¿…é¡»æ˜¯åŠ¨æ€çš„ï¼ŒåŠ¨æ€æ•°ç»„æ˜¯æˆ‘æœ€å–œæ¬¢çš„ç»“æ„ä¹‹ä¸€ï¼Œè¿™å¬èµ·æ¥åƒæ˜¯å£°ç§°é¦™è‰æ˜¯æˆ‘æœ€å–œæ¬¢çš„å†°æ·‡æ·‹å£å‘³ï¼Œä½†æ˜¯ï¼Œè¯·å¬æˆ‘è§£é‡Šï¼ŒåŠ¨æ€æ•°ç»„æä¾›äº†: </p>
<ul>
<li>
<p>ç¼“å­˜å‹å¥½ï¼Œå¯†é›†çš„å­˜å‚¨æ–¹å¼</p>
</li>
<li>
<p>å¸¸æ•°æ—¶é—´çš„ç´¢å¼•å…ƒç´ æŸ¥æ‰¾</p>
</li>
<li>
<p>åœ¨åˆ—è¡¨æ·»åŠ å…ƒç´ ï¼Œå¸¸æ•°æ—¶é—´</p>
</li>
</ul>
<p>ç”±äºè¿™äº›ç‰¹å¾ï¼Œæˆ‘ä»¬åœ¨jloxä¸­ä¸€ç›´ä½¿ç”¨Java çš„ ArrayListç±»æ¥ä¼ªè£…åŠ¨æ€æ•°ç»„ï¼Œç°åœ¨åœ¨æˆ‘ä»¬çš„clox ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå·±ç¼–å†™ã€‚å¦‚æœä½ å¯¹åŠ¨æ€æ•°ç»„ä¸å¤ªç†Ÿæ‚‰ï¼Œè¿™ä¸ªæƒ³æ³•ç›¸å½“ç®€å•ï¼Œé™¤äº†æ•°ç»„æœ¬èº«ï¼Œæˆ‘ä»¬è¿˜ä¿ç•™äº†ä¸¤ä¸ªæ•°å­—:</p>
<p>(1) æˆ‘ä»¬å·²ç»åˆ†é…çš„æ•°ç»„å…ƒç´ ä¸ªæ•°ï¼ˆå®¹é‡ï¼‰</p>
<p>(2) å®é™…ä½¿ç”¨çš„åˆ†é…å…ƒç´ çš„æ•°é‡ï¼ˆè®¡æ•°ï¼‰</p>
<pre><code class="language-c">
// chunk.h, in struct Chunk

typedef struct {
  int count;
  int capacity;
  uint8_t* code;
} Chunk;


</code></pre>
<p>When we add an element, if the count is less than the capacity, then there is already available space in the array. We store the new element right in there and bump the count.</p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/14_insert.png?raw=true" alt="insert" /></p>
<p>å½“æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªå…ƒç´ æ—¶å€™ï¼Œå¦‚æœè®¡æ•°å°äºå®¹é‡ï¼Œé‚£ä¹ˆæ•°ç»„ä¸­ä»ç„¶æœ‰å¯ç”¨çš„ç©ºé—´ã€‚æˆ‘ä»¬å°†æ–°å…ƒç´ ä¿å­˜åœ¨é‚£é‡Œï¼Œå¢åŠ è®¡æ•°</p>
<p>If we have no spare capacity, then the process is a little more involved.</p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/14_grow.png?raw=true" alt="grow" /></p>
<ol>
<li>
<p>Allocate a new array with more capacity.</p>
</li>
<li>
<p>Copy the existing elements from the old array to the new one.</p>
</li>
<li>
<p>Store the new capacity.</p>
</li>
<li>
<p>Delete the old array.</p>
</li>
<li>
<p>Update code to point to the new array.</p>
</li>
<li>
<p>Store the element in the new array now that there is room.</p>
</li>
<li>
<p>Update the count.</p>
</li>
</ol>
<p>å¦‚æœæ²¡æœ‰å¤šä½™çš„ç©ºé—´ï¼Œé‚£ä¹ˆè¿™ä¸ªè¿‡ç¨‹ä¼šç¨å¾®å¤æ‚ä¸€ç‚¹ã€‚</p>
<ol>
<li>
<p>åˆ†é…ä¸€ä¸ªæœ‰æ›´å¤§å®¹é‡çš„æ–°æ•°ç»„</p>
</li>
<li>
<p>å°†ç°æœ‰æ•°æ®ä»æ—§æ•°ç»„å¤åˆ¶åˆ°æ–°æ•°ç»„</p>
</li>
<li>
<p>å­˜å‚¨æ–°çš„å®¹é‡</p>
</li>
<li>
<p>åˆ é™¤æ—§æ•°ç»„</p>
</li>
<li>
<p>æ›´æ–°ä»£ç æŒ‡å‘æ–°çš„æ•°ç»„</p>
</li>
<li>
<p>ç°åœ¨æœ‰ç©ºé—´äº†ï¼Œå°†æ–°å…ƒç´ ä¿å­˜åˆ°æ–°æ•°ç»„ä¸­</p>
</li>
<li>
<p>æ›´æ–°è®¡æ•°</p>
</li>
</ol>
<blockquote>
<p>Copying the existing elements when you grow the array makes it seem like appending an element is O(n), not O(1) like I said above. However, you need to do this copy step only on some of the appends. Most of the time, there is already extra capacity, so you donâ€™t need to copy.</p>
<p>To understand how this works, we need <a href="https://en.wikipedia.org/wiki/Amortized_analysis">amortized analysis</a>. That shows us that as long as we grow the array by a multiple of its current size, when we average out the cost of a sequence of appends, each append is O(1).</p>
<p>å½“æˆ‘ä»¬å¢åŠ æ•°ç»„å¤§å°æ—¶å€™ï¼Œå¤åˆ¶æ‰€æœ‰çš„ç°æœ‰å…ƒç´ ä¼¼ä¹ä½¿å¾—æ·»åŠ ä¸€ä¸ªå…ƒç´ çš„æ—¶é—´å¤æ‚åº¦ä¸º \( O(n) \), è€Œä¸æ˜¯ä¹‹å‰çš„ \( O(1) \), ä½†æ˜¯ï¼Œä½ åªéœ€è¦åœ¨æŸäº›è¿½åŠ æ“ä½œä¸­è¿›è¡Œå¤åˆ¶ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå·²ç»æœ‰äº†é¢å¤–çš„å®¹é‡ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¤åˆ¶</p>
<p>è¦ç†è§£è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œåˆ†æ‘Šåˆ†æï¼Œè¿™å¯ä»¥å‘Šè¯‰æˆ‘ä»¬ï¼Œåªè¦æˆ‘ä»¬æŠŠæ•°ç»„çš„å¤§å°å¢åŠ åˆ°å½“å‰å¤§å°çš„å€æ•°ï¼Œå½“æˆ‘ä»¬å¹³å‡ä¸€ç³»åˆ—è¿½åŠ æ“ä½œçš„æˆæœ¬æ—¶å€™ï¼Œæ¯ä¸ªè¿½åŠ æ“ä½œéƒ½æ˜¯ \( O(1) \)</p>
</blockquote>
<p>We have our struct ready, so letâ€™s implement the functions to work with it. C doesnâ€™t have constructors, so we declare a function to initialize a new chunk.</p>
<p>æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†ç»“æ„ä½“ï¼Œæ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®ç°ä¸ä¹‹ä¸€èµ·å·¥ä½œçš„å‡½æ•°ï¼ŒCæ²¡æœ‰æ„é€ å‡½æ•°ï¼Œå› æ­¤æˆ‘ä»¬å£°æ˜ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆå§‹åŒ–ä¸€ä¸ªæ–°çš„ chunk</p>
<pre><code class="language-C">
// chunk.h, add after struct Chunk

} Chunk;

void initChunk(Chunk* chunk);

#endif


</code></pre>
<p>And implement it thusly:</p>
<p>ç„¶åï¼Œè¿™æ ·å®ç°å®ƒ</p>
<pre><code class="language-c">
// chunk.c, create new file

#include &lt;stdlib.h&gt;

#include &quot;chunk.h&quot;

void initChunk(Chunk* chunk) {
  chunk-&gt;count = 0;
  chunk-&gt;capacity = 0;
  chunk-&gt;code = NULL;
}


</code></pre>
<p>The dynamic array starts off completely empty. We donâ€™t even allocate a raw array yet. To append a byte to the end of the chunk, we use a new function.</p>
<p>åŠ¨æ€æ•°ç»„ä¸€å¼€å§‹æ˜¯å®Œå…¨ç©ºçš„ï¼Œæˆ‘ä»¬ç”šè‡³éƒ½æ²¡æœ‰åˆ†é…åŸå§‹æ•°ç»„ï¼Œè¦å°†ä¸€ä¸ªå­—èŠ‚è¿½åŠ åˆ°å—çš„æœ«å°¾ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ–°çš„å‡½æ•°</p>
<pre><code class="language-c">
// chunk.h, add after initChunk()

void initChunk(Chunk* chunk);
void writeChunk(Chunk* chunk, uint8_t byte);

#endif

</code></pre>
<p>This is where the interesting work happens.</p>
<p>æ¥ä¸‹æ¥å°†æ˜¯æœ‰è¶£çš„åœ°æ–¹</p>
<pre><code class="language-c">
// chunk.c, add after initChunk()

void writeChunk(Chunk* chunk, uint8_t byte) {
  if (chunk-&gt;capacity &lt; chunk-&gt;count + 1) {
    int oldCapacity = chunk-&gt;capacity;
    chunk-&gt;capacity = GROW_CAPACITY(oldCapacity);
    chunk-&gt;code = GROW_ARRAY(uint8_t, chunk-&gt;code,
        oldCapacity, chunk-&gt;capacity);
  }

  chunk-&gt;code[chunk-&gt;count] = byte;
  chunk-&gt;count++;
}

</code></pre>
<p>The first thing we need to do is see if the current array already has capacity for the new byte. If it doesnâ€™t, then we first need to grow the array to make room. (We also hit this case on the very first write when the array is NULL and capacity is 0.)</p>
<p>To grow the array, first we figure out the new capacity and grow the array to that size. Both of those lower-level memory operations are defined in a new module.</p>
<p>æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯ï¼ŒæŸ¥çœ‹å½“å‰æ•°ç»„æ˜¯å¦è¿˜æœ‰æ–°å­—èŠ‚çš„æ·»åŠ ç©ºé—´ï¼Œ</p>
<p>å¦‚æœæ²¡æœ‰ç©ºé—´ï¼Œæˆ‘ä»¬éœ€è¦æ‰©å±•æ•°ç»„ï¼Œè…¾å‡ºç©ºé—´ï¼ˆå½“æ•°ç»„ä¸ºNULLï¼Œå®¹é‡ä¸º0ï¼Œæ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¼šé‡åˆ°è¿™ç§é—®é¢˜ï¼‰</p>
<p>è¦æ‰©å±•æ•°ç»„ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ–°æ•°ç»„çš„å®¹é‡ï¼Œå°†æ•°ç»„å¤§å°æ‰©å±•åˆ°è¯¥å¤§å°ï¼Œè¿™ä¸¤ä¸ªè¾ƒä½çº§åˆ«çš„å†…å­˜æ“ä½œï¼Œæˆ‘ä»¬å°†åœ¨ä¸€ä¸ªæ–°æ¨¡å—ä¸­å®šä¹‰ã€‚</p>
<pre><code class="language-c">
// chunk.c

#include &quot;chunk.h&quot;
#include &quot;memory.h&quot;

void initChunk(Chunk* chunk) {

</code></pre>
<p>This is enough to get us started.</p>
<pre><code class="language-c">
// memory.h, create new file

#ifndef clox_memory_h
#define clox_memory_h

#include &quot;common.h&quot;

#define GROW_CAPACITY(capacity) \
    ((capacity) &lt; 8 ? 8 : (capacity) * 2)

#endif


</code></pre>
<p>This macro calculates a new capacity based on a given current capacity. In order to get the performance we want, the important part is that it scales based on the old size. We grow by a factor of two, which is pretty typical. 1.5Ã— is another common choice.</p>
<p>We also handle when the current capacity is zero. In that case, we jump straight to eight elements instead of starting at one. That avoids a little extra memory churn when the array is very small, at the expense of wasting a few bytes on very small chunks.</p>
<p>è¿™ä¸ªå®æ ¹æ®å½“å‰ç»™å®šçš„å®¹é‡ï¼Œè®¡ç®—ä¸€ä¸ªæ–°å®¹é‡ã€‚ä¸ºäº†å¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„æ€§èƒ½ï¼Œé‡è¦çš„éƒ¨åˆ†æ˜¯å®ƒåŸºäºæ—§å®¹é‡è¿›è¡Œç¼©æ”¾ï¼Œæˆ‘ä»¬æŒ‰ç…§ä¸¤å€å¢é•¿ï¼Œè¿™æ˜¯ç›¸å½“å…¸å‹çš„ï¼Œ1.5å€æ˜¯å¦å¤–ä¸€ä¸ªå¸¸è§çš„é€‰æ‹©ã€‚</p>
<p>æˆ‘ä»¬è¿˜å°†å¤„ç†å½“å‰å®¹é‡ä¸º0çš„åœºæ™¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç›´æ¥è·³åˆ°8ä¸ªå…ƒç´ ï¼Œè€Œä¸æ˜¯ä»ä¸€ä¸ªå…ƒç´ å¼€å§‹ï¼Œè¿™é¿å…äº†åœ¨æ•°ç»„éå¸¸å°çš„æƒ…å†µä¸‹ï¼Œå¤šä½™çš„å†…å­˜æ³¢åŠ¨ï¼Œä»£ä»·æ˜¯åœ¨éå¸¸å°çš„å—ä¸Šæµªè´¹äº†ä¸€äº›å­—èŠ‚ã€‚</p>
<blockquote>
<p>I picked the number eight somewhat arbitrarily for the book. Most dynamic array implementations have a minimum threshold like this. The right way to pick a value for this is to profile against real-world usage and see which constant makes the best performance trade-off between extra grows versus wasted space.</p>
<p>æˆ‘åœ¨æœ¬ä¹¦ä¸­ï¼Œé€‰æ‹©æ•°ç»„æœ€å°é•¿åº¦ä¸º8ï¼Œæœ‰äº›éšæ„ï¼Œå¤§å¤šæ•°çš„åŠ¨æ€æ•°ç»„å®ç°ï¼Œéƒ½æœ‰è¿™æ ·çš„æœ€å°é˜ˆå€¼ã€‚é€‰æ‹©è¿™ä¸ªå€¼çš„æ­£ç¡®æ–¹æ³•æ˜¯é’ˆå¯¹å®é™…ä½¿ç”¨æƒ…å†µè¿›è¡Œåˆ†æï¼Œå¹¶æŸ¥çœ‹å“ªä¸ªå¸¸é‡åœ¨é¢å¤–å¢é•¿å’Œæµªè´¹ç©ºé—´ä¹‹é—´ï¼Œå–å¾—æœ€ä½³æ€§èƒ½å¹³è¡¡ã€‚</p>
</blockquote>
<p>Once we know the desired capacity, we create or grow the array to that size using GROW_ARRAY().</p>
<p>ä¸€æ—¦æˆ‘ä»¬çŸ¥é“æ‰€éœ€å®¹é‡çš„å¤§å°ï¼Œæˆ‘ä»¬ä½¿ç”¨GROW_ARRAY() åˆ›å»ºæˆ–è€…å¢é•¿æ•°ç»„åˆ°è¯¥å¤§å°</p>
<pre><code class="language-c">
// memory.h

#define GROW_CAPACITY(capacity) \
    ((capacity) &lt; 8 ? 8 : (capacity) * 2)

#define GROW_ARRAY(type, pointer, oldCount, newCount) \
    (type*)reallocate(pointer, sizeof(type) * (oldCount), \
        sizeof(type) * (newCount))

void* reallocate(void* pointer, size_t oldSize, size_t newSize);

#endif

</code></pre>
<p>This macro pretties up a function call to reallocate() where the real work happens. The macro itself takes care of getting the size of the arrayâ€™s element type and casting the resulting void* back to a pointer of the right type.</p>
<p>è¿™ä¸ªå®ç¾åŒ–äº†å¯¹ reallocate() å‡½æ•°çš„è°ƒç”¨ï¼Œå®é™…çš„å·¥ä½œå‘ç”Ÿåœ¨è¿™é‡Œã€‚å®æœ¬èº«è´Ÿè´£è·å–æ•°ç»„å…ƒç´ ç±»å‹çš„å¤§å°å¹¶å°†ç»“æœ void* å¼ºåˆ¶è½¬åŒ–ä¸ºæ­£ç¡®ç±»å‹çš„æŒ‡é’ˆã€‚</p>
<p>This reallocate() function is the single function weâ€™ll use for all dynamic memory management in cloxâ€”allocating memory, freeing it, and changing the size of an existing allocation. Routing all of those operations through a single function will be important later when we add a garbage collector that needs to keep track of how much memory is in use.</p>
<p>The two size arguments passed to reallocate() control which operation to perform:</p>
<table><thead><tr><th>oldSize</th><th>newSize</th><th>Operation</th></tr></thead><tbody>
<tr><td>0</td><td>Nonâ€‘zero</td><td>Allocate new block.</td></tr>
<tr><td>Nonâ€‘zero</td><td>0</td><td>Free allocation.</td></tr>
<tr><td>Nonâ€‘zero</td><td>Smaller than oldSize</td><td>Shrink existing allocation.</td></tr>
<tr><td>Nonâ€‘zero</td><td>Larger than oldSize</td><td>Grow existing allocation.</td></tr>
</tbody></table>
<p>è¿™ä¸ªreallocate å‡½æ•°æ˜¯æˆ‘ä»¬åœ¨clox ä¸­ç”¨äºæ‰€æœ‰åŠ¨æ€å†…å­˜ç®¡ç†çš„å”¯ä¸€å‡½æ•°â€”â€”åˆ†é…å†…å­˜ã€é‡Šæ”¾å®ƒã€æ›´æ”¹ç°æœ‰åˆ†é…çš„å¤§å°ã€‚å°†æ‰€æœ‰è¿™äº›æ“ä½œè·¯ç”±åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œåœ¨ç¨åæ·»åŠ éœ€è¦è·Ÿè¸ªä½¿ç”¨å¤šå°‘å†…å­˜çš„åƒåœ¾å›æ”¶å™¨æ—¶ï¼Œå°†éå¸¸é‡è¦ã€‚</p>
<p>ä¼ é€’ç»™reallocate() çš„ä¸¤ä¸ªå‚æ•°æ§åˆ¶å°†è¦æ‰§è¡Œçš„æ“ä½œ</p>
<table><thead><tr><th>æ—§çš„size</th><th>æ–°çš„size</th><th>æ“ä½œ</th></tr></thead><tbody>
<tr><td>0</td><td>é0</td><td>åˆ†é…æ–°å—</td></tr>
<tr><td>é0</td><td>0</td><td>é‡Šæ”¾å—</td></tr>
<tr><td>é0</td><td>æ–°çš„size &lt; æ—§çš„size</td><td>ç¼©å°ç°æœ‰çš„åˆ†é…</td></tr>
<tr><td>é0</td><td>æ–°çš„size &gt; æ—§çš„size</td><td>å¢åŠ ç°æœ‰åˆ†é…</td></tr>
</tbody></table>
<p>That sounds like a lot of cases to handle, but hereâ€™s the implementation:</p>
<p>å¬èµ·æ¥ï¼Œå¥½åƒè¦å¤„ç†å¾ˆå¤šçš„åœºæ™¯ï¼Œä½†è¿™æ˜¯å®ç°</p>
<pre><code class="language-c">
// memory.c, create new file


#include &lt;stdlib.h&gt;

#include &quot;memory.h&quot;

void* reallocate(void* pointer, size_t oldSize, size_t newSize) {
  if (newSize == 0) {
    free(pointer);
    return NULL;
  }

  void* result = realloc(pointer, newSize);
  return result;
}


</code></pre>
<p>When newSize is zero, we handle the deallocation case ourselves by calling free(). Otherwise, we rely on the C standard libraryâ€™s realloc() function. That function conveniently supports the other three aspects of our policy. When oldSize is zero, realloc() is equivalent to calling malloc().</p>
<p>The interesting cases are when both oldSize and newSize are not zero. Those tell realloc() to resize the previously allocated block. If the new size is smaller than the existing block of memory, it simply updates the size of the block and returns the same pointer you gave it. If the new size is larger, it attempts to grow the existing block of memory.</p>
<p>It can do that only if the memory after that block isnâ€™t already in use. If there isnâ€™t room to grow the block, realloc() instead allocates a new block of memory of the desired size, copies over the old bytes, frees the old block, and then returns a pointer to the new block. Remember, thatâ€™s exactly the behavior we want for our dynamic array.</p>
<p>Because computers are finite lumps of matter and not the perfect mathematical abstractions computer science theory would have us believe, allocation can fail if there isnâ€™t enough memory and realloc() will return NULL. We should handle that.</p>
<p>å½“newSizeä¸º0æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨free() é‡Šæ”¾ç©ºé—´ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬å°†ä¾èµ–Cæ ‡å‡†åº“çš„ realloc() å‡½æ•°ã€‚è¯¥å‡½æ•°å¾ˆæ–¹ä¾¿çš„æ”¯æŒæˆ‘ä»¬çš„å¦å¤–ä¸‰ç§æƒ…å†µã€‚å½“oldSize ä¸º0æ—¶ï¼Œ realloc() ç­‰æ•ˆäº malloc()</p>
<p>æœ‰è¶£çš„åœºæ™¯æ˜¯ newSize å’Œ oldSize éƒ½ä¸ç­‰äº0æ—¶ï¼Œè¿™å‘Šè¯‰ realloc() è°ƒæ•´å…ˆå‰åˆ†é…å—çš„å¤§å°ã€‚</p>
<ul>
<li>
<p>å¦‚æœnewSize &lt; oldSize, åˆ™å®ƒåªä¼šæ›´æ–°å—çš„å¤§å°ï¼Œè¿”å›æˆ‘ä»¬æä¾›çš„ç›¸åŒçš„æŒ‡é’ˆï¼Œ</p>
</li>
<li>
<p>å¦‚æœ newSize &gt; oldSize, åˆ™å®ƒä¼šå°è¯•å¢åŠ ç°æœ‰å—çš„å¤§å°</p>
</li>
</ul>
<p>å®ƒåªèƒ½è¿™æ ·åšï¼Œå‰ææ˜¯å—åé¢çš„å†…å­˜è¿˜æ²¡æœ‰è¢«ä½¿ç”¨ï¼Œå¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç©ºé—´å¢åŠ å—ï¼Œåˆ™realloc() ä¼šåˆ†é…ä¸€ä¸ªæ‰€éœ€å¤§å°çš„æ–°å†…å­˜å—ï¼Œå¤åˆ¶æ–°å­—èŠ‚ï¼Œé‡Šæ”¾æ—§å—ï¼Œç„¶åè¿”å›æŒ‡å‘æ–°å—çš„æŒ‡é’ˆï¼Œè®°ä½ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„åŠ¨æ€æ•°ç»„çš„è¡Œä¸º</p>
<p>å› ä¸ºè®¡ç®—æœºæ˜¯æœ‰é™èµ„æºï¼Œè€Œä¸æ˜¯è®¡ç®—æœºç§‘å­¦ç†è®ºæ‰€å¸Œæœ›çš„å®Œç¾æ•°å­¦æŠ½è±¡ï¼Œå¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼Œåˆ†é…å¯èƒ½ä¼šå¤±è´¥ï¼Œrealloc() å¯èƒ½ä¼šè¿”å›NULL, æˆ‘ä»¬åº”è¯¥å¤„ç†è¿™ç§æƒ…å†µ</p>
<pre><code class="language-c">
// memory.c, in reallocate()

  void* result = realloc(pointer, newSize);
  if (result == NULL) exit(1);
  return result;


</code></pre>
<p>Thereâ€™s not really anything useful that our VM can do if it canâ€™t get the memory it needs, but we at least detect that and abort the process immediately instead of returning a NULL pointer and letting it go off the rails later.</p>
<blockquote>
<p>Since all we passed in was a bare pointer to the first byte of memory, what does it mean to â€œupdateâ€ the blockâ€™s size? Under the hood, the memory allocator maintains additional bookkeeping information for each block of heap-allocated memory, including its size.</p>
<p>Given a pointer to some previously allocated memory, it can find this bookkeeping information, which is necessary to be able to cleanly free it. Itâ€™s this size metadata that realloc() updates.</p>
<p>Many implementations of malloc() store the allocated size in memory right before the returned address.</p>
<p>ç”±äºæˆ‘ä»¬ä¼ é€’çš„ä»…ä»…æ˜¯æŒ‡å‘å†…å­˜ç¬¬ä¸€ä¸ªå­—èŠ‚çš„è£¸æŒ‡é’ˆï¼Œé‚£ä¹ˆæ›´æ–°å—çš„å¤§å°æ„å‘³ç€ä»€ä¹ˆå‘¢ï¼Ÿåœ¨åº•å±‚ï¼Œå†…å­˜åˆ†é…å™¨ä¸ºæ¯ä¸€ä¸ªå †åˆ†é…çš„å†…å­˜å—ç»´æŠ¤é¢å¤–çš„è®°å½•ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶å¤§å°</p>
<p>ç»™å®šæŒ‡å‘å…ˆå‰åˆ†é…çš„å†…å­˜çš„æŒ‡é’ˆï¼Œå®ƒå¯ä»¥æ‰¾åˆ°è¯¥å†…å­˜å—çš„è®°å½•ä¿¡æ¯ï¼Œè¿™æ˜¯èƒ½å¤Ÿå¹²å‡€çš„é‡Šæ”¾å†…å­˜çš„å¿…è¦æ¡ä»¶ï¼Œrealloc() å°±æ˜¯æ›´æ–°è¿™ä¸ªå¤§å°å…ƒæ•°æ®</p>
<p>è®¸å¤šmalloc() å®ç°ï¼Œå°†å·²ç»åˆ†é…çš„å¤§å°å­˜å‚¨åœ¨è¿”å›åœ°å€å‰é¢çš„å†…å­˜ä¸­</p>
</blockquote>
<p>å¦‚æœæˆ‘ä»¬æ— æ³•è·å–æ‰€éœ€çš„å†…å­˜ï¼Œæˆ‘ä»¬çš„è™šæ‹Ÿæœºå®é™…ä¸Šï¼Œä¸èƒ½æ‰§è¡Œä»»ä½•æœ‰ç”¨çš„æ“ä½œï¼Œä½†æˆ‘ä»¬è‡³å°‘ä¼šæ£€æµ‹åˆ°å¹¶ä¸”ç«‹å³ç»ˆæ­¢è¿›ç¨‹ï¼Œè€Œä¸æ˜¯è¿”å›ä¸€ä¸ªNULLæŒ‡é’ˆï¼Œå¹¶ä¸”åœ¨è¿™ä¹‹åï¼Œè®©å®ƒåç¦»æ­£è½¨ã€‚</p>
<p>OK, we can create new chunks and write instructions to them. Are we done? Nope! Weâ€™re in C now, remember, we have to manage memory ourselves, like in Ye Olden Times, and that means freeing it too.</p>
<p>å¥½çš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºæ–°çš„ chunkï¼Œå¹¶ä¸”å°†æŒ‡ä»¤å†™å…¥å…¶ä¸­ã€‚æˆ‘ä»¬å®Œæˆäº†å—ï¼Ÿå¹¶æ²¡æœ‰ï¼Œç°åœ¨æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯Cï¼Œå¿…é¡»è‡ªå·±ç®¡ç†å†…å­˜ï¼Œå°±åƒæ˜¯ä»¥å‰çš„æ—¶ä»£ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦é‡Šæ”¾å®ƒã€‚</p>
<pre><code class="language-c">// chunk.h, add after initChunk()

void initChunk(Chunk* chunk);
void freeChunk(Chunk* chunk);
void writeChunk(Chunk* chunk, uint8_t byte);

</code></pre>
<p>The implementation is:</p>
<pre><code class="language-c">
// chunk.c, add after initChunk()

void freeChunk(Chunk* chunk) {
  FREE_ARRAY(uint8_t, chunk-&gt;code, chunk-&gt;capacity);
  initChunk(chunk);
}


</code></pre>
<p>We deallocate all of the memory and then call initChunk() to zero out the fields leaving the chunk in a well-defined empty state. To free the memory, we add one more macro.</p>
<p>æˆ‘ä»¬é‡Šæ”¾æ‰€æœ‰å†…å­˜ï¼Œç„¶åè°ƒç”¨ initChunk() æ¥æ¸…é›¶å­—æ®µï¼Œå°†chunk å®šä¹‰ä¸ºä¸€ä¸ªè‰¯å¥½çš„ç©ºçŠ¶æ€ï¼Œä¸ºäº†é‡Šæ”¾å†…å­˜ï¼Œæˆ‘ä»¬æ·»åŠ ä¸€ä¸ªé¢å¤–çš„å®</p>
<pre><code class="language-c">
// memory.h

#define GROW_ARRAY(type, pointer, oldCount, newCount) \
    (type*)reallocate(pointer, sizeof(type) * (oldCount), \
        sizeof(type) * (newCount))

#define FREE_ARRAY(type, pointer, oldCount) \
    reallocate(pointer, sizeof(type) * (oldCount), 0)

void* reallocate(void* pointer, size_t oldSize, size_t newSize);

</code></pre>
<p>Like GROW_ARRAY(), this is a wrapper around a call to reallocate(). This one frees the memory by passing in zero for the new size. I know, this is a lot of boring low-level stuff. Donâ€™t worry, weâ€™ll get a lot of use out of these in later chapters and will get to program at a higher level. Before we can do that, though, we gotta lay our own foundation.</p>
<p>åƒæ˜¯ GROW_ARRAY() ,è¿™æ˜¯å¯¹reallocate() è°ƒç”¨çš„åŒ…è£…ï¼Œé€šè¿‡å°†newSize è®¾ç½®ä¸º0æ¥é‡Šæ”¾ç©ºé—´ï¼Œæˆ‘çŸ¥é“ï¼Œè¿™æ˜¯å¾ˆå¤šä½çº§åˆ«çš„æ— èŠå·¥ä½œï¼Œä½†æ˜¯ï¼Œä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘ä»¬å°†åœ¨åé¢çš„ç« èŠ‚ä¸­ï¼Œå¤§é‡ä½¿ç”¨è¿™äº›ï¼Œå¹¶å°†åœ¨è¾ƒé«˜å±‚æ¬¡ä¸Šè¿›è¡Œç¼–ç¨‹ã€‚ä½†åœ¨é‚£ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»æ‰“ä¸‹è‡ªå·±çš„åŸºç¡€ã€‚</p>
<h2 id="å››disassembling-chunks"><a class="header" href="#å››disassembling-chunks">å››ã€Disassembling Chunks</a></h2>
<p>Now we have a little module for creating chunks of bytecode. Letâ€™s try it out by hand-building a sample chunk.</p>
<p>ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªåˆ›å»ºå­—èŠ‚ç å—çš„å°æ¨¡å—ï¼Œè®©æˆ‘ä»¬æ‰‹å·¥åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å—</p>
<pre><code class="language-c">// main.c, in main()

int main(int argc, const char* argv[]) {
  Chunk chunk;
  initChunk(&amp;chunk);
  writeChunk(&amp;chunk, OP_RETURN);
  freeChunk(&amp;chunk);
  return 0;


</code></pre>
<p>Donâ€™t forget the include.</p>
<pre><code class="language-c">
// main.c

#include &quot;common.h&quot;
#include &quot;chunk.h&quot;

int main(int argc, const char* argv[]) {

</code></pre>
<p>Run that and give it a try. Did it work? Uhâ€‰.â€‰.â€‰. who knows? All weâ€™ve done is push some bytes around in memory. We have no human-friendly way to see whatâ€™s actually inside that chunk we made.</p>
<p>To fix this, weâ€™re going to create a disassembler. An assembler is an old-school program that takes a file containing human-readable mnemonic names for CPU instructions like â€œADDâ€ and â€œMULTâ€ and translates them to their binary machine code equivalent. A disassembler goes in the other directionâ€”given a blob of machine code, it spits out a textual listing of the instructions.</p>
<p>Weâ€™ll implement something similar. Given a chunk, it will print out all of the instructions in it. A Lox user wonâ€™t use this, but we Lox maintainers will certainly benefit since it gives us a window into the interpreterâ€™s internal representation of code.</p>

			<div id="bottom"> 
			     <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>

			     <a href="https://info.flagcounter.com/42Wy"><img src="https://s01.flagcounter.com/count/42Wy/bg_FFFFFF/txt_000000/border_CCCCCC/columns_3/maxflags_9/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
		       </div>   	 							 
                       <div id="giscus-container"></div>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <a rel="prev" href="../vm/bytecode-vm.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                        </a>


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../vm/bytecode-vm.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../giscus.js"></script>


    </body>


</html>
