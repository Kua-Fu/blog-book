# å­—èŠ‚ç å—

> If you find that youâ€™re spending almost all your time on theory, start turning some attention to practical things; it will improve your theories. If you find that youâ€™re spending almost all your time on practice, start turning some attention to theoretical things; it will improve your practice.
>
> å¦‚ä½•ä½ å‘ç°è‡ªå·±ç»å¤§éƒ¨åˆ†æ—¶é—´ï¼Œéƒ½èŠ±åœ¨ç†è®ºä¸Šï¼Œé‚£ä¹ˆå¼€å§‹æŠŠä¸€äº›æ³¨æ„åŠ›æ”¾åœ¨å®è·µä¸Šï¼Œè¿™å°†æœ‰åŠ©äºæé«˜ä½ çš„ç†è®ºæ°´å¹³ï¼›
> 
> å¦‚æœä½ å‘ç°è‡ªå·±å‡ ä¹æŠŠæ‰€æœ‰æ—¶é—´éƒ½ç”¨åœ¨å®è·µä¸­ï¼Œé‚£å°±å¼€å§‹å…³æ³¨ä¸€äº›ç†è®ºæ€§çš„ä¸œè¥¿ï¼Œè¿™ä¼šæé«˜ä½ çš„å®è·µèƒ½åŠ›ã€‚


> <p align=right> â€”â€” Donald Knuth </p>

We already have ourselves a complete implementation of Lox with jlox, so why isnâ€™t the book over yet? Part of this is because jlox relies on the JVM to do lots of things for us. If we want to understand how an interpreter works all the way down to the metal, we need to build those bits and pieces ourselves.

æˆ‘ä»¬å·²ç»ä½¿ç”¨jlox å®ç°äº†å®Œæ•´çš„loxï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆæœ¬ä¹¦è¿˜æ²¡æœ‰ç»“æŸå‘¢ï¼Ÿéƒ¨åˆ†åŸå› æ˜¯å› ä¸ºjloxä¾èµ–äº JVMæ¥å®Œæˆå¾ˆå¤šå·¥ä½œï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å®Œå…¨ç†è§£è§£é‡Šå™¨çš„å·¥ä½œåŸç†ï¼Œæˆ‘ä»¬éœ€è¦è‡ªå·±æ„å»ºè¿™äº›éƒ¨åˆ†ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦ä»åº•å±‚å¼€å§‹ä¸€æ­¥æ­¥æ„å»ºè§£é‡Šå™¨ï¼Œä»¥æ·±å…¥äº†è§£å…¶å·¥ä½œåŸç†ã€‚


> Of course, our second interpreter relies on the C standard library for basics like memory allocation, and the C compiler frees us from details of the underlying machine code weâ€™re running it on. Heck, that machine code is probably implemented in terms of microcode on the chip. And the C runtime relies on the operating system to hand out pages of memory. But we have to stop somewhere if this book is going to fit on your bookshelf.
> 
> å½“ç„¶ï¼Œæˆ‘ä»¬çš„ç¬¬äºŒä¸ªè§£é‡Šå™¨ä½¿ç”¨C æ ‡å‡†åº“æ¥è¿›è¡ŒåŸºæœ¬çš„å†…å­˜åˆ†é…æ“ä½œï¼Œè€ŒCç¼–è¯‘å™¨åˆ™ä¸ºæˆ‘ä»¬é¿å…äº†è¿è¡Œæœºå™¨ç æ—¶å€™çš„å†…éƒ¨æ‰§è¡Œç»†èŠ‚ï¼Œå®é™…ä¸Šï¼Œè¿™äº›æœºå™¨ç å¯èƒ½æ˜¯åŸºäºèŠ¯ç‰‡ä¸Šçš„å¾®ç å®ç°ï¼Œè€ŒC è¿è¡Œæ—¶å€™ï¼Œä¾èµ–äºæ“ä½œç³»ç»Ÿæ¥åˆ†é…å†…å­˜é¡µã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›è¿™æœ¬ä¹¦é€‚åˆæ”¾å…¥ä½ çš„ä¹¦æ¶ï¼Œå¿…é¡»åœ¨æŸäº›åœ°æ–¹åœä¸‹æ¥ã€‚

An even more fundamental reason that jlox isnâ€™t sufficient is that itâ€™s too damn slow. A tree-walk interpreter is fine for some kinds of high-level, declarative languages. But for a general-purpose, imperative languageâ€”even a â€œscriptingâ€ language like Loxâ€”it wonâ€™t fly. Take this little script:

è¿˜æœ‰ä¸€ä¸ªæ›´åŠ å®é™…çš„åŸå› ï¼Œæ˜¯jlox æ‰§è¡Œå¤ªæ…¢äº†ã€‚å¯¹äºæŸäº›é«˜çº§ã€å£°æ˜å¼çš„è¯­è¨€ï¼ŒåŸºäºè¯­æ³•æ ‘éå†çš„è§£é‡Šå™¨æ˜¯å¯ä»¥æ¥å—çš„ã€‚ä½†æ˜¯ï¼Œå¯¹äºé€šç”¨çš„ã€å‘½ä»¤å¼è¯­è¨€â€”â€”ä¾‹å¦‚ï¼šloxï¼Œè¿™ç§æ–¹å¼å®ç°çš„è§£é‡Šå™¨ï¼Œå°±ä¸å¤Ÿç”¨äº†ï¼Œæ‰§è¡Œä¸‹é¢çš„è¿™ä¸ªç¨‹åº

```python


fun fib(n) {
  if (n < 2) return n;
  return fib(n - 1) + fib(n - 2); 
}

var before = clock();
print fib(40);
var after = clock();
print after - before;

```
On my laptop, that takes jlox about 72 seconds to execute. An equivalent C program finishes in half a second. Our dynamically typed scripting language is never going to be as fast as a statically typed language with manual memory management, but we donâ€™t need to settle for more than two orders of magnitude slower.

We could take jlox and run it in a profiler and start tuning and tweaking hotspots, but that will only get us so far. The execution modelâ€”walking the ASTâ€”is fundamentally the wrong design. We canâ€™t micro-optimize that to the performance we want any more than you can polish an AMC Gremlin into an SR-71 Blackbird.

We need to rethink the core model. This chapter introduces that model, bytecode, and begins our new interpreter, clox.

åœ¨æˆ‘çš„ç¬”è®°æœ¬ä¸Šï¼Œæ‰§è¡Œä¸Šé¢çš„lox ç¨‹åºè€—æ—¶ 72ç§’ï¼Œè€Œä¸€ä¸ªç­‰æ•ˆçš„C ç¨‹åºåªéœ€è¦åŠç§’é’Ÿå°±å¯ä»¥æ‰§è¡ŒåŒæ ·åŠŸèƒ½ã€‚æˆ‘ä»¬çš„åŠ¨æ€ç±»å‹è„šæœ¬è¯­è¨€ï¼Œå¯èƒ½æ°¸è¿œæ— æ³•åƒå¯ä»¥è‡ªå·±ç®¡ç†å†…å­˜çš„é™æ€ç±»å‹è¯­è¨€é‚£æ ·é«˜æ•ˆï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿä¸æ¥å—ä¸¤ä¸ªæ•°é‡çº§çš„å·®è·ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åˆ†æå™¨åˆ†æloxç¨‹åºï¼Œæ‰¾åˆ°ã€è°ƒæ•´çƒ­ç‚¹ä»£ç ï¼Œä½†æ˜¯ï¼Œè¿™åªèƒ½å¾ˆæœ‰é™çš„æé«˜æ€§èƒ½ã€‚jloxçš„æ‰§è¡Œæ¨¡å‹â€”â€”éå†ASTï¼Œå¯¹æˆ‘ä»¬æ¥è¯´ï¼Œæ˜¯ä¸€ä¸ªé”™è¯¯çš„è®¾è®¡æ–¹å‘ï¼Œæˆ‘ä»¬æ— æ³•é€šè¿‡å¾®è§‚ä¼˜åŒ–æ¥è¾¾åˆ°æˆ‘ä»¬æƒ³è¦çš„æ€§èƒ½ï¼Œå°±åƒæˆ‘ä»¬æ— æ³•æŠŠ AMC Gremlin ï¼ˆæ±½è½¦ï¼‰å˜æˆé«˜æ€§èƒ½çš„ SR-71ï¼ˆé£æœº)

æˆ‘ä»¬éœ€è¦é‡æ–°æ€è€ƒæ ¸å¿ƒæ¨¡å‹ï¼Œæœ¬ç« ä»‹ç»äº†è¿™ä¸ªæ¨¡å‹â€”â€”å­—èŠ‚ç ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ–°çš„è§£é‡Šå™¨ clox

> This is a comically inefficient way to actually calculate Fibonacci numbers. Our goal is to see how fast the interpreter runs, not to see how fast of a program we can write. A slow program that does a lot of workâ€”pointless or notâ€”is a good test case for that.
> 
> è¿™å®é™…ä¸Šæ˜¯ä¸€ç§éå¸¸ä½æ•ˆçš„è®¡ç®—fibonacciæ•°åˆ—çš„æ–¹å¼ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æŸ¥çœ‹è§£é‡Šå™¨çš„è¿è¡Œé€Ÿåº¦ï¼Œè€Œä¸æ˜¯è€ƒå¯Ÿæˆ‘ä»¬èƒ½ç¼–å†™å¤šå¿«çš„ç¨‹åºã€‚ä¸€ä¸ªæ…¢ï¼Œä½†æ˜¯èƒ½è¿›è¡Œå¤§é‡å·¥ä½œï¼ˆæ— è®ºé‡Šæ”¾æœ‰æ„ä¹‰ï¼‰çš„ç¨‹åºï¼Œæ˜¯ä¸€ä¸ªå¥½çš„æµ‹è¯•æ¡ˆä¾‹ã€‚

## ä¸€ã€Bytecode?

In engineering, few choices are without trade-offs. To best understand why weâ€™re going with bytecode, letâ€™s stack it up against a couple of alternatives.

åœ¨å·¥ç¨‹é¢†åŸŸï¼Œå¾ˆå°‘æœ‰é€‰æ‹©ï¼Œå¯ä»¥ä¸ç»è¿‡æƒè¡¡ï¼Œä¸ºäº†æ›´å¥½çš„ç†è§£æˆ‘ä»¬ä¸ºä»€ä¹ˆé€‰æ‹©å­—èŠ‚ç ï¼Œè®©æˆ‘ä»¬æŠŠå®ƒå’Œä¸€äº›æ›¿ä»£æ–¹æ¡ˆè¿›è¡Œæ¯”è¾ƒã€‚



### 1.1 Why not walk the AST?

Our existing interpreter has a couple of things going for it:

* Well, first, we already wrote it. Itâ€™s done. And the main reason itâ€™s done is because this style of interpreter is really simple to implement. The runtime representation of the code directly maps to the syntax. Itâ€™s virtually effortless to get from the parser to the data structures we need at runtime.

* Itâ€™s portable. Our current interpreter is written in Java and runs on any platform Java supports. We could write a new implementation in C using the same approach and compile and run our language on basically every platform under the sun.

æˆ‘ä»¬ç°æœ‰çš„è§£é‡Šå™¨æœ‰ä¸€äº›ä¼˜ç‚¹ï¼š

* é¦–å…ˆï¼Œæˆ‘ä»¬ç¼–å†™äº†å®ƒï¼Œå®ƒå·²ç»èƒ½ä½¿ç”¨äº†ã€‚è¿™ä¸ªè§£é‡Šå™¨ä¹‹æ‰€ä»¥èƒ½å®Œæˆï¼Œä¸»è¦æ˜¯å› ä¸ºè¿™ç§è§£é‡Šå™¨çš„å®ç°éå¸¸ç®€å•ã€‚ä»£ç çš„è¿è¡Œæ—¶è¡¨ç¤ºç›´æ¥æ˜ å°„åˆ°è¯­æ³•ï¼Œä»è§£é‡Šå™¨åˆ°æˆ‘ä»¬åœ¨è¿è¡Œæ—¶æ‰€éœ€çš„æ•°æ®ç»“æ„ï¼Œå‡ ä¹æ²¡æœ‰ä»€ä¹ˆéš¾åº¦ã€‚

* å®ƒæ˜¯å¯ç§»æ¤çš„ï¼Œæˆ‘ä»¬å½“å‰çš„è§£é‡Šå™¨æ˜¯ç”¨Javaç¼–å†™çš„ï¼Œå¯ä»¥åœ¨Javaæ”¯æŒçš„ä»»ä½•å¹³å°ä¸Šè¿è¡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸åŒçš„æ–¹æ³•åœ¨Cä¸­ç¼–å†™ä¸€ä¸ªæ–°çš„å®ç°ï¼Œå¹¶ä¸”åœ¨å‡ ä¹æ‰€æœ‰å¹³å°ä¸Šç¼–è¯‘å’Œè¿è¡Œæˆ‘ä»¬çš„è¯­è¨€ã€‚

Those are real advantages. But, on the other hand, itâ€™s not memory-efficient. Each piece of syntax becomes an AST node. A tiny Lox expression like 1 + 2 turns into a slew of objects with lots of pointers between them, something like:

è¿™äº›çš„ç¡®æ˜¯çœŸæ­£çš„ä¼˜ç‚¹ï¼Œä½†æ˜¯ï¼Œå¦ä¸€æ–¹é¢ï¼Œå®ƒå¹¶ä¸æ˜¯å†…å­˜æ•ˆç‡é«˜çš„å®ç°æ–¹å¼ï¼Œæ¯ä¸ªè¯­æ³•ç‰‡æ®µéƒ½å˜æˆäº†ä¸€ä¸ªAST èŠ‚ç‚¹ï¼Œä¸€ä¸ªå°å°çš„Loxè¡¨è¾¾å¼ï¼Œä¾‹å¦‚: 1+2 å°±ä¼šå˜ä¸ºä¸€å †å¯¹è±¡ï¼Œå®ƒä»¬ä¹‹é—´æœ‰å¾ˆå¤šæŒ‡é’ˆï¼Œå¤§æ¦‚æ˜¯è¿™æ ·çš„ï¼Œ

![ast](https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/ast1.png?raw=true)

> The â€œ(header)â€ parts are the bookkeeping information the Java virtual machine uses to support memory management and store the objectâ€™s type. Those take up space too!
> 
> header éƒ¨åˆ†æ˜¯Java è™šæ‹Ÿæœºç”¨äºæ”¯æŒå†…å­˜ç®¡ç†å’Œå­˜å‚¨å¯¹è±¡ç±»å‹çš„è®°å½•ä¿¡æ¯ï¼Œè¿™äº›ä¹Ÿä¼šå ç”¨ç©ºé—´ï¼



Each of those pointers adds an extra 32 or 64 bits of overhead to the object. Worse, sprinkling our data across the heap in a loosely connected web of objects does bad things for spatial locality.

æ¯ä¸ªæŒ‡é’ˆéƒ½ä¼šç»™å¯¹è±¡å¢åŠ é¢å¤–çš„32ä½ æˆ–è€… 64ä½çš„å¼€é”€ï¼Œæ›´ç³Ÿç³•çš„æ˜¯ï¼Œå°†æˆ‘ä»¬çš„æ•°æ®æ•£å¸ƒåˆ°å †ä¸­ï¼Œå½¢æˆæ¾æ•£é“¾æ¥çš„å¯¹è±¡ç½‘ç»œï¼Œå¯¹ç©ºé—´å±€éƒ¨æ€§äº§ç”Ÿä¸è‰¯å½±å“ã€‚

> I wrote an entire chapter about this exact problem in my first book, Game Programming Patterns, if you want to really dig in.
> 
> å¦‚æœä½ æƒ³è¦æ·±å…¥äº†è§£è¿™ä¸ªé—®é¢˜ï¼Œå¯ä»¥åœ¨æˆ‘å†™çš„ç¬¬ä¸€æœ¬ä¹¦ã€Šæ¸¸æˆç¼–ç¨‹æ¨¡å¼ã€‹ä¸­å‘ç°æ›´å¤šçš„è§£é‡Šã€‚

Modern CPUs process data way faster than they can pull it from RAM. To compensate for that, chips have multiple layers of caching. If a piece of memory it needs is already in the cache, it can be loaded more quickly. Weâ€™re talking upwards of 100 times faster.

How does data get into that cache? The machine speculatively stuffs things in there for you. Its heuristic is pretty simple. Whenever the CPU reads a bit of data from RAM, it pulls in a whole little bundle of adjacent bytes and stuffs them in the cache.

If our program next requests some data close enough to be inside that cache line, our CPU runs like a well-oiled conveyor belt in a factory. We really want to take advantage of this. To use the cache effectively, the way we represent code in memory should be dense and ordered like itâ€™s read.

Now look up at that tree. Those sub-objects could be anywhere. Every step the tree-walker takes where it follows a reference to a child node may step outside the bounds of the cache and force the CPU to stall until a new lump of data can be slurped in from RAM. Just the overhead of those tree nodes with all of their pointer fields and object headers tends to push objects away from each other and out of the cache.

Our AST walker has other overhead too around interface dispatch and the Visitor pattern, but the locality issues alone are enough to justify a better code representation.

ç°ä»£CPU å¤„ç†æ•°æ®çš„é€Ÿåº¦ï¼Œè¿œå¿«äºä»RAM ä¸­è¯»å–æ•°æ®çš„é€Ÿåº¦ï¼Œä¸ºäº†å¼¥è¡¥è¿™ä¸€ç‚¹ï¼ŒèŠ¯ç‰‡ä¸­æœ‰å¤šçº§ç¼“å­˜ï¼Œå¦‚æœå®ƒéœ€è¦çš„ä¸€å—å†…å­˜å·²ç»å­˜åœ¨äºå¤šçº§ç¼“å­˜ä¸­ï¼Œé‚£ä¹ˆå®ƒå¯ä»¥æ›´å¿«çš„åŠ è½½æ•°æ®ï¼Œè¿™ä¸ªé€Ÿåº¦å¯ä»¥å¿«äº†100å€ã€‚

æ•°æ®æ˜¯å¦‚ä½•è¿›å…¥ç¼“å­˜ä¸­çš„å‘¢ï¼Ÿæœºå™¨ä¼šè‡ªåŠ¨å°†æ•°æ®æ”¾å…¥ç¼“å­˜ï¼Œå®ƒçš„ç®—æ³•éå¸¸ç®€å•ï¼Œæ¯å½“CPU è¯»å–RAMçš„ä¸€äº›æ•°æ®æ—¶å€™ï¼Œå®ƒä¼šå°†ç›¸é‚»çš„ä¸€ç»„å­—èŠ‚ä¸€èµ·æ‹‰å…¥åˆ°ç¼“å­˜ä¸­ã€‚

å¦‚æœæˆ‘ä»¬çš„ç¨‹åºæ¥ä¸‹æ¥è¯·æ±‚çš„æ•°æ®æ¥è¿‘ç¼“å­˜è¡Œï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„CPUå°±ä¼šåƒå·¥å‚é‡Œé¢çš„ä¼ é€å¸¦ä¸€æ ·å¹³æ»‘çš„è¿è¡Œã€‚æˆ‘ä»¬çœŸçš„æƒ³è¦åˆ©ç”¨è¿™ä¸€ç‚¹ï¼Œä¸ºäº†æœ‰æ•ˆçš„åˆ©ç”¨ç¼“å­˜ï¼Œæˆ‘ä»¬åœ¨å†…å­˜ä¸­è¡¨ç¤ºä»£ç çš„æ–¹å¼åº”è¯¥æ˜¯å¯†é›†æœ‰åºçš„ã€‚

ç°åœ¨çœ‹çœ‹ä¸Šé¢çš„é‚£æ£µæ ‘ï¼Œè¿™äº›å­å¯¹è±¡å¯èƒ½åœ¨ä»»ä½•åœ°æ–¹ï¼Œæ¯ä¸€æ¬¡éå†è¯­æ³•æ ‘æ‰§è¡Œæ“ä½œæ—¶å€™ï¼Œéƒ½æœ‰å¯èƒ½è¶…è¿‡ç¼“å­˜çš„è¾¹ç•Œï¼Œè¿«ä½¿CPUåœé¡¿ï¼Œä¸€ç›´åˆ°å¯ä»¥ä»RAMä¸­è¯»å–æ–°çš„æ•°æ®ã€‚è¿™äº›è¯­æ³•æ ‘èŠ‚ç‚¹çš„å¼€é”€ï¼ŒåŒ…æ‹¬å®ƒä»¬æ‰€æœ‰çš„æŒ‡é’ˆå­—æ®µå’Œå¯¹è±¡å¤´ï¼Œå¾€å¾€ä¼šå°†å¯¹è±¡æ¨è¿œå¹¶å°†å®ƒä»¬ç§»å‡ºç¼“å­˜ã€‚

æˆ‘ä»¬çš„ASTéå†è¿˜æœ‰å…¶ä»–å¼€é”€ï¼Œæ¯”å¦‚: æ¥å£è°ƒç”¨å’Œè®¿é—®è€…æ¨¡å¼ï¼Œä½†æ˜¯ï¼Œä»…ä»…å±€éƒ¨æ€§é—®é¢˜ï¼Œå°±è¶³ä»¥éœ€è¦æˆ‘ä»¬æ›´å¥½çš„ä»£ç è¡¨è¾¾æ–¹å¼ã€‚

> Even if the objects happened to be allocated in sequential memory when the parser first produced them, after a couple of rounds of garbage collectionâ€”which may move objects around in memoryâ€”thereâ€™s no telling where theyâ€™ll be.
> 
> å³ä½¿å¯¹è±¡åœ¨è§£é‡Šå™¨ç¬¬ä¸€æ¬¡ç”Ÿæˆæ—¶å€™ï¼Œæ˜¯æŒ‰ç…§é¡ºåºåˆ†é…çš„ï¼Œç»è¿‡å‡ è½®åƒåœ¾å›æ”¶åï¼ˆå¯èƒ½ä¼šç§»åŠ¨å†…å­˜ä¸­çš„å¯¹è±¡ï¼‰ï¼Œæˆ‘ä»¬æ— æ³•ç¡®å®šå®ƒä¼šè¢«ç§»åŠ¨åˆ°å“ªé‡Œã€‚

### 1.2 Why not compile to native code?

If you want to go real fast, you want to get all of those layers of indirection out of the way. Right down to the metal. Machine code. It even sounds fast. Machine code.

Compiling directly to the native instruction set the chip supports is what the fastest languages do. Targeting native code has been the most efficient option since way back in the early days when engineers actually handwrote programs in machine code.

å¦‚æœä½ æƒ³è¦çœŸæ­£å¿«é€Ÿï¼Œä½ éœ€è¦æ‘†è„±æ‰€æœ‰çš„é—´æ¥å±‚çº§ã€‚ç›´æ¥åˆ°æœºå™¨å±‚é¢ï¼Œæœºå™¨ç ã€‚å®ƒç”šè‡³å¬èµ·æ¥å°±å¾ˆå¿« ğŸ˜„

ç›´æ¥ç¼–è¯‘ä¸ºèŠ¯ç‰‡æ”¯æŒçš„æœ¬åœ°æŒ‡ä»¤é›†æ˜¯æœ€å¿«çš„è¯­è¨€æ‰€åšçš„ï¼Œè‡ªä»æ—©æœŸå·¥ç¨‹å¸ˆæ‰‹å†™æœºå™¨ç ä»¥æ¥ï¼Œé’ˆå¯¹æœ¬åœ°ä»£ç ä¸€ç›´æ˜¯æœ€æœ‰æ•ˆçš„é€‰æ‹©ã€‚

If youâ€™ve never written any machine code, or its slightly more human-palatable cousin assembly code before, Iâ€™ll give you the gentlest of introductions. Native code is a dense series of operations, encoded directly in binary. Each instruction is between one and a few bytes long, and is almost mind-numbingly low level. â€œMove a value from this address to this register.â€ â€œAdd the integers in these two registers.â€ Stuff like that.

The CPU cranks through the instructions, decoding and executing each one in order. There is no tree structure like our AST, and control flow is handled by jumping from one point in the code directly to another. No indirection, no overhead, no unnecessary skipping around or chasing pointers.

Lightning fast, but that performance comes at a cost. First of all, compiling to native code ainâ€™t easy. Most chips in wide use today have sprawling Byzantine architectures with heaps of instructions that accreted over decades. They require sophisticated register allocation, pipelining, and instruction scheduling.

And, of course, youâ€™ve thrown portability out. Spend a few years mastering some architecture and that still only gets you onto one of the several popular instruction sets out there. To get your language on all of them, you need to learn all of their instruction sets and write a separate back end for each one.

å¦‚æœä½ ä»¥å‰æ²¡æœ‰å†™è¿‡ä»»ä½•æœºå™¨ç æˆ–è€…ç¨å¾®å®¹æ˜“ç†è§£çš„æ±‡ç¼–ä»£ç ï¼Œæˆ‘ä¼šç»™ä½ ä¸€ä¸ªæœ€æ¸©å’Œçš„ä»‹ç»ï¼Œæœ¬åœ°ä»£ç æ˜¯ä¸€ç³»åˆ—ç›´æ¥ç¼–ç ä¸ºäºŒè¿›åˆ¶çš„æ“ä½œï¼Œæ¯æ¡æŒ‡ä»¤çš„é•¿åº¦æ˜¯1ä¸ªæˆ–è€…å‡ ä¸ªå­—èŠ‚ä¹‹é—´ï¼Œå‡ ä¹è®©äººæ„ŸåŠ¨æ— èŠçš„ä½çº§ã€‚æ¯”å¦‚ï¼šå°†ä¸€ä¸ªå€¼ä»è¿™ä¸ªåœ°å€ç§»åŠ¨åˆ°è¿™ä¸ªå¯„å­˜å™¨ã€‚å°†ä¸¤ä¸ªå¯„å­˜å™¨ä¸­çš„å€¼ç›¸åŠ ï¼Œç±»ä¼¼è¿™æ ·çš„æ“çºµã€‚

CPUè¿è¡Œè¿™äº›æŒ‡ä»¤ï¼ŒæŒ‰ç…§é¡ºåºè§£ç å’Œæ‰§è¡Œå®ƒä»¬ï¼Œæ²¡æœ‰åƒä¹‹å‰æåˆ°çš„è¯­æ³•æ ‘ç»“æ„ï¼Œæ§åˆ¶æµç›´æ¥ä»ä»£ç ä¸­çš„ä¸€ä¸ªç‚¹è·³è½¬åˆ°å¦ä¸€ä¸ªç‚¹æ¥å¤„ç†ã€‚æ²¡æœ‰é—´æ¥å¯»å€ï¼Œæ²¡æœ‰å¼€é”€ï¼Œæ²¡æœ‰ä¸å¿…è¦çš„è·³è·ƒï¼Œæˆ–è€…æŒ‡é’ˆè¿½è¸ªã€‚

è¿è¡Œé€Ÿåº¦éå¸¸å¿«ï¼Œä½†æ˜¯è¿™ç§æ€§èƒ½æ˜¯æœ‰ä»£ä»·çš„ã€‚é¦–å…ˆï¼Œç¼–è¯‘ä¸ºæœºå™¨ç å¹¶ä¸å®¹æ˜“ï¼Œä»Šå¤©å¹¿æ³›ä½¿ç”¨çš„å¤§å¤šæ•°èŠ¯ç‰‡ï¼Œéƒ½æœ‰åºå¤§çš„æ‹œå åº­å¼ç»“æ„ï¼Œæœ‰æ•°åå¹´çš„æŒ‡ä»¤é›†ç§¯ç´¯ã€‚å®ƒä»¬éœ€è¦å¤æ‚çš„å¯„å­˜å™¨åˆ†é…ã€æµæ°´çº¿å’ŒæŒ‡ä»¤è°ƒåº¦ã€‚

å½“ç„¶ï¼Œä½ ä¹Ÿæ”¾å¼ƒäº†å¯ç§»æ¤æ€§ã€‚èŠ±è´¹å‡ å¹´æ—¶é—´æŒæ¡æŸä¸ªä½“ç³»ç»“æ„ï¼Œä»ç„¶åªèƒ½è®©ä½ ä½¿ç”¨å‡ ç§æµè¡Œçš„æŒ‡ä»¤é›†ä¸­çš„ä¸€ç§ã€‚è¦åœ¨æ‰€æœ‰çš„æŒ‡ä»¤é›†ä¸Šè¿è¡Œä½ çš„è¯­è¨€ï¼Œä½ éœ€è¦å­¦ä¹ æ‰€æœ‰çš„æŒ‡ä»¤é›†å¹¶ä¸”ä¸ºæ¯ä¸ªæŒ‡ä»¤é›†ç¼–å†™ä¸€ä¸ªå•ç‹¬çš„åç«¯ã€‚

> Yes, they actually wrote machine code by hand. On punched cards. Which, presumably, they punched with their fists.
> 
> æ˜¯çš„ï¼Œä»–ä»¬å®é™…ä¸Šæ˜¯æ‰‹å†™æœºå™¨ç ï¼Œåœ¨æ‰“å­”å¡ä¸Šï¼Œæˆ‘æƒ³ä»–ä»¬å¯èƒ½æ˜¯ç”¨æ‹³å¤´æ‰“å­”çš„å§ ğŸ˜ 

> The situation isnâ€™t entirely dire. A well-architected compiler lets you share the front end and most of the middle layer optimization passes across the different architectures you support. Itâ€™s mainly the code generation and some of the details around instruction selection that youâ€™ll need to write afresh each time.
>
> The LLVM project gives you some of this out of the box. If your compiler outputs LLVMâ€™s own special intermediate language, LLVM in turn compiles that to native code for a plethora of architectures.
> 
> æƒ…å†µå¹¶éå®Œå…¨ç»æœ›ï¼Œä¸€ä¸ªè‰¯å¥½è®¾è®¡çš„ç¼–è¯‘å™¨å¯ä»¥è®©ä½ åœ¨ï¼Œæ”¯æŒçš„ä¸åŒä½“ç³»ç»“æ„ä¹‹é—´å…±äº«å‰ç«¯å’Œå¤§å¤šæ•°ä¸­é—´å±‚ä¼˜åŒ–å¤„ç†ã€‚ä¸»è¦æ˜¯ï¼Œä»£ç ç”Ÿæˆå’Œä¸€äº›å…³äºæŒ‡ä»¤é€‰æ‹©çš„ç»†èŠ‚éœ€è¦æ¯æ¬¡é‡æ–°ç¼–å†™ã€‚
>
> [LLVM é¡¹ç›®](https://llvm.org/)å¯ä»¥ä¸ºä½ æä¾›ä¸€äº›è¿™æ–¹é¢çš„æ”¯æŒï¼Œå¦‚æœä½ çš„ç¼–è¯‘å™¨è¾“å‡ºLLVM çš„ç‰¹æ®Šä¸­é—´è¯­è¨€ï¼ŒLLVMå¯ä»¥å°†å…¶ç¼–è¯‘ä¸ºä¼—å¤šä½“ç³»ç»“æ„çš„æœºå™¨ç ã€‚


### 1.3 What is bytecode?

Fix those two points in your mind. On one end, a tree-walk interpreter is simple, portable, and slow. On the other, native code is complex and platform-specific but fast. Bytecode sits in the middle. It retains the portability of a tree-walkerâ€”we wonâ€™t be getting our hands dirty with assembly code in this book. It sacrifices some simplicity to get a performance boost in return, though not as fast as going fully native.

è¯·è®°ä½è¿™ä¸¤ä¸ªè§‚ç‚¹ï¼Œ

* ä¸€æ–¹é¢ï¼Œè¯­æ³•æ ‘éå†æ–¹å¼çš„è§£é‡Šå™¨ç®€å•ã€å¯ç§»æ¤ï¼Œä½†æ˜¯è¿è¡Œé€Ÿåº¦æ…¢

* å¦ä¸€æ–¹é¢ï¼Œç¼–è¯‘ä¸ºæœºå™¨ç æ–¹å¼ï¼Œå¤æ‚ã€ä¸å¹³å°æœ‰å…³ï¼Œä½†æ˜¯è¿è¡Œé€Ÿåº¦å¿«

å­—èŠ‚ç å¤„äºä¸¤è€…ä¹‹é—´ã€‚

å®ƒä¿ç•™äº†ç¬¬ä¸€ç§æ–¹å¼çš„å¯ç§»æ¤æ€§â€”â€”åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šæ¶‰åŠåˆ°æ±‡ç¼–ä»£ç ã€‚ä½†æ˜¯ï¼Œå®ƒä¹Ÿç‰ºç‰²äº†ä¸€äº›ç®€å•æ€§ï¼Œæ¢å–æ€§èƒ½æå‡ï¼Œå°½ç®¡ä¸å¦‚å®Œå…¨çš„æœºå™¨ç é‚£ä¹ˆå¿«ã€‚

Structurally, bytecode resembles machine code. Itâ€™s a dense, linear sequence of binary instructions. That keeps overhead low and plays nice with the cache. However, itâ€™s a much simpler, higher-level instruction set than any real chip out there. (In many bytecode formats, each instruction is only a single byte long, hence â€œbytecodeâ€.)

Imagine youâ€™re writing a native compiler from some source language and youâ€™re given carte blanche to define the easiest possible architecture to target. Bytecode is kind of like that. Itâ€™s an idealized fantasy instruction set that makes your life as the compiler writer easier.

åœ¨ç»“æ„ä¸Šï¼Œå­—èŠ‚ç ç±»ä¼¼äºæœºå™¨ç ã€‚å®ƒæ˜¯ä¸€ä¸ªå¯†é›†çš„ã€çº¿æ€§çš„äºŒè¿›åˆ¶æŒ‡ä»¤åºåˆ—ã€‚è¿™ä½¿å¾—å¼€é”€æ¯”è¾ƒä½ï¼Œèƒ½å¤Ÿå¾ˆå¥½çš„å’Œç¼“å­˜é…åˆã€‚ç„¶è€Œï¼Œå®ƒæ¯”ä»»ä½•çœŸå®èŠ¯ç‰‡ä¸Šçš„æŒ‡ä»¤é›†è¦ç®€ç­”å¾ˆå¤šï¼Œå±äºæ›´é«˜å±‚æ¬¡çš„æŒ‡ä»¤é›†ã€‚ï¼ˆåœ¨å¾ˆå¤šå­—èŠ‚ç æ ¼å¼ä¸­ï¼Œæ¯ä¸ªæŒ‡ä»¤åªæœ‰ä¸€ä¸ªå­—èŠ‚é•¿ï¼Œå› æ­¤ç§°ä¸ºå­—èŠ‚ç ï¼‰

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ­£åœ¨ä»æºè¯­è¨€ç¼–å†™ä¸€ä¸ªæœºå™¨ç ç¼–è¯‘å™¨ï¼Œä½ è¢«æˆæƒå®šä¹‰ä¸€ä¸ªæœ€ç®€å•çš„æ¶æ„ï¼Œå­—èŠ‚ç å°±æœ‰ç‚¹åƒæ˜¯è¿™æ ·ï¼Œå®ƒæ˜¯ä¸€ä¸ªç†æƒ³åŒ–çš„å‡æƒ³çš„æŒ‡ä»¤é›†ï¼Œä½¿å¾—ï¼Œæˆ‘ä»¬ç¼–å†™ç¼–è¯‘å™¨æ›´åŠ å®¹æ˜“ã€‚

The problem with a fantasy architecture, of course, is that it doesnâ€™t exist. We solve that by writing an emulatorâ€”a simulated chip written in software that interprets the bytecode one instruction at a time. A virtual machine (VM), if you will.

That emulation layer adds overhead, which is a key reason bytecode is slower than native code. But in return, it gives us portability. Write our VM in a language like C that is already supported on all the machines we care about, and we can run our emulator on top of any hardware we like.

å½“ç„¶ï¼Œå‡æƒ³çš„æ¶æ„çš„é—®é¢˜æ˜¯å®ƒå¹¶ä¸å­˜åœ¨ï¼Œæˆ‘ä»¬é€šè¿‡ç¼–å†™æ¨¡æ‹Ÿå™¨â€”â€”ä¸€ç§ä»¥è½¯ä»¶å½¢å¼ç¼–å†™çš„æ¨¡æ‹ŸèŠ¯ç‰‡ï¼Œé€æ¡è§£é‡Šå­—èŠ‚ç æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸€ä¸ªè™šæ‹Ÿæœº VMï¼Œå¦‚æœæˆ‘ä»¬è¦ç§°å‘¼å®ƒã€‚

è¿™ä¸ªä»¿çœŸå±‚å¢åŠ äº†ä¸€äº›å¼€é”€ï¼Œè¿™ä¹Ÿæ˜¯å­—èŠ‚ç æ¯”æœºå™¨ç æ…¢çš„ä¸€ä¸ªé‡è¦åŸå› ï¼Œä½†æ˜¯ï¼Œä½œä¸ºå›æŠ¥ï¼Œå®ƒç»™äº†æˆ‘ä»¬å¯ç§»æ¤æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨ç±»ä¼¼C çš„è¯­è¨€ç¼–å†™VMï¼Œè€Œè¿™åœ¨æ‰€æœ‰çš„æœºå™¨ä¸Šéƒ½æ˜¯æ”¯æŒçš„ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä»»ä½•æˆ‘ä»¬å–œæ¬¢çš„ç¡¬ä»¶ä¸Šï¼Œè¿è¡Œæˆ‘ä»¬çš„æ¨¡æ‹Ÿå™¨ã€‚

This is the path weâ€™ll take with our new interpreter, clox. Weâ€™ll follow in the footsteps of the main implementations of Python, Ruby, Lua, OCaml, Erlang, and others. In many ways, our VMâ€™s design will parallel the structure of our previous interpreter:

![phrases](https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/phases.png?raw=true)

Of course, we wonâ€™t implement the phases strictly in order. Like our previous interpreter, weâ€™ll bounce around, building up the implementation one language feature at a time. In this chapter, weâ€™ll get the skeleton of the application in place and create the data structures needed to store and represent a chunk of bytecode.

è¿™å°±æ˜¯æˆ‘ä»¬æ–°çš„è§£é‡Šå™¨ cloxï¼Œæ‰€è¦ä½¿ç”¨çš„è·¯å¾„ã€‚æˆ‘ä»¬å°†è·Ÿéšç€ Pythonã€Rubyã€Luaã€OCamlã€Erlangå’Œå…¶ä»–è¯­è¨€çš„å®ç°æ–¹å¼ã€‚åœ¨å¾ˆå¤šæ–¹é¢ï¼Œæˆ‘ä»¬çš„è™šæ‹Ÿæœºè®¾è®¡å°†ä¸æˆ‘ä»¬ä¹‹å‰çš„è§£é‡Šå™¨ç»“æ„ç›¸å¯¹åº”ã€‚

å½“ç„¶ï¼Œæˆ‘ä»¬ä¸ä¼šæŒ‰ç…§é¡ºåºä¸¥æ ¼å®ç°å„ä¸ªé˜¶æ®µã€‚å°±åƒæ˜¯ä»¥å‰çš„è§£é‡Šå™¨ä¸€æ ·ï¼Œæˆ‘ä»¬å°†è·³è½¬ï¼Œæœ€ç»ˆå®ç°ä¸€ä¸ªè§£é‡Šå™¨ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†è·å–è¯¥è§£é‡Šå™¨çš„æ¶æ„ï¼Œå¹¶ä¸”åˆ›å»ºæ•°æ®ç»“æ„ï¼Œè¯¥ç»“æ„å­˜å‚¨ç€å­—èŠ‚ç ã€‚

> One of the first bytecode formats was [p-code](https://en.wikipedia.org/wiki/P-code_machine), developed for Niklaus Wirthâ€™s Pascal language. You might think a PDP-11 running at 15MHz couldnâ€™t afford the overhead of emulating a virtual machine. But back then, computers were in their Cambrian explosion and new architectures appeared every day. Keeping up with the latest chips was worth more than squeezing the maximum performance from each one. Thatâ€™s why the â€œpâ€ in p-code doesnâ€™t stand for â€œPascalâ€, but â€œportableâ€.
> 
> æœ€æ—©çš„ä¸€ç§å­—èŠ‚ç æ˜¯ï¼ŒNiklaus Wirth ä¸ºPascalè¯­è¨€å¼€å‘çš„ p-code. ä½ å¯èƒ½ä¼šè®¤ä¸ºï¼ŒPDP-11 ä»¥15MHz çš„è¿è¡Œé¢‘ç‡æ— æ³•æ‰¿å—ä¸€ä¸ªè™šæ‹Ÿæœºçš„è¿è¡Œã€‚ä½†å½“æ—¶ï¼Œè®¡ç®—æœºæ­£å¤„äºå¯’æ­¦çºªçˆ†å‘æœŸï¼Œæ¯å¤©éƒ½ä¼šå‡ºç°æ–°çš„ä½“ç³»ç»“æ„ã€‚è·Ÿä¸Šæœ€æ–°èŠ¯ç‰‡çš„æ­¥ä¼ï¼Œæ€»æ¯”ä»æ¯ç§èŠ¯ç‰‡ä¸­æŒ¤å‡ºæ›´å¤§çš„æ€§èƒ½æ›´å€¼å¾—ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆï¼Œp-codeä¸­çš„p è¡¨ç¤ºä¸º protableï¼ˆå¯ç§»æ¤æ€§ï¼‰ï¼Œè€Œä¸æ˜¯Pascal çš„åŸå› ã€‚




## äºŒã€Getting Started


Where else to begin, but at main()? Fire up your trusty text editor and start typing.

æ²¡ä»€ä¹ˆæ¯”ä» main() å¼€å§‹æ›´å¥½çš„èµ·ç‚¹äº†å§ï¼Œæ‰“å¼€ç¼–è¾‘å™¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹ç¼–ç¨‹å§

```c

// main.c, create new file

#include "common.h"

int main(int argc, const char* argv[]) {
  return 0;
}

```

> Now is a good time to stretch, maybe crack your knuckles. A little montage music wouldnâ€™t hurt either.
> 
> ç°åœ¨æ˜¯ä¸€ä¸ªå¥½çš„æ—¶æœºï¼Œç¼–å†™æ–°çš„ä»£ç äº†ï¼ŒåŒæ—¶æ’­æ”¾ä¸€äº›éŸ³ä¹æˆ–è®¸æ›´å¥½ï¼

From this tiny seed, we will grow our entire VM. Since C provides us with so little, we first need to spend some time amending the soil. Some of that goes into this header:

ä»è¿™æ£µå¾®å°çš„ç§å­å¼€å§‹ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ•´ä¸ªè™šæ‹Ÿæœºçš„ç¼–å†™ã€‚ç”±äºCè¯­è¨€æä¾›çš„å†…å®¹å¾ˆå°‘ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦èŠ±è´¹ä¸€äº›æ—¶é—´ï¼Œæ”¹å–„ä¸€ä¸‹åœŸå£¤ã€‚å…¶ä¸­ï¼Œä¸€éƒ¨åˆ†å·¥ä½œæ¶‰åŠè¿™ä¸ªå¤´æ–‡ä»¶ã€‚

```c

# common.h, create new file

#ifndef clox_common_h
#define clox_common_h

#include <stdbool.h>
#include <stddef.h>
#include <stdint.h>

#endif

```

There are a handful of types and constants weâ€™ll use throughout the interpreter, and this is a convenient place to put them. For now, itâ€™s the venerable NULL, size_t, the nice C99 Boolean bool, and explicit-sized integer typesâ€”uint8_t and friends.

 åœ¨è§£é‡Šå™¨ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€äº›ç±»å‹å’Œå¸¸é‡ï¼Œå¹¶ä¸”åœ¨common.h ä¸­æ”¾ç½®å®ƒä»¬ã€‚ç›®å‰ï¼Œè¿™äº›åŒ…å« NULLï¼Œsize_t ï¼ŒC99è§„èŒƒä¸­å®šä¹‰çš„å¸ƒå°”ç±»å‹ boolï¼Œä»¥åŠæ˜¾å¼å¤§å°çš„æ•´æ•°ç±»å‹ unit8_t ç­‰
 
## ä¸‰ã€ Chunks of Instructions


Next, we need a module to define our code representation. Iâ€™ve been using â€œchunkâ€ to refer to sequences of bytecode, so letâ€™s make that the official name for that module.

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¨¡å—æ¥å®šä¹‰æˆ‘ä»¬çš„ä»£ç è¡¨ç¤ºå½¢å¼ï¼Œæˆ‘ä¸€ç›´ä½¿ç”¨ chunkæ¥æŒ‡ä»£å­—èŠ‚ç åºåˆ—ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬å°†å…¶ä½œä¸ºæ¨¡å—çš„åç§°ã€‚

```c

// chunk.h, create new file

#ifndef clox_chunk_h
#define clox_chunk_h

#include "common.h"

#endif


```

In our bytecode format, each instruction has a one-byte operation code (universally shortened to opcode). That number controls what kind of instruction weâ€™re dealing withâ€”add, subtract, look up variable, etc. We define those here:

åœ¨æˆ‘ä»¬çš„å­—èŠ‚ç æ ¼å¼ä¸­ï¼Œæ¯ä¸€ä¸ªæŒ‡ä»¤éƒ½æœ‰ä¸€ä¸ªä¸€å­—èŠ‚é•¿åº¦çš„æ“ä½œç ï¼ˆé€šå¸¸ç¼©å†™ä¸ºopcode), è¯¥æ•°å­—æ§åˆ¶æˆ‘ä»¬æ­£åœ¨å¤„ç†çš„æŒ‡ä»¤ç±»å‹â€”â€”åŠ ã€å‡ã€æŸ¥æ‰¾å˜é‡ç­‰ç­‰ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰:

```c

// chunk.h

#include "common.h"

typedef enum {
  OP_RETURN,
} OpCode;

#endif

```

For now, we start with a single instruction, OP_RETURN. When we have a full-featured VM, this instruction will mean â€œreturn from the current functionâ€. I admit this isnâ€™t exactly useful yet, but we have to start somewhere, and this is a particularly simple instruction, for reasons weâ€™ll get to later.

ç›®å‰ï¼Œæˆ‘ä»¬åªæ˜¯ç”¨ä¸€ä¸ªæŒ‡ä»¤ OP_RETURN ,å½“æˆ‘ä»¬æ‹¥æœ‰ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„è™šæ‹Ÿæœºæ—¶å€™ï¼Œè¿™ä¸ªæŒ‡ä»¤å°†æ„å‘³ç€ ä»å½“å‰å‡½æ•°è¿”å›ï¼Œæˆ‘æ‰¿è®¤ç°åœ¨è¿™å¹¶ä¸æ˜¯éå¸¸æœ‰ç”¨ï¼Œä½†æ˜¯æˆ‘ä»¬å¿…é¡»ä»æŸä¸ªåœ°æ–¹å¼€å§‹ï¼Œè€Œè¿™æ˜¯ä¸€ä¸ªç‰¹åˆ«ç®€å•çš„æŒ‡ä»¤ï¼ŒåŸå› ç¨åæˆ‘ä»¬ä¼šè®²åˆ°ã€‚

### 3.1 A dynamic array of instructions

Bytecode is a series of instructions. Eventually, weâ€™ll store some other data along with the instructions, so letâ€™s go ahead and create a struct to hold it all.

å­—èŠ‚ç æ˜¯ä¸€ç³»åˆ—æŒ‡ä»¤ï¼Œæœ€ç»ˆï¼Œæˆ‘ä»¬å°†å­˜å‚¨ä¸€äº›å’ŒæŒ‡ä»¤ä¸€èµ·çš„å…¶ä»–æ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç»“æ„ä½“æ¥ä¿å­˜å®ƒä»¬ã€‚

```c

// chunk.h, add after enum OpCode

} OpCode;

typedef struct {
  uint8_t* code;
} Chunk;

#endif

```


At the moment, this is simply a wrapper around an array of bytes. Since we donâ€™t know how big the array needs to be before we start compiling a chunk, it must be dynamic. Dynamic arrays are one of my favorite data structures. That sounds like claiming vanilla is my favorite ice cream flavor, but hear me out. Dynamic arrays provide:

* Cache-friendly, dense storage

* Constant-time indexed element lookup

* Constant-time appending to the end of the array

> Butter pecan is actually my favorite.
> 
> ç‰›æ²¹å±±æ ¸æ¡ƒå†°æ·‡æ·‹å®é™…ä¸Šæ˜¯æˆ‘çš„æœ€çˆ±

Those features are exactly why we used dynamic arrays all the time in jlox under the guise of Javaâ€™s ArrayList class. Now that weâ€™re in C, we get to roll our own. If youâ€™re rusty on dynamic arrays, the idea is pretty simple. In addition to the array itself, we keep two numbers: the number of elements in the array we have allocated (â€œcapacityâ€) and how many of those allocated entries are actually in use (â€œcountâ€).

ç›®å‰ï¼Œè¿™åªæ˜¯ä¸€ä¸ªåŒ…è£…åœ¨å­—èŠ‚æ•°ç»„å‘¨å›´çš„ç»“æ„ä½“ï¼Œç”±äºåœ¨ç¼–è¯‘å—ä¹‹å‰ï¼Œæˆ‘ä»¬ä¸çŸ¥é“æ•°ç»„æœ‰å¤šå¤§ï¼Œå› æ­¤å®ƒå¿…é¡»æ˜¯åŠ¨æ€çš„ï¼ŒåŠ¨æ€æ•°ç»„æ˜¯æˆ‘æœ€å–œæ¬¢çš„ç»“æ„ä¹‹ä¸€ï¼Œè¿™å¬èµ·æ¥åƒæ˜¯å£°ç§°é¦™è‰æ˜¯æˆ‘æœ€å–œæ¬¢çš„å†°æ·‡æ·‹å£å‘³ï¼Œä½†æ˜¯ï¼Œè¯·å¬æˆ‘è§£é‡Šï¼ŒåŠ¨æ€æ•°ç»„æä¾›äº†: 

* ç¼“å­˜å‹å¥½ï¼Œå¯†é›†çš„å­˜å‚¨æ–¹å¼

* å¸¸æ•°æ—¶é—´çš„ç´¢å¼•å…ƒç´ æŸ¥æ‰¾

* åœ¨åˆ—è¡¨æ·»åŠ å…ƒç´ ï¼Œå¸¸æ•°æ—¶é—´

ç”±äºè¿™äº›ç‰¹å¾ï¼Œæˆ‘ä»¬åœ¨jloxä¸­ä¸€ç›´ä½¿ç”¨Java çš„ ArrayListç±»æ¥ä¼ªè£…åŠ¨æ€æ•°ç»„ï¼Œç°åœ¨åœ¨æˆ‘ä»¬çš„clox ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå·±ç¼–å†™ã€‚å¦‚æœä½ å¯¹åŠ¨æ€æ•°ç»„ä¸å¤ªç†Ÿæ‚‰ï¼Œè¿™ä¸ªæƒ³æ³•ç›¸å½“ç®€å•ï¼Œé™¤äº†æ•°ç»„æœ¬èº«ï¼Œæˆ‘ä»¬è¿˜ä¿ç•™äº†ä¸¤ä¸ªæ•°å­—:

(1) æˆ‘ä»¬å·²ç»åˆ†é…çš„æ•°ç»„å…ƒç´ ä¸ªæ•°ï¼ˆå®¹é‡ï¼‰

(2) å®é™…ä½¿ç”¨çš„åˆ†é…å…ƒç´ çš„æ•°é‡ï¼ˆè®¡æ•°ï¼‰

```c

// chunk.h, in struct Chunk

typedef struct {
  int count;
  int capacity;
  uint8_t* code;
} Chunk;


```


When we add an element, if the count is less than the capacity, then there is already available space in the array. We store the new element right in there and bump the count.

![insert](https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/14_insert.png?raw=true)

å½“æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªå…ƒç´ æ—¶å€™ï¼Œå¦‚æœè®¡æ•°å°äºå®¹é‡ï¼Œé‚£ä¹ˆæ•°ç»„ä¸­ä»ç„¶æœ‰å¯ç”¨çš„ç©ºé—´ã€‚æˆ‘ä»¬å°†æ–°å…ƒç´ ä¿å­˜åœ¨é‚£é‡Œï¼Œå¢åŠ è®¡æ•°

If we have no spare capacity, then the process is a little more involved.


![grow](https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/14_grow.png?raw=true)

1. Allocate a new array with more capacity.

1. Copy the existing elements from the old array to the new one.

1. Store the new capacity.

1. Delete the old array.

1. Update code to point to the new array.

1. Store the element in the new array now that there is room.

1. Update the count.

å¦‚æœæ²¡æœ‰å¤šä½™çš„ç©ºé—´ï¼Œé‚£ä¹ˆè¿™ä¸ªè¿‡ç¨‹ä¼šç¨å¾®å¤æ‚ä¸€ç‚¹ã€‚

1. åˆ†é…ä¸€ä¸ªæœ‰æ›´å¤§å®¹é‡çš„æ–°æ•°ç»„

1. å°†ç°æœ‰æ•°æ®ä»æ—§æ•°ç»„å¤åˆ¶åˆ°æ–°æ•°ç»„

1. å­˜å‚¨æ–°çš„å®¹é‡

1. åˆ é™¤æ—§æ•°ç»„

1. æ›´æ–°ä»£ç æŒ‡å‘æ–°çš„æ•°ç»„

1. ç°åœ¨æœ‰ç©ºé—´äº†ï¼Œå°†æ–°å…ƒç´ ä¿å­˜åˆ°æ–°æ•°ç»„ä¸­

1. æ›´æ–°è®¡æ•°

> Copying the existing elements when you grow the array makes it seem like appending an element is O(n), not O(1) like I said above. However, you need to do this copy step only on some of the appends. Most of the time, there is already extra capacity, so you donâ€™t need to copy.
>
> To understand how this works, we need [amortized analysis](https://en.wikipedia.org/wiki/Amortized_analysis). That shows us that as long as we grow the array by a multiple of its current size, when we average out the cost of a sequence of appends, each append is O(1).
> 
> å½“æˆ‘ä»¬å¢åŠ æ•°ç»„å¤§å°æ—¶å€™ï¼Œå¤åˆ¶æ‰€æœ‰çš„ç°æœ‰å…ƒç´ ä¼¼ä¹ä½¿å¾—æ·»åŠ ä¸€ä¸ªå…ƒç´ çš„æ—¶é—´å¤æ‚åº¦ä¸º \\( O(n) \\), è€Œä¸æ˜¯ä¹‹å‰çš„ \\( O(1) \\), ä½†æ˜¯ï¼Œä½ åªéœ€è¦åœ¨æŸäº›è¿½åŠ æ“ä½œä¸­è¿›è¡Œå¤åˆ¶ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå·²ç»æœ‰äº†é¢å¤–çš„å®¹é‡ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬ä¸éœ€è¦å¤åˆ¶
>
> è¦ç†è§£è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œåˆ†æ‘Šåˆ†æï¼Œè¿™å¯ä»¥å‘Šè¯‰æˆ‘ä»¬ï¼Œåªè¦æˆ‘ä»¬æŠŠæ•°ç»„çš„å¤§å°å¢åŠ åˆ°å½“å‰å¤§å°çš„å€æ•°ï¼Œå½“æˆ‘ä»¬å¹³å‡ä¸€ç³»åˆ—è¿½åŠ æ“ä½œçš„æˆæœ¬æ—¶å€™ï¼Œæ¯ä¸ªè¿½åŠ æ“ä½œéƒ½æ˜¯ \\( O(1) \\)


We have our struct ready, so letâ€™s implement the functions to work with it. C doesnâ€™t have constructors, so we declare a function to initialize a new chunk.

æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†ç»“æ„ä½“ï¼Œæ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®ç°ä¸ä¹‹ä¸€èµ·å·¥ä½œçš„å‡½æ•°ï¼ŒCæ²¡æœ‰æ„é€ å‡½æ•°ï¼Œå› æ­¤æˆ‘ä»¬å£°æ˜ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºåˆå§‹åŒ–ä¸€ä¸ªæ–°çš„ chunk

```C

// chunk.h, add after struct Chunk

} Chunk;

void initChunk(Chunk* chunk);

#endif


```

And implement it thusly:

ç„¶åï¼Œè¿™æ ·å®ç°å®ƒ

```c

// chunk.c, create new file

#include <stdlib.h>

#include "chunk.h"

void initChunk(Chunk* chunk) {
  chunk->count = 0;
  chunk->capacity = 0;
  chunk->code = NULL;
}


```


The dynamic array starts off completely empty. We donâ€™t even allocate a raw array yet. To append a byte to the end of the chunk, we use a new function.

åŠ¨æ€æ•°ç»„ä¸€å¼€å§‹æ˜¯å®Œå…¨ç©ºçš„ï¼Œæˆ‘ä»¬ç”šè‡³éƒ½æ²¡æœ‰åˆ†é…åŸå§‹æ•°ç»„ï¼Œè¦å°†ä¸€ä¸ªå­—èŠ‚è¿½åŠ åˆ°å—çš„æœ«å°¾ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ–°çš„å‡½æ•°

```c

// chunk.h, add after initChunk()

void initChunk(Chunk* chunk);
void writeChunk(Chunk* chunk, uint8_t byte);

#endif

```

This is where the interesting work happens.

æ¥ä¸‹æ¥å°†æ˜¯æœ‰è¶£çš„åœ°æ–¹

```c 

// chunk.c, add after initChunk()

void writeChunk(Chunk* chunk, uint8_t byte) {
  if (chunk->capacity < chunk->count + 1) {
    int oldCapacity = chunk->capacity;
    chunk->capacity = GROW_CAPACITY(oldCapacity);
    chunk->code = GROW_ARRAY(uint8_t, chunk->code,
        oldCapacity, chunk->capacity);
  }

  chunk->code[chunk->count] = byte;
  chunk->count++;
}

```


The first thing we need to do is see if the current array already has capacity for the new byte. If it doesnâ€™t, then we first need to grow the array to make room. (We also hit this case on the very first write when the array is NULL and capacity is 0.)

To grow the array, first we figure out the new capacity and grow the array to that size. Both of those lower-level memory operations are defined in a new module.

æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯ï¼ŒæŸ¥çœ‹å½“å‰æ•°ç»„æ˜¯å¦è¿˜æœ‰æ–°å­—èŠ‚çš„æ·»åŠ ç©ºé—´ï¼Œ

å¦‚æœæ²¡æœ‰ç©ºé—´ï¼Œæˆ‘ä»¬éœ€è¦æ‰©å±•æ•°ç»„ï¼Œè…¾å‡ºç©ºé—´ï¼ˆå½“æ•°ç»„ä¸ºNULLï¼Œå®¹é‡ä¸º0ï¼Œæ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¼šé‡åˆ°è¿™ç§é—®é¢˜ï¼‰

è¦æ‰©å±•æ•°ç»„ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æ–°æ•°ç»„çš„å®¹é‡ï¼Œå°†æ•°ç»„å¤§å°æ‰©å±•åˆ°è¯¥å¤§å°ï¼Œè¿™ä¸¤ä¸ªè¾ƒä½çº§åˆ«çš„å†…å­˜æ“ä½œï¼Œæˆ‘ä»¬å°†åœ¨ä¸€ä¸ªæ–°æ¨¡å—ä¸­å®šä¹‰ã€‚

```c

// chunk.c

#include "chunk.h"
#include "memory.h"

void initChunk(Chunk* chunk) {

```

This is enough to get us started.


```c

// memory.h, create new file

#ifndef clox_memory_h
#define clox_memory_h

#include "common.h"

#define GROW_CAPACITY(capacity) \
    ((capacity) < 8 ? 8 : (capacity) * 2)

#endif


```

This macro calculates a new capacity based on a given current capacity. In order to get the performance we want, the important part is that it scales based on the old size. We grow by a factor of two, which is pretty typical. 1.5Ã— is another common choice.

We also handle when the current capacity is zero. In that case, we jump straight to eight elements instead of starting at one. That avoids a little extra memory churn when the array is very small, at the expense of wasting a few bytes on very small chunks.

è¿™ä¸ªå®æ ¹æ®å½“å‰ç»™å®šçš„å®¹é‡ï¼Œè®¡ç®—ä¸€ä¸ªæ–°å®¹é‡ã€‚ä¸ºäº†å¾—åˆ°æˆ‘ä»¬æƒ³è¦çš„æ€§èƒ½ï¼Œé‡è¦çš„éƒ¨åˆ†æ˜¯å®ƒåŸºäºæ—§å®¹é‡è¿›è¡Œç¼©æ”¾ï¼Œæˆ‘ä»¬æŒ‰ç…§ä¸¤å€å¢é•¿ï¼Œè¿™æ˜¯ç›¸å½“å…¸å‹çš„ï¼Œ1.5å€æ˜¯å¦å¤–ä¸€ä¸ªå¸¸è§çš„é€‰æ‹©ã€‚

æˆ‘ä»¬è¿˜å°†å¤„ç†å½“å‰å®¹é‡ä¸º0çš„åœºæ™¯ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç›´æ¥è·³åˆ°8ä¸ªå…ƒç´ ï¼Œè€Œä¸æ˜¯ä»ä¸€ä¸ªå…ƒç´ å¼€å§‹ï¼Œè¿™é¿å…äº†åœ¨æ•°ç»„éå¸¸å°çš„æƒ…å†µä¸‹ï¼Œå¤šä½™çš„å†…å­˜æ³¢åŠ¨ï¼Œä»£ä»·æ˜¯åœ¨éå¸¸å°çš„å—ä¸Šæµªè´¹äº†ä¸€äº›å­—èŠ‚ã€‚

> I picked the number eight somewhat arbitrarily for the book. Most dynamic array implementations have a minimum threshold like this. The right way to pick a value for this is to profile against real-world usage and see which constant makes the best performance trade-off between extra grows versus wasted space.
> 
> æˆ‘åœ¨æœ¬ä¹¦ä¸­ï¼Œé€‰æ‹©æ•°ç»„æœ€å°é•¿åº¦ä¸º8ï¼Œæœ‰äº›éšæ„ï¼Œå¤§å¤šæ•°çš„åŠ¨æ€æ•°ç»„å®ç°ï¼Œéƒ½æœ‰è¿™æ ·çš„æœ€å°é˜ˆå€¼ã€‚é€‰æ‹©è¿™ä¸ªå€¼çš„æ­£ç¡®æ–¹æ³•æ˜¯é’ˆå¯¹å®é™…ä½¿ç”¨æƒ…å†µè¿›è¡Œåˆ†æï¼Œå¹¶æŸ¥çœ‹å“ªä¸ªå¸¸é‡åœ¨é¢å¤–å¢é•¿å’Œæµªè´¹ç©ºé—´ä¹‹é—´ï¼Œå–å¾—æœ€ä½³æ€§èƒ½å¹³è¡¡ã€‚

Once we know the desired capacity, we create or grow the array to that size using GROW_ARRAY().

ä¸€æ—¦æˆ‘ä»¬çŸ¥é“æ‰€éœ€å®¹é‡çš„å¤§å°ï¼Œæˆ‘ä»¬ä½¿ç”¨GROW_ARRAY() åˆ›å»ºæˆ–è€…å¢é•¿æ•°ç»„åˆ°è¯¥å¤§å°

```c

// memory.h

#define GROW_CAPACITY(capacity) \
    ((capacity) < 8 ? 8 : (capacity) * 2)

#define GROW_ARRAY(type, pointer, oldCount, newCount) \
    (type*)reallocate(pointer, sizeof(type) * (oldCount), \
        sizeof(type) * (newCount))

void* reallocate(void* pointer, size_t oldSize, size_t newSize);

#endif

```

This macro pretties up a function call to reallocate() where the real work happens. The macro itself takes care of getting the size of the arrayâ€™s element type and casting the resulting void* back to a pointer of the right type.

è¿™ä¸ªå®ç¾åŒ–äº†å¯¹ reallocate() å‡½æ•°çš„è°ƒç”¨ï¼Œå®é™…çš„å·¥ä½œå‘ç”Ÿåœ¨è¿™é‡Œã€‚å®æœ¬èº«è´Ÿè´£è·å–æ•°ç»„å…ƒç´ ç±»å‹çš„å¤§å°å¹¶å°†ç»“æœ void* å¼ºåˆ¶è½¬åŒ–ä¸ºæ­£ç¡®ç±»å‹çš„æŒ‡é’ˆã€‚

This reallocate() function is the single function weâ€™ll use for all dynamic memory management in cloxâ€”allocating memory, freeing it, and changing the size of an existing allocation. Routing all of those operations through a single function will be important later when we add a garbage collector that needs to keep track of how much memory is in use.

The two size arguments passed to reallocate() control which operation to perform:

|oldSize|	newSize|	Operation|
|---|---|---|
|0	|Nonâ€‘zero	|Allocate new block.|
|Nonâ€‘zero|	0	|Free allocation.|
|Nonâ€‘zero|	Smaller than oldSize|	Shrink existing allocation.|
|Nonâ€‘zero|	Larger than oldSize|	Grow existing allocation.|


è¿™ä¸ªreallocate å‡½æ•°æ˜¯æˆ‘ä»¬åœ¨clox ä¸­ç”¨äºæ‰€æœ‰åŠ¨æ€å†…å­˜ç®¡ç†çš„å”¯ä¸€å‡½æ•°â€”â€”åˆ†é…å†…å­˜ã€é‡Šæ”¾å®ƒã€æ›´æ”¹ç°æœ‰åˆ†é…çš„å¤§å°ã€‚å°†æ‰€æœ‰è¿™äº›æ“ä½œè·¯ç”±åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œåœ¨ç¨åæ·»åŠ éœ€è¦è·Ÿè¸ªä½¿ç”¨å¤šå°‘å†…å­˜çš„åƒåœ¾å›æ”¶å™¨æ—¶ï¼Œå°†éå¸¸é‡è¦ã€‚

ä¼ é€’ç»™reallocate() çš„ä¸¤ä¸ªå‚æ•°æ§åˆ¶å°†è¦æ‰§è¡Œçš„æ“ä½œ





|æ—§çš„size| æ–°çš„size| æ“ä½œ|
|---|---|---|
|0| é0| åˆ†é…æ–°å—|
|é0|0| é‡Šæ”¾å—|
|é0| æ–°çš„size < æ—§çš„size|ç¼©å°ç°æœ‰çš„åˆ†é…|
|é0| æ–°çš„size > æ—§çš„size|å¢åŠ ç°æœ‰åˆ†é…|


That sounds like a lot of cases to handle, but hereâ€™s the implementation:

å¬èµ·æ¥ï¼Œå¥½åƒè¦å¤„ç†å¾ˆå¤šçš„åœºæ™¯ï¼Œä½†è¿™æ˜¯å®ç°

```c

// memory.c, create new file


#include <stdlib.h>

#include "memory.h"

void* reallocate(void* pointer, size_t oldSize, size_t newSize) {
  if (newSize == 0) {
    free(pointer);
    return NULL;
  }

  void* result = realloc(pointer, newSize);
  return result;
}


```

When newSize is zero, we handle the deallocation case ourselves by calling free(). Otherwise, we rely on the C standard libraryâ€™s realloc() function. That function conveniently supports the other three aspects of our policy. When oldSize is zero, realloc() is equivalent to calling malloc().

The interesting cases are when both oldSize and newSize are not zero. Those tell realloc() to resize the previously allocated block. If the new size is smaller than the existing block of memory, it simply updates the size of the block and returns the same pointer you gave it. If the new size is larger, it attempts to grow the existing block of memory.

It can do that only if the memory after that block isnâ€™t already in use. If there isnâ€™t room to grow the block, realloc() instead allocates a new block of memory of the desired size, copies over the old bytes, frees the old block, and then returns a pointer to the new block. Remember, thatâ€™s exactly the behavior we want for our dynamic array.

Because computers are finite lumps of matter and not the perfect mathematical abstractions computer science theory would have us believe, allocation can fail if there isnâ€™t enough memory and realloc() will return NULL. We should handle that.

å½“newSizeä¸º0æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨free() é‡Šæ”¾ç©ºé—´ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬å°†ä¾èµ–Cæ ‡å‡†åº“çš„ realloc() å‡½æ•°ã€‚è¯¥å‡½æ•°å¾ˆæ–¹ä¾¿çš„æ”¯æŒæˆ‘ä»¬çš„å¦å¤–ä¸‰ç§æƒ…å†µã€‚å½“oldSize ä¸º0æ—¶ï¼Œ realloc() ç­‰æ•ˆäº malloc()

æœ‰è¶£çš„åœºæ™¯æ˜¯ newSize å’Œ oldSize éƒ½ä¸ç­‰äº0æ—¶ï¼Œè¿™å‘Šè¯‰ realloc() è°ƒæ•´å…ˆå‰åˆ†é…å—çš„å¤§å°ã€‚

* å¦‚æœnewSize < oldSize, åˆ™å®ƒåªä¼šæ›´æ–°å—çš„å¤§å°ï¼Œè¿”å›æˆ‘ä»¬æä¾›çš„ç›¸åŒçš„æŒ‡é’ˆï¼Œ

* å¦‚æœ newSize > oldSize, åˆ™å®ƒä¼šå°è¯•å¢åŠ ç°æœ‰å—çš„å¤§å°

å®ƒåªèƒ½è¿™æ ·åšï¼Œå‰ææ˜¯å—åé¢çš„å†…å­˜è¿˜æ²¡æœ‰è¢«ä½¿ç”¨ï¼Œå¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç©ºé—´å¢åŠ å—ï¼Œåˆ™realloc() ä¼šåˆ†é…ä¸€ä¸ªæ‰€éœ€å¤§å°çš„æ–°å†…å­˜å—ï¼Œå¤åˆ¶æ–°å­—èŠ‚ï¼Œé‡Šæ”¾æ—§å—ï¼Œç„¶åè¿”å›æŒ‡å‘æ–°å—çš„æŒ‡é’ˆï¼Œè®°ä½ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„åŠ¨æ€æ•°ç»„çš„è¡Œä¸º

å› ä¸ºè®¡ç®—æœºæ˜¯æœ‰é™èµ„æºï¼Œè€Œä¸æ˜¯è®¡ç®—æœºç§‘å­¦ç†è®ºæ‰€å¸Œæœ›çš„å®Œç¾æ•°å­¦æŠ½è±¡ï¼Œå¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„å†…å­˜ï¼Œåˆ†é…å¯èƒ½ä¼šå¤±è´¥ï¼Œrealloc() å¯èƒ½ä¼šè¿”å›NULL, æˆ‘ä»¬åº”è¯¥å¤„ç†è¿™ç§æƒ…å†µ

```c

// memory.c, in reallocate()

  void* result = realloc(pointer, newSize);
  if (result == NULL) exit(1);
  return result;


```

Thereâ€™s not really anything useful that our VM can do if it canâ€™t get the memory it needs, but we at least detect that and abort the process immediately instead of returning a NULL pointer and letting it go off the rails later.

> Since all we passed in was a bare pointer to the first byte of memory, what does it mean to â€œupdateâ€ the blockâ€™s size? Under the hood, the memory allocator maintains additional bookkeeping information for each block of heap-allocated memory, including its size.
>
> Given a pointer to some previously allocated memory, it can find this bookkeeping information, which is necessary to be able to cleanly free it. Itâ€™s this size metadata that realloc() updates.
>
> Many implementations of malloc() store the allocated size in memory right before the returned address.
> 
> ç”±äºæˆ‘ä»¬ä¼ é€’çš„ä»…ä»…æ˜¯æŒ‡å‘å†…å­˜ç¬¬ä¸€ä¸ªå­—èŠ‚çš„è£¸æŒ‡é’ˆï¼Œé‚£ä¹ˆæ›´æ–°å—çš„å¤§å°æ„å‘³ç€ä»€ä¹ˆå‘¢ï¼Ÿåœ¨åº•å±‚ï¼Œå†…å­˜åˆ†é…å™¨ä¸ºæ¯ä¸€ä¸ªå †åˆ†é…çš„å†…å­˜å—ç»´æŠ¤é¢å¤–çš„è®°å½•ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶å¤§å°
> 
> ç»™å®šæŒ‡å‘å…ˆå‰åˆ†é…çš„å†…å­˜çš„æŒ‡é’ˆï¼Œå®ƒå¯ä»¥æ‰¾åˆ°è¯¥å†…å­˜å—çš„è®°å½•ä¿¡æ¯ï¼Œè¿™æ˜¯èƒ½å¤Ÿå¹²å‡€çš„é‡Šæ”¾å†…å­˜çš„å¿…è¦æ¡ä»¶ï¼Œrealloc() å°±æ˜¯æ›´æ–°è¿™ä¸ªå¤§å°å…ƒæ•°æ®
>
> è®¸å¤šmalloc() å®ç°ï¼Œå°†å·²ç»åˆ†é…çš„å¤§å°å­˜å‚¨åœ¨è¿”å›åœ°å€å‰é¢çš„å†…å­˜ä¸­


å¦‚æœæˆ‘ä»¬æ— æ³•è·å–æ‰€éœ€çš„å†…å­˜ï¼Œæˆ‘ä»¬çš„è™šæ‹Ÿæœºå®é™…ä¸Šï¼Œä¸èƒ½æ‰§è¡Œä»»ä½•æœ‰ç”¨çš„æ“ä½œï¼Œä½†æˆ‘ä»¬è‡³å°‘ä¼šæ£€æµ‹åˆ°å¹¶ä¸”ç«‹å³ç»ˆæ­¢è¿›ç¨‹ï¼Œè€Œä¸æ˜¯è¿”å›ä¸€ä¸ªNULLæŒ‡é’ˆï¼Œå¹¶ä¸”åœ¨è¿™ä¹‹åï¼Œè®©å®ƒåç¦»æ­£è½¨ã€‚

OK, we can create new chunks and write instructions to them. Are we done? Nope! Weâ€™re in C now, remember, we have to manage memory ourselves, like in Ye Olden Times, and that means freeing it too.

å¥½çš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºæ–°çš„ chunkï¼Œå¹¶ä¸”å°†æŒ‡ä»¤å†™å…¥å…¶ä¸­ã€‚æˆ‘ä»¬å®Œæˆäº†å—ï¼Ÿå¹¶æ²¡æœ‰ï¼Œç°åœ¨æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯Cï¼Œå¿…é¡»è‡ªå·±ç®¡ç†å†…å­˜ï¼Œå°±åƒæ˜¯ä»¥å‰çš„æ—¶ä»£ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦é‡Šæ”¾å®ƒã€‚

```c 
// chunk.h, add after initChunk()

void initChunk(Chunk* chunk);
void freeChunk(Chunk* chunk);
void writeChunk(Chunk* chunk, uint8_t byte);

```

The implementation is:

```c

// chunk.c, add after initChunk()

void freeChunk(Chunk* chunk) {
  FREE_ARRAY(uint8_t, chunk->code, chunk->capacity);
  initChunk(chunk);
}


```

We deallocate all of the memory and then call initChunk() to zero out the fields leaving the chunk in a well-defined empty state. To free the memory, we add one more macro.

æˆ‘ä»¬é‡Šæ”¾æ‰€æœ‰å†…å­˜ï¼Œç„¶åè°ƒç”¨ initChunk() æ¥æ¸…é›¶å­—æ®µï¼Œå°†chunk å®šä¹‰ä¸ºä¸€ä¸ªè‰¯å¥½çš„ç©ºçŠ¶æ€ï¼Œä¸ºäº†é‡Šæ”¾å†…å­˜ï¼Œæˆ‘ä»¬æ·»åŠ ä¸€ä¸ªé¢å¤–çš„å®

```c

// memory.h

#define GROW_ARRAY(type, pointer, oldCount, newCount) \
    (type*)reallocate(pointer, sizeof(type) * (oldCount), \
        sizeof(type) * (newCount))

#define FREE_ARRAY(type, pointer, oldCount) \
    reallocate(pointer, sizeof(type) * (oldCount), 0)

void* reallocate(void* pointer, size_t oldSize, size_t newSize);

```

Like GROW_ARRAY(), this is a wrapper around a call to reallocate(). This one frees the memory by passing in zero for the new size. I know, this is a lot of boring low-level stuff. Donâ€™t worry, weâ€™ll get a lot of use out of these in later chapters and will get to program at a higher level. Before we can do that, though, we gotta lay our own foundation.

åƒæ˜¯ GROW_ARRAY() ,è¿™æ˜¯å¯¹reallocate() è°ƒç”¨çš„åŒ…è£…ï¼Œé€šè¿‡å°†newSize è®¾ç½®ä¸º0æ¥é‡Šæ”¾ç©ºé—´ï¼Œæˆ‘çŸ¥é“ï¼Œè¿™æ˜¯å¾ˆå¤šä½çº§åˆ«çš„æ— èŠå·¥ä½œï¼Œä½†æ˜¯ï¼Œä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘ä»¬å°†åœ¨åé¢çš„ç« èŠ‚ä¸­ï¼Œå¤§é‡ä½¿ç”¨è¿™äº›ï¼Œå¹¶å°†åœ¨è¾ƒé«˜å±‚æ¬¡ä¸Šè¿›è¡Œç¼–ç¨‹ã€‚ä½†åœ¨é‚£ä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»æ‰“ä¸‹è‡ªå·±çš„åŸºç¡€ã€‚

## å››ã€Disassembling Chunks

Now we have a little module for creating chunks of bytecode. Letâ€™s try it out by hand-building a sample chunk.

ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†ä¸€ä¸ªåˆ›å»ºå­—èŠ‚ç å—çš„å°æ¨¡å—ï¼Œè®©æˆ‘ä»¬æ‰‹å·¥åˆ›å»ºä¸€ä¸ªç¤ºä¾‹å—

```c
// main.c, in main()

int main(int argc, const char* argv[]) {
  Chunk chunk;
  initChunk(&chunk);
  writeChunk(&chunk, OP_RETURN);
  freeChunk(&chunk);
  return 0;


```

Donâ€™t forget the include.

```c

// main.c

#include "common.h"
#include "chunk.h"

int main(int argc, const char* argv[]) {

```

Run that and give it a try. Did it work? Uhâ€‰.â€‰.â€‰. who knows? All weâ€™ve done is push some bytes around in memory. We have no human-friendly way to see whatâ€™s actually inside that chunk we made.

To fix this, weâ€™re going to create a disassembler. An assembler is an old-school program that takes a file containing human-readable mnemonic names for CPU instructions like â€œADDâ€ and â€œMULTâ€ and translates them to their binary machine code equivalent. A disassembler goes in the other directionâ€”given a blob of machine code, it spits out a textual listing of the instructions.

Weâ€™ll implement something similar. Given a chunk, it will print out all of the instructions in it. A Lox user wonâ€™t use this, but we Lox maintainers will certainly benefit since it gives us a window into the interpreterâ€™s internal representation of code.

è¿è¡Œå¹¶è¯•è¯•ï¼Œå®ƒæ˜¯å¦èµ·ä½œç”¨ï¼Ÿå—¯ï¼Œè°çŸ¥é“å—ï¼Ÿæˆ‘ä»¬æ‰€åšçš„åªæ˜¯åœ¨å†…å­˜ä¸­ç§»åŠ¨ä¸€äº›å­—èŠ‚ï¼Œè¿˜æ²¡æœ‰æ›´åŠ å¥½çš„æ–¹å¼å¯ä»¥æŸ¥çœ‹ï¼Œç¨‹åºä¸­åˆ›å»ºçš„å—çš„å†…å®¹

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåæ±‡ç¼–å™¨ï¼Œæ±‡ç¼–å™¨æ˜¯ä¸€ç§å¤è€çš„ç¨‹åºï¼Œå®ƒæ¥å—ä¸€ä¸ªäººç±»å¯è¯»çš„CPU æŒ‡ä»¤åŠ©è®°ç¬¦åç§°ï¼ˆä¾‹å¦‚: ADD MULTç­‰ï¼‰çš„æ–‡ä»¶ï¼Œå¹¶ä¸”å°†å®ƒä»¬è½¬æ¢ä¸ºäºŒè¿›åˆ¶çš„æœºå™¨ç å½¢å¼ã€‚åæ±‡ç¼–å™¨åˆ™ç›¸åâ€”â€”ç»™å®šä¸€å—æœºå™¨ç ï¼Œå®ƒå¯ä»¥è¾“å‡ºæŒ‡ä»¤çš„æ–‡æœ¬åˆ—è¡¨

æˆ‘ä»¬å°†å®ç°ç±»ä¼¼çš„ä¸œè¥¿ï¼Œç»™å®šä¸€ä¸ªå—ï¼Œå®ƒå°†æ‰“å°å‡ºå…¶ä¸­çš„æ‰€æœ‰æŒ‡ä»¤ï¼ŒLoxç”¨æˆ·ä¸ä¼šä½¿ç”¨å®ƒï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬çš„Loxç»´æŠ¤è€…ä¼šç”¨åˆ°ã€‚å› ä¸ºï¼Œå®ƒç»™äº†æˆ‘ä»¬æŸ¥çœ‹è§£é‡Šå™¨ä»£ç çš„å†…éƒ¨è¡¨ç¤ºçš„çª—å£

> In jlox, our analogous tool was the AstPrinter class.
> 
> åœ¨jloxä¸­ï¼Œç±»ä¼¼çš„å·¥å…·æ˜¯AstProinter ç±»ã€‚


In main(), after we create the chunk, we pass it to the disassembler.

åœ¨main() å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºå¥½chunkåï¼Œå°†å…¶ä¼ é€’ç»™äº† åæ±‡ç¼–å™¨

```c

// main.c, in main()

  initChunk(&chunk);
  writeChunk(&chunk, OP_RETURN);

  disassembleChunk(&chunk, "test chunk");
  freeChunk(&chunk);
  
```

Again, we whip up yet another module.

æˆ‘ä»¬å°†å†æ¬¡åˆ›å»ºä¸€ä¸ªæ–°çš„æ¨¡å—

```c

// main.c

#include "chunk.h"
#include "debug.h"

int main(int argc, const char* argv[]) {

```

Hereâ€™s that header:

```c

// debug.h, create new file

#ifndef clox_debug_h
#define clox_debug_h

#include "chunk.h"

void disassembleChunk(Chunk* chunk, const char* name);
int disassembleInstruction(Chunk* chunk, int offset);

#endif


```

> I promise you we wonâ€™t be creating this many new files in later chapters.
> 
> æˆ‘å‘ä½ ä¿è¯ï¼Œåé¢çš„ç« èŠ‚ä¸­ï¼Œä¸ä¼šåˆ›å»ºè¿™ä¹ˆå¤šçš„æ–°æ–‡ä»¶

In main(), we call disassembleChunk() to disassemble all of the instructions in the entire chunk. Thatâ€™s implemented in terms of the other function, which just disassembles a single instruction. It shows up here in the header because weâ€™ll call it from the VM in later chapters.

Hereâ€™s a start at the implementation file:

åœ¨main() å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬è°ƒç”¨ disassembleChunk() æ¥åæ±‡ç¼–è¿™ä¸ªchunk ä¸­çš„æ‰€æœ‰æŒ‡ä»¤ï¼Œè¿™æ˜¯é€šè¿‡å…¶ä»–å‡½æ•°æ¥å®ç°çš„ï¼Œ å®ƒåªèƒ½åæ±‡ç¼–å•ä¸ªæŒ‡ä»¤ã€‚å®ƒåœ¨è¿™é‡Œå‡ºç°åœ¨å¤´æ–‡ä»¶ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨åé¢çš„ç« èŠ‚ä¸­ï¼Œä¼šä»VM ä¸­è°ƒç”¨è¿™ä¸ªå‡½æ•°

ä¸‹é¢æ˜¯å®ç°çš„å¼€å¤´

```c

// debug.c, create new file

#include <stdio.h>

#include "debug.h"

void disassembleChunk(Chunk* chunk, const char* name) {
  printf("== %s ==\n", name);

  for (int offset = 0; offset < chunk->count;) {
    offset = disassembleInstruction(chunk, offset);
  }
}

```

To disassemble a chunk, we print a little header (so we can tell which chunk weâ€™re looking at) and then crank through the bytecode, disassembling each instruction. The way we iterate through the code is a little odd. Instead of incrementing offset in the loop, we let disassembleInstruction() do it for us. When we call that function, after disassembling the instruction at the given offset, it returns the offset of the next instruction. This is because, as weâ€™ll see later, instructions can have different sizes.

The core of the â€œdebugâ€ module is this function:

ä¸ºäº†åæ±‡ç¼–ä¸€ä¸ªä»£ç å—ï¼Œæˆ‘ä»¬é¦–å…ˆæ‰“å°ä¸€ä¸ªå°æ ‡é¢˜ï¼Œï¼ˆè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥çŸ¥é“æˆ‘ä»¬åœ¨æŸ¥çœ‹å“ªä¸€ä¸ªä»£ç å—ï¼‰ï¼Œç„¶åéå†å­—èŠ‚ç å¹¶ä¸”åæ±‡ç¼–æ¯ä¸ªæŒ‡ä»¤ï¼Œæˆ‘ä»¬è¿­ä»£ä»£ç çš„æ–¹å¼æœ‰ç‚¹å¥‡æ€ªï¼Œæˆ‘ä»¬ä¸æ˜¯åœ¨å¾ªç¯ä¸­é€’å¢åç§»é‡ï¼Œè€Œæ˜¯è®©disassembleInstruction() å‡½æ•°ä¸ºæˆ‘ä»¬å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼Œå½“æˆ‘ä»¬è°ƒç”¨è¯¥å‡½æ•°æ—¶å€™ï¼Œåœ¨åæ±‡ç¼–ç»™å®šåç§»é‡å¤„çš„æŒ‡ä»¤åï¼Œå®ƒä¼šè¿”å›ä¸‹ä¸€æ¡æŒ‡ä»¤çš„åç§»é‡ï¼Œè¿™æ˜¯å› ä¸ºï¼Œæ­£å¦‚æˆ‘ä»¬ç¨åå°†çœ‹åˆ°çš„ï¼ŒæŒ‡ä»¤çš„å¤§å°å¯èƒ½ä¸ç›¸åŒ

debugæ¨¡å—çš„æ ¸å¿ƒæ˜¯è¿™ä¸ªå‡½æ•°

```c
// debug.c, add after disassembleChunk()

int disassembleInstruction(Chunk* chunk, int offset) {
  printf("%04d ", offset);

  uint8_t instruction = chunk->code[offset];
  switch (instruction) {
    case OP_RETURN:
      return simpleInstruction("OP_RETURN", offset);
    default:
      printf("Unknown opcode %d\n", instruction);
      return offset + 1;
  }
}

```

First, it prints the byte offset of the given instructionâ€”that tells us where in the chunk this instruction is. This will be a helpful signpost when we start doing control flow and jumping around in the bytecode.

Next, it reads a single byte from the bytecode at the given offset. Thatâ€™s our opcode. We switch on that. For each kind of instruction, we dispatch to a little utility function for displaying it. On the off chance that the given byte doesnâ€™t look like an instruction at allâ€”a bug in our compilerâ€”we print that too. For the one instruction we do have, OP_RETURN, the display function is:

é¦–å…ˆï¼Œå®ƒä¼šæ‰“å°ç»™å®šæŒ‡ä»¤çš„å­—èŠ‚åç§»é‡â€”â€”è¿™å‘Šè¯‰æˆ‘ä»¬è¿™ä¸ªæŒ‡ä»¤åœ¨ä»£ç å—ä¸­çš„ä½ç½®ï¼Œå½“æˆ‘ä»¬å¼€å§‹è¿›è¡Œæ§åˆ¶æµå’Œå­—èŠ‚ç è·³è½¬æ—¶å€™ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ ‡å¿—ã€‚

æ¥ä¸‹æ¥ï¼Œå®ƒä»ç»™å®šåç§»é‡å¤„çš„å­—èŠ‚ç ä¸­è¯»å–ä¸€ä¸ªå­—èŠ‚ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„æ“ä½œç ï¼Œæˆ‘ä»¬å¯¹æ“ä½œç è¿›è¡Œ switchè¯­å¥ï¼Œå¯¹äºæ¯ç§ç±»å‹çš„æŒ‡ä»¤ï¼Œæˆ‘ä»¬ä¼šè°ƒç”¨ä¸€ä¸ªå°çš„å®ç”¨ç¨‹åºæ¥æ˜¾ç¤ºã€‚ä¸‡ä¸€ç»™å®šçš„å­—èŠ‚æ ¹æœ¬ä¸æ˜¯ä¸€ä¸ªæŒ‡ä»¤â€”â€”è¿™æ˜¯ç¼–è¯‘å™¨ä¸­çš„ä¸€ä¸ªé”™è¯¯â€”â€”æˆ‘ä»¬ä¹Ÿä¼šæ‰“å°å‡ºæ¥ï¼Œå¯¹äºæˆ‘ä»¬å”¯ä¸€æ‹¥æœ‰çš„æŒ‡ä»¤OP_RETURN, æ˜¾ç¤ºå‡½æ•°æ˜¯

```c

// debug.c, add after disassembleChunk()

static int simpleInstruction(const char* name, int offset) {
  printf("%s\n", name);
  return offset + 1;
}

```

> We have only one instruction right now, but this switch will grow throughout the rest of the book.
> 
> æˆ‘ä»¬ç°åœ¨åªæœ‰ä¸€æ¡æŒ‡ä»¤ï¼Œä½†æ˜¯ï¼Œåœ¨æœ¬ä¹¦çš„å…¶ä½™éƒ¨åˆ†ï¼Œè¿™ä¸ªswitch è¯­å¥ï¼Œä¼šä¸æ–­å¢é•¿ã€‚

There isnâ€™t much to a return instruction, so all it does is print the name of the opcode, then return the next byte offset past this instruction. Other instructions will have more going on.

If we run our nascent interpreter now, it actually prints something:

returnæŒ‡ä»¤ï¼Œå¹¶æ²¡æœ‰å¤ªå¤šå†…å®¹ï¼Œå› æ­¤å®ƒåªæ˜¯æ‰“å°æ“ä½œç çš„åç§°ï¼Œç„¶åï¼Œè¿”å›è·³è¿‡return æŒ‡ä»¤çš„ä¸‹ä¸€ä¸ªå­—èŠ‚åç§»é‡ã€‚å…¶ä»–æŒ‡ä»¤å°†ä¼šæœ‰æ›´å¤šçš„å†…å®¹ã€‚

å¦‚æœæˆ‘ä»¬ç°åœ¨è¿è¡Œ cloxè§£é‡Šå™¨ï¼Œå®ƒä¼šæ‰“å°å‡ºä¸€äº›ä¸œè¥¿

```c

== test chunk ==
0000 OP_RETURN

```

It worked! This is sort of the â€œHello, world!â€ of our code representation. We can create a chunk, write an instruction to it, and then extract that instruction back out. Our encoding and decoding of the binary bytecode is working.

å®ƒèµ·ä½œç”¨äº†ï¼Œè¿™æœ‰ç‚¹åƒæ˜¯æˆ‘ä»¬ä»£ç è¡¨ç¤ºæ³• çš„"hello, world!" æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªä»£ç å—ï¼Œå‘å…¶ä¸­å†™å…¥ä¸€ä¸ªæŒ‡ä»¤ï¼Œç„¶åå°†è¯¥æŒ‡ä»¤æå–å‡ºæ¥ï¼Œæˆ‘ä»¬çš„äºŒè¿›åˆ¶å­—èŠ‚ç çš„ç¼–ç å’Œè§£ç æ­£åœ¨å·¥ä½œã€‚

## äº”ã€Constants

Now that we have a rudimentary chunk structure working, letâ€™s start making it more useful. We can store code in chunks, but what about data? Many values the interpreter works with are created at runtime as the result of operations.

ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªåŸºæœ¬çš„ä»£ç å—ç»“æ„ï¼Œè®©æˆ‘ä»¬å¼€å§‹è®©å®ƒæ›´åŠ æœ‰ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä»£ç å—ä¸­å­˜å‚¨ä»£ç ï¼Œä½†æ˜¯æ•°æ®å‘¢ï¼Ÿè®¸å¤šè§£é‡Šå™¨å¤„ç†çš„å€¼æ˜¯åœ¨è¿è¡Œæ—¶ï¼Œä½œä¸ºæ“ä½œç»“æœåˆ›å»ºçš„

```
1 + 2;

```

The value 3 appears nowhere in the code here. However, the literals 1 and 2 do. To compile that statement to bytecode, we need some sort of instruction that means â€œproduce a constantâ€ and those literal values need to get stored in the chunk somewhere. In jlox, the Expr.Literal AST node held the value. We need a different solution now that we donâ€™t have a syntax tree.

ä»£ç ä¸­æ²¡æœ‰å‡ºç°3ï¼Œ ç„¶è€Œï¼Œå­—é¢é‡1 å’Œ 2 å‡ºç°äº†ï¼Œä¸ºäº†å°†è¯¥è¯­å¥ç¼–è¯‘ä¸ºå­—èŠ‚ç ï¼Œæˆ‘ä»¬éœ€è¦æŸç§æŒ‡ä»¤ï¼Œè¡¨ç¤ºç”Ÿæˆä¸€ä¸ªå¸¸é‡ï¼Œå¹¶ä¸”è¿™äº›å­—é¢å€¼éœ€è¦è¢«å­˜å‚¨åˆ°ä»£ç ä¸­çš„æŸä¸ªåœ°æ–¹ï¼Œåœ¨jlox ä¸­ï¼ŒExpr.Literal èŠ‚ç‚¹ï¼Œä¿å­˜äº†è¯¥å€¼ã€‚ç”±äºç°åœ¨æˆ‘ä»¬æ²¡æœ‰è¯­æ³•æ ‘ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸åŒçš„è§£å†³æ–¹æ¡ˆ

### 5.1 Representing values

è¡¨ç¤ºå€¼

We wonâ€™t be running any code in this chapter, but since constants have a foot in both the static and dynamic worlds of our interpreter, they force us to start thinking at least a little bit about how our VM should represent values.

For now, weâ€™re going to start as simple as possibleâ€”weâ€™ll support only double-precision, floating-point numbers. This will obviously expand over time, so weâ€™ll set up a new module to give ourselves room to grow.

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šè¿è¡Œä»»ä½•ä»£ç ï¼Œä½†æ˜¯ï¼Œç”±äºå¸¸é‡åŒæ—¶æ¶‰åŠåˆ°è§£é‡Šå™¨çš„é™æ€å’ŒåŠ¨æ€ä¸–ç•Œï¼Œå®ƒè¿«ä½¿æˆ‘ä»¬å¼€å§‹è€ƒè™‘å¦‚ä½•è¡¨ç¤ºå€¼

ç°åœ¨ï¼Œæˆ‘ä»¬å°†å°½å¯èƒ½ç®€å•çš„å¼€å§‹â€”â€”æˆ‘ä»¬ä»…ä»…æ”¯æŒ double ç±»å‹ï¼Œéšç€æ—¶é—´çš„æ‰©å±•ï¼Œè¿™æ˜¾ç„¶ä¼šæ‰©å±•ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å°†è®¾ç½®ä¸€ä¸ªæ–°çš„æ¨¡å—ï¼Œç•™å‡ºå‘å±•ç©ºé—´

```c


// value.h, create new file

#ifndef clox_value_h
#define clox_value_h

#include "common.h"

typedef double Value;

#endif


```

This typedef abstracts how Lox values are concretely represented in C. That way, we can change that representation without needing to go back and fix existing code that passes around values.

Back to the question of where to store constants in a chunk. For small fixed-size values like integers, many instruction sets store the value directly in the code stream right after the opcode. These are called immediate instructions because the bits for the value are immediately after the opcode.

That doesnâ€™t work well for large or variable-sized constants like strings. In a native compiler to machine code, those bigger constants get stored in a separate â€œconstant dataâ€ region in the binary executable. Then, the instruction to load a constant has an address or offset pointing to where the value is stored in that section.

Most virtual machines do something similar. For example, the Java Virtual Machine associates a constant pool with each compiled class. That sounds good enough for clox to me. Each chunk will carry with it a list of the values that appear as literals in the program. To keep things simpler, weâ€™ll put all constants in there, even simple integers.

è¿™ä¸ª typedef æŠ½è±¡äº†Loxä¸­çš„å€¼åœ¨Cä¸­çš„å…·ä½“è¡¨ç¤ºæ–¹å¼ï¼Œè¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ”¹è¯¥è¡¨è¾¾æ–¹å¼ï¼Œè€Œä¸éœ€è¦å›åˆ°ç°æœ‰ä»£ç æ¥ä¿®å¤ä¼ é€’å€¼çš„ä»£ç 

å›åˆ°å°†å¸¸é‡å­˜å‚¨åœ¨ä»£ç å—ä¸­çš„é—®é¢˜ï¼Œå¯¹äºåƒæ•´æ•°è¿™æ ·å›ºå®šé•¿åº¦çš„å€¼ï¼Œè®¸å¤šæŒ‡ä»¤é›†å°†è¯¥å€¼ç›´æ¥å­˜å‚¨åˆ°æ“ä½œç åé¢çš„ï¼Œä»£ç æµä¸­ã€‚è¿™äº›è¢«ç§°ä¸ºç«‹å³æŒ‡ä»¤ï¼Œå› ä¸ºè¯¥å€¼çš„ä½ï¼Œç´§è·Ÿåœ¨æ“ä½œç åé¢ã€‚

ä½†æ˜¯ï¼Œè¿™å¯¹äºåƒæ˜¯å­—ç¬¦ä¸²è¿™æ ·çš„å¤§çš„æˆ–è€…å¯å˜é•¿åº¦çš„å¸¸é‡ï¼Œå¹¶ä¸é€‚ç”¨ã€‚åœ¨æœ¬æœºç¼–è¯‘åˆ°æœºå™¨ç çš„æƒ…å†µä¸‹ï¼Œè¿™äº›æ›´å¤§çš„å¸¸é‡è¢«å­˜å‚¨åœ¨äºŒè¿›åˆ¶å¯æ‰§è¡Œæ–‡ä»¶ä¸­çš„å•ç‹¬çš„â€”â€”å¸¸é‡æ•°æ®ï¼ŒåŒºåŸŸä¸­ã€‚ç„¶åï¼ŒåŠ è½½å¸¸é‡çš„æŒ‡ä»¤ï¼Œå…·æœ‰æŒ‡å‘è¯¥éƒ¨åˆ†å­˜å‚¨å€¼çš„åœ°å€ï¼Œæˆ–è€…åç§»é‡

å¤§å¤šæ•°çš„è™šæ‹Ÿæœºéƒ½ä¼šåšç›¸åŒçš„äº‹æƒ…ï¼Œä¾‹å¦‚ï¼šJavaè™šæ‹Ÿæœºå°†å¸¸é‡æ± ä¸æ¯ä¸ªç¼–è¯‘çš„ç±»å…³è”èµ·æ¥ï¼Œè¿™å¯¹äºcloxæ¥è¯´è¶³å¤Ÿå¥½ï¼Œæ¯ä¸ªä»£ç å—å°†æºå¸¦åœ¨ç¨‹åºä¸­å‡ºç°çš„å­—é¢é‡å€¼çš„åˆ—è¡¨ï¼Œä¸ºäº†ä½¿äº‹æƒ…æ›´åŠ ç®€å•ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰çš„å¸¸é‡æ”¾å…¥å…¶ä¸­ï¼Œç”šè‡³æ˜¯ç®€å•çš„æ•´æ•°

> In addition to needing two kinds of constant instructionsâ€”one for immediate values and one for constants in the constant tableâ€”immediates also force us to worry about alignment, padding, and endianness. Some architectures arenâ€™t happy if you try to say, stuff a 4-byte integer at an odd address.
> 
> é™¤äº†éœ€è¦ä¸¤ç§å¸¸é‡æŒ‡ä»¤ï¼ˆä¸€ç§ç”¨äºç«‹å³æ•°ï¼Œå¦ä¸€ç§ç”¨äºå¸¸é‡è¡¨ä¸­çš„å¸¸é‡ï¼‰ä¹‹å¤–ï¼Œç«‹å³æ•°è¿˜éœ€è¦æˆ‘ä»¬å…³æ³¨å¯¹é½ã€å¡«å……å’Œå­—èŠ‚åºçš„é—®é¢˜ï¼Œå¦‚æœä½ è¯•å›¾å°†ä¸€ä¸ª4å­—èŠ‚æ•´æ•°å­˜å‚¨åœ¨å¥‡æ•°ä½åœ°å€ä¸Šï¼Œåœ¨æŸäº›æ¶æ„ä¸­ï¼Œå¯èƒ½ä¼šå‡ºç°é—®é¢˜ã€‚

### 5.2 Value arrays


The constant pool is an array of values. The instruction to load a constant looks up the value by index in that array. As with our bytecode array, the compiler doesnâ€™t know how big the array needs to be ahead of time. So, again, we need a dynamic one. Since C doesnâ€™t have generic data structures, weâ€™ll write another dynamic array data structure, this time for Value.


å¸¸é‡æ± æ˜¯å€¼çš„æ•°ç»„ï¼ŒåŠ è½½å¸¸é‡çš„æŒ‡ä»¤ï¼Œåœ¨è¯¥æ•°ç»„ä¸­é€šè¿‡ç´¢å¼•æŸ¥æ‰¾è¯¥å€¼ï¼Œä¸å­—èŠ‚ç æ•°ç»„ä¸€æ ·ï¼Œç¼–è¯‘å™¨äº‹å…ˆä¸çŸ¥é“æ•°ç»„çš„å¤§å°ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬å†æ¬¡éœ€è¦ä¸€ä¸ªåŠ¨æ€æ•°ç»„ï¼Œç”±äºC æ²¡æœ‰é€šç”¨æ•°æ®ç»“æ„ï¼Œæˆ‘ä»¬å°†ä¸ºValueç¼–å†™å¦ä¸€ä¸ªåŠ¨æ€æ•°ç»„æ•°æ®ç»“æ„

```c

// value.h

typedef double Value;

typedef struct {
  int capacity;
  int count;
  Value* values;
} ValueArray;

#endif

```

> Defining a new struct and manipulation functions each time we need a dynamic array of a different type is a chore. We could cobble together some preprocessor macros to fake generics, but thatâ€™s overkill for clox. We wonâ€™t need many more of these.
> 
> æ¯æ¬¡éœ€è¦ä¸åŒç±»å‹çš„åŠ¨æ€æ•°ç»„æ—¶å€™ï¼Œéƒ½å®šä¹‰ä¸€ä¸ªæ–°çš„ç»“æ„ä½“å’Œæ“ä½œå‡½æ•°ï¼Œæ˜¯å¾ˆç¹ççš„ã€‚æˆ‘ä»¬å¯ä»¥æ‹¼å‡‘å‡ºä¸€äº›é¢„å¤„ç†å™¨å®ï¼Œæ¥æ¨¡æ‹Ÿæ³›å‹ã€‚ä½†è¿™å¯¹äºcloxæ¥è¯´è¿‡äºç¹çï¼Œæˆ‘ä»¬ä¸éœ€è¦æ›´å¤šè¿™æ ·çš„æ“ä½œã€‚


As with the bytecode array in Chunk, this struct wraps a pointer to an array along with its allocated capacity and the number of elements in use. We also need the same three functions to work with value arrays.

å’Œchunkä¸­çš„å­—èŠ‚ç æ•°ç»„ä¸€æ ·ï¼Œè¿™ä¸ªç»“æ„ä½“åŒ…è£…äº†æŒ‡å‘æ•°ç»„çš„æŒ‡é’ˆï¼Œä»¥åŠå…¶åˆ†é…çš„å®¹é‡å’Œæ­£åœ¨ä½¿ç”¨çš„å…ƒç´ æ•°ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸‰ä¸ªå‡½æ•°æ¥å¤„ç†å€¼æ•°ç»„ã€‚

```c

// value.h, add after struct ValueArray

} ValueArray;

void initValueArray(ValueArray* array);
void writeValueArray(ValueArray* array, Value value);
void freeValueArray(ValueArray* array);

#endif

```


The implementations will probably give you dÃ©jÃ  vu. First, to create a new one:

è¿™äº›å®ç°å¯èƒ½ä¼šè®©ä½ æœ‰ä¸€ç§ä¼¼æ›¾ç›¸è¯†çš„æ„Ÿè§‰ï¼Œé¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„å€¼æ•°ç»„

```c

// value.c, create new file

#include <stdio.h>

#include "memory.h"
#include "value.h"

void initValueArray(ValueArray* array) {
  array->values = NULL;
  array->capacity = 0;
  array->count = 0;
}

```

Once we have an initialized array, we can start adding values to it.

å½“æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå·²ç»åˆå§‹åŒ–çš„æ•°ç»„ï¼Œæˆ‘ä»¬å°±å¯ä»¥å‘å…¶ä¸­æ·»åŠ å€¼äº†

```c 

// value.c, add after initValueArray()

void writeValueArray(ValueArray* array, Value value) {
  if (array->capacity < array->count + 1) {
    int oldCapacity = array->capacity;
    array->capacity = GROW_CAPACITY(oldCapacity);
    array->values = GROW_ARRAY(Value, array->values,
                               oldCapacity, array->capacity);
  }

  array->values[array->count] = value;
  array->count++;
}

```

> Fortunately, we donâ€™t need other operations like insertion and removal.
> 
> å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦å…¶ä»–æ“ä½œï¼Œä¾‹å¦‚: æ’å…¥ã€åˆ é™¤ã€‚

The memory-management macros we wrote earlier do let us reuse some of the logic from the code array, so this isnâ€™t too bad. Finally, to release all memory used by the array:

æˆ‘ä»¬ä¹‹å‰ç¼–å†™çš„å†…å­˜ç®¡ç†ï¼Œå¯ä»¥è®©æˆ‘ä»¬å¤ç”¨åœ¨ä»£ç æ•°ç»„ä¸­ï¼Œå› æ­¤ï¼Œæƒ…å†µå¹¶ä¸ç®—å¤ªå·®ã€‚æœ€åï¼Œè¦é‡Šæ”¾æ•°ç»„ä½¿ç”¨çš„æ‰€æœ‰å†…å­˜ã€‚

```c

// value.c, add after writeValueArray()

void freeValueArray(ValueArray* array) {
  FREE_ARRAY(Value, array->values, array->capacity);
  initValueArray(array);
}


```

Now that we have growable arrays of values, we can add one to Chunk to store the chunkâ€™s constants.

ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†å¯å¢é•¿çš„å€¼æ•°ç»„ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æ·»åŠ åˆ° chunkä¸­ï¼Œç”¨äºå­˜å‚¨ä»£ç å—çš„å¸¸é‡ã€‚

```c
// chunk.h, in struct Chunk

  uint8_t* code;
  ValueArray constants;
} Chunk;

```


Donâ€™t forget the include.

```c

// chunk.h

#include "common.h"
#include "value.h"

typedef enum {

```

Ah, C, and its Stone Age modularity story. Where were we? Right. When we initialize a new chunk, we initialize its constant list too.

C  å’Œå®ƒçš„å¤è€çš„æ¨¡å—åŒ–æ•…äº‹ï¼Œæˆ‘ä»¬åœ¨å“ªé‡Œï¼Ÿå½“æˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„ä»£ç å—æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿåˆå§‹åŒ–å®ƒçš„å¸¸é‡åˆ—è¡¨


```c 

// chunk.c, in initChunk()

  chunk->code = NULL;
  initValueArray(&chunk->constants);
}


```

Likewise, we free the constants when we free the chunk.

 åŒæ ·çš„ï¼Œå½“æˆ‘ä»¬é‡Šæ”¾ä»£ç å—æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¼šé‡Šæ”¾å¸¸é‡
 
 
```c 

// chunk.c, in freeChunk()

  FREE_ARRAY(uint8_t, chunk->code, chunk->capacity);
  freeValueArray(&chunk->constants);
  initChunk(chunk);


```


Next, we define a convenience method to add a new constant to the chunk. Our yet-to-be-written compiler could write to the constant array inside Chunk directlyâ€”itâ€™s not like C has private fields or anythingâ€”but itâ€™s a little nicer to add an explicit function.

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ–¹ä¾¿çš„æ–¹æ³•ï¼Œå°†ä¸€ä¸ªæ–°çš„å¸¸é‡æ·»åŠ åˆ°chunkä¸­ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰ç¼–å†™çš„ç¼–è¯‘å™¨ï¼Œå¯ä»¥ç›´æ¥å†™å…¥chunkå†…éƒ¨çš„å¸¸é‡æ•°ç»„ï¼Œâ€”â€”è¿™ä¸åƒæ˜¯C æœ‰ç§æœ‰å­—æ®µæˆ–è€…å…¶ä»–ä¸œè¥¿â€”â€”ä½†æ˜¯ï¼Œæ·»åŠ ä¸€ä¸ªæ˜¾å¼çš„å‡½æ•°ä¼šè®©äº‹æƒ…æ›´åŠ ç¾å¥½

```c 


// chunk.h, add after writeChunk()

void writeChunk(Chunk* chunk, uint8_t byte);
int addConstant(Chunk* chunk, Value value);

#endif

```

Then we implement it.

```c

// chunk.c, add after writeChunk()

int addConstant(Chunk* chunk, Value value) {
  writeValueArray(&chunk->constants, value);
  return chunk->constants.count - 1;
}

```

After we add the constant, we return the index where the constant was appended so that we can locate that same constant later.

æˆ‘ä»¬æ·»åŠ äº†å¸¸é‡åï¼Œè¿”å›è¯¥å¸¸é‡è¢«è¿½åŠ çš„ç´¢å¼•ï¼Œä»¥ä¾¿äºä»¥åå¯ä»¥å®šä½åˆ°åŒä¸€ä¸ªå¸¸é‡


### 5.3 Constant instructions

å¸¸é‡æŒ‡ä»¤

We can store constants in chunks, but we also need to execute them. In a piece of code like:

æˆ‘ä»¬å¯ä»¥å°†å¸¸é‡ä¿å­˜åœ¨chunkä¸­ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æ‰§è¡Œå®ƒä»¬ï¼Œåœ¨ä¸‹é¢è¿™æ ·çš„ä»£ç ç‰‡æ®µä¸­

```c

print 1;
print 2;

```

The compiled chunk needs to not only contain the values 1 and 2, but know when to produce them so that they are printed in the right order. Thus, we need an instruction that produces a particular constant.

ç¼–è¯‘åçš„å—ï¼Œä¸ä»…éœ€è¦åŒ…å«å€¼1å’Œ2ï¼Œè¿˜éœ€è¦çŸ¥é“ä½•æ—¶ç”Ÿæˆå®ƒä»¬ï¼Œä»¥ä¾¿ä»¥æ­£ç¡®çš„é¡ºåºæ‰“å°å®ƒä»¬ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€æ¡æŒ‡ä»¤æ¥ç”Ÿæˆç‰¹å®šçš„å¸¸é‡

```c

// chunk.h, in enum OpCode

typedef enum {
  OP_CONSTANT,
  OP_RETURN,
	
```

When the VM executes a constant instruction, it â€œloadsâ€ the constant for use. This new instruction is a little more complex than OP_RETURN. In the above example, we load two different constants. A single bare opcode isnâ€™t enough to know which constant to load.

å½“è™šæ‹Ÿæœºæ‰§è¡Œå¸¸é‡æŒ‡ä»¤æ—¶ï¼Œå®ƒä¼šåŠ è½½è¯¥å¸¸é‡ï¼Œä»¥ä¾›ä½¿ç”¨ï¼Œè¿™ä¸ªæ–°æŒ‡ä»¤æ¯”OP_RETURN å¤æ‚ä¸€äº›ï¼Œåœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åŠ è½½äº†ä¸¤ä¸ªä¸åŒçš„å¸¸é‡ï¼Œä¸€ä¸ªå•ç‹¬çš„æ“ä½œç ï¼Œä¸è¶³ä»¥çŸ¥é“è¦åŠ è½½å“ªä¸ªå¸¸é‡

To handle cases like this, our bytecodeâ€”like most othersâ€”allows instructions to have operands. These are stored as binary data immediately after the opcode in the instruction stream and let us parameterize what the instruction does.

ä¸ºäº†å¤„ç†è¿™ç§æƒ…å†µï¼Œæˆ‘ä»¬çš„å­—èŠ‚ç ï¼ˆåƒæ˜¯å¤§å¤šæ•°å­—èŠ‚ç ä¸€æ ·ï¼‰ï¼Œå…è®¸æŒ‡ä»¤å…·æœ‰æ“ä½œæ•°ï¼Œè¿™äº›æ“ä½œæ•°ä½œä¸ºäºŒè¿›åˆ¶æ•°æ®ï¼Œç«‹å³å­˜å‚¨åœ¨æŒ‡ä»¤æµçš„æ“ä½œç ä¹‹åï¼Œè®©æˆ‘ä»¬å¯¹æŒ‡ä»¤çš„æ“ä½œè¿›è¡Œå‚æ•°åŒ–

![format](https://github.com/Kua-Fu/blog-book-images/blob/main/crafting-interpreters/14_format.png?raw=true)

> Iâ€™m being vague about what it means to â€œloadâ€ or â€œproduceâ€ a constant because we havenâ€™t learned how the virtual machine actually executes code at runtime yet. For that, youâ€™ll have to wait until you get to (or skip ahead to, I suppose) the next chapter.
> 
> 

Each opcode determines how many operand bytes it has and what they mean. For example, a simple operation like â€œreturnâ€ may have no operands, where an instruction for â€œload local variableâ€ needs an operand to identify which variable to load. Each time we add a new opcode to clox, we specify what its operands look likeâ€”its instruction format.

æ¯ç§æ“ä½œç ï¼Œç¡®å®šå®ƒæœ‰å¤šå°‘æ“ä½œæ•°å­—èŠ‚ï¼Œä»¥åŠå®ƒä»¬çš„å«ä¹‰ï¼Œä¾‹å¦‚ï¼šreturn è¿™æ ·ç®€å•ç±»å‹çš„æ“ä½œç ï¼Œå¯èƒ½æ²¡æœ‰æ“ä½œæ•°ï¼›è€Œ åŠ è½½æœ¬åœ°å˜é‡ æ“ä½œç ï¼Œè¿˜éœ€è¦ä¸€ä¸ªæ“ä½œæ•°ï¼Œç”¨äºæ ‡è¯†è¦åŠ è½½å“ªä¸ªå˜é‡ï¼›æ¯æ¬¡åƒclox æ·»åŠ æ–°çš„æ“ä½œç æ—¶å€™ï¼Œæˆ‘ä»¬éƒ½ä¼šæŒ‡å®šå®ƒä»¬çš„æ“ä½œæ•°æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œä¹Ÿå°±æ˜¯æŒ‡ä»¤æ ¼å¼

In this case, OP_CONSTANT takes a single byte operand that specifies which constant to load from the chunkâ€™s constant array. Since we donâ€™t have a compiler yet, we â€œhand-compileâ€ an instruction in our test chunk.

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒOP_CONSTANT æŒ‡ä»¤éœ€è¦ä¸€ä¸ªå•å­—èŠ‚æ“ä½œæ•°ï¼Œç”¨äºæŒ‡å®šè¦ä»å—çš„å¸¸é‡æ•°ç»„ä¸­åŠ è½½å“ªä¸ªå¸¸é‡ï¼Œç”±äºæˆ‘ä»¬è¿˜æ²¡æœ‰ç¼–è¯‘å™¨ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬åœ¨æµ‹è¯•å—ä¸­æ‰‹åŠ¨ç¼–è¯‘æŒ‡ä»¤ã€‚

```c

// main.c, in main()

  initChunk(&chunk);

  int constant = addConstant(&chunk, 1.2);
  writeChunk(&chunk, OP_CONSTANT);
  writeChunk(&chunk, constant);

  writeChunk(&chunk, OP_RETURN);


```


We add the constant value itself to the chunkâ€™s constant pool. That returns the index of the constant in the array. Then we write the constant instruction, starting with its opcode. After that, we write the one-byte constant index operand. Note that writeChunk() can write opcodes or operands. Itâ€™s all raw bytes as far as that function is concerned.

If we try to run this now, the disassembler is going to yell at us because it doesnâ€™t know how to decode the new instruction. Letâ€™s fix that.


æˆ‘ä»¬å°†å¸¸é‡å€¼æœ¬èº«ï¼Œæ·»åŠ åˆ°å—çš„å¸¸é‡æ± ä¸­ï¼Œè¿™ä¼šè¿”å›è¯¥å¸¸é‡åœ¨æ•°ç»„ä¸­çš„ç´¢å¼•ï¼Œç„¶åï¼Œæˆ‘ä»¬ç¼–å†™å¸¸é‡æŒ‡ä»¤ï¼Œä»å…¶æ“ä½œç å¼€å§‹ï¼Œä¹‹åï¼Œæˆ‘ä»¬å†™å…¥ä¸€ä¸ªå­—èŠ‚çš„å¸¸é‡ç´¢å¼•æ“ä½œæ•°ï¼Œè¯·æ³¨æ„ï¼ŒwriteChunk() å¯ä»¥å†™å…¥æ“ä½œæ•°æˆ–è€…æ“ä½œç ã€‚åœ¨è¯¥å‡½æ•°çœ‹æ¥ï¼Œéƒ½æ˜¯åŸå§‹å­—èŠ‚

å¦‚æœæˆ‘ä»¬ç°åœ¨å°è¯•è¿è¡Œï¼Œåæ±‡ç¼–å™¨ä¼šå› ä¸ºï¼Œä¸çŸ¥é“å¦‚ä½•è§£ç æ–°æŒ‡ä»¤ï¼Œè€Œå‡ºé”™ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è§£å†³è¿™ä¸ªé—®é¢˜

```c

// debug.c, in disassembleInstruction()

  switch (instruction) {
    case OP_CONSTANT:
      return constantInstruction("OP_CONSTANT", chunk, offset);
    case OP_RETURN:
		
```

This instruction has a different instruction format, so we write a new helper function to disassemble it.

ç”±äºè¿™ä¸ªæŒ‡ä»¤æœ‰ä¸åŒçš„æŒ‡ä»¤æ ¼å¼ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬ç¼–å†™ä¸€ä¸ªæ–°çš„è¾…åŠ©å‡½æ•°ï¼Œç”¨äºåæ±‡ç¼–å®ƒ

```c

// debug.c, add after disassembleChunk()

static int constantInstruction(const char* name, Chunk* chunk,
                               int offset) {
  uint8_t constant = chunk->code[offset + 1];
  printf("%-16s %4d '", name, constant);
  printValue(chunk->constants.values[constant]);
  printf("'\n");
}

```

Thereâ€™s more going on here. As with OP_RETURN, we print out the name of the opcode. Then we pull out the constant index from the subsequent byte in the chunk. We print that index, but that isnâ€™t super useful to us human readers. So we also look up the actual constant valueâ€”since constants are known at compile time after allâ€”and display the value itself too.

This requires some way to print a clox Value. That function will live in the â€œvalueâ€ module, so we include that.

è¿™é‡Œæœ‰æ›´å¤šçš„å†…å®¹ï¼Œå’ŒOP_RETURN æŒ‡ä»¤ä¸€æ ·ï¼Œæˆ‘ä»¬æ‰“å°æ“ä½œç çš„åç§°ï¼Œç„¶åï¼Œæˆ‘ä»¬ä»chunkçš„ä¸‹ä¸€ä¸ªå­—èŠ‚ä¸­ï¼Œæå–å¸¸é‡çš„ç´¢å¼•ï¼Œæˆ‘ä»¬æ‰“å°è¯¥ç´¢å¼•ï¼Œä½†æ˜¯å¯¹äºè¯»è€…æ¥è¯´ï¼Œå¸¸é‡çš„ç´¢å¼•ï¼Œå¹¶ä¸éå¸¸æœ‰ç”¨ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æŸ¥æ‰¾å®é™…çš„å¸¸é‡æ•°å€¼ï¼Œå¹¶ä¸”æ˜¾ç¤ºè¯¥å€¼æœ¬èº«ã€‚

ç”±äºå¸¸é‡åœ¨ç¼–è¯‘æ—¶å€™ï¼Œå·²çŸ¥ï¼Œå› æ­¤ï¼Œè¿™éœ€è¦æŸç§æ–¹å¼æ¥æ‰“å°cloxçš„å€¼ï¼Œè¿™ä¸ªå‡½æ•°å°†å­˜åœ¨äºvalue æ¨¡å—ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å¼•å…¥ value.h

```c

// debug.c

#include "debug.h"
#include "value.h"

void disassembleChunk(Chunk* chunk, const char* name) {

```

Over in that header, we declare:

```c

// value.h, add after freeValueArray()

void freeValueArray(ValueArray* array);
void printValue(Value value);

#endif

```

And hereâ€™s an implementation:

```c

// value.c, add after freeValueArray()

void printValue(Value value) {
  printf("%g", value);
}

```

Magnificent, right? As you can imagine, this is going to get more complex once we add dynamic typing to Lox and have values of different types.

Back in constantInstruction(), the only remaining piece is the return value.

è¿™å¾ˆæ£’ï¼Œä¸æ˜¯å—ï¼Ÿæ­£å¦‚ä½ æƒ³è±¡çš„é‚£æ ·ï¼Œä¸€æ—¦æˆ‘ä»¬åœ¨cloxä¸­ï¼Œæ·»åŠ äº†åŠ¨æ€ç±»å‹ï¼Œå¹¶å…·æœ‰ä¸åŒç±»å‹çš„å€¼ï¼Œè¿™å°†å˜å¾—æ›´åŠ å¤æ‚

å›åˆ°constantInstruction(), å”¯ä¸€å‰©ä¸‹çš„éƒ¨åˆ†å°±æ˜¯è¿”å›å€¼äº†

```c 

// debug.c, in constantInstruction()

  printf("'\n");
  return offset + 2;
}

```

Remember that disassembleInstruction() also returns a number to tell the caller the offset of the beginning of the next instruction. Where OP_RETURN was only a single byte, OP_CONSTANT is twoâ€”one for the opcode and one for the operand.

è®°ä½ï¼ŒdisassembleInstruction() è¿˜ä¼šè¿”å›ä¸€ä¸ªæ•°å­—ï¼Œå‘Šè¯‰è°ƒç”¨è€…ä¸‹ä¸€æ¡æŒ‡ä»¤çš„åç§»é‡ï¼Œå…¶ä¸­ OP_RETURN æŒ‡ä»¤åªæœ‰ä¸€ä¸ªå­—èŠ‚ï¼Œè€Œ OP_CONSTANT æŒ‡ä»¤æœ‰ä¸¤ä¸ªå­—èŠ‚â€”â€”ä¸€ä¸ªæ˜¯æ“ä½œç ï¼Œå¦å¤–ä¸€ä¸ªæ˜¯æ“ä½œæ•°

```c

== test chunk ==
0000 OP_CONSTANT         0 '1.2'
0002 OP_RETURN

```


## å…­ã€Line Information

è¡Œä¿¡æ¯

Chunks contain almost all of the information that the runtime needs from the userâ€™s source code. Itâ€™s kind of crazy to think that we can reduce all of the different AST classes that we created in jlox down to an array of bytes and an array of constants. Thereâ€™s only one piece of data weâ€™re missing. We need it, even though the user hopes to never see it.

å—åŒ…å«äº†è¿è¡Œæ—¶å€™ï¼Œä»ç”¨æˆ·æºä»£ç ä¸­éœ€è¦çš„å‡ ä¹æ‰€æœ‰ä¿¡æ¯ï¼Œåœ¨jloxä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºçš„æ‰€æœ‰ä¸åŒçš„ASTç±»ï¼Œåœ¨cloxä¸­ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥ç®€åŒ–ä¸ºä¸€ç³»åˆ—çš„å­—èŠ‚å’Œå¸¸é‡æ•°ç»„ï¼Œè¿™ä¼¼ä¹æœ‰ç‚¹ç–¯ç‹‚ï¼Œæˆ‘ä»¬åªæ˜¯ç¼ºå°‘ä¸€ä¸ªæ•°æ®ç‰‡æ®µï¼Œå³ä½¿ç”¨æˆ·å¸Œæœ›æ°¸è¿œä¸ä¼šçœ‹åˆ°å®ƒï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦å®ƒã€‚

When a runtime error occurs, we show the user the line number of the offending source code. In jlox, those numbers live in tokens, which we in turn store in the AST nodes. We need a different solution for clox now that weâ€™ve ditched syntax trees in favor of bytecode. Given any bytecode instruction, we need to be able to determine the line of the userâ€™s source program that it was compiled from.

There are a lot of clever ways we could encode this. I took the absolute simplest approach I could come up with, even though itâ€™s embarrassingly inefficient with memory. In the chunk, we store a separate array of integers that parallels the bytecode. Each number in the array is the line number for the corresponding byte in the bytecode. When a runtime error occurs, we look up the line number at the same index as the current instructionâ€™s offset in the code array.

å½“è¿è¡Œæ—¶ï¼Œå‘ç”Ÿäº†é”™è¯¯ï¼Œæˆ‘ä»¬ä¼šæ˜¾ç¤ºé”™è¯¯çš„ä»£ç è¡Œå·ç»™ç”¨æˆ·ï¼Œåœ¨jloxä¸­ï¼Œè¿™äº›æ•°å­—å­˜å‚¨åœ¨tokenä¸­ï¼Œè€Œæˆ‘ä»¬å°† tokenä¿å­˜åœ¨ASTç±»èŠ‚ç‚¹ä¸­ï¼Œæ—¢ç„¶æˆ‘ä»¬å·²ç»æ”¾å¼ƒäº†è¯­æ³•æ ‘ï¼Œè€Œä½¿ç”¨å­—èŠ‚ç ã€‚é‚£ä¹ˆï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸åŒçš„è§£å†³æ–¹æ¡ˆã€‚é’ˆå¯¹ä»»ä½•çš„å­—èŠ‚ç æŒ‡ä»¤ï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿç¡®å®šå®ƒç¼–è¯‘è‡ªç”¨æˆ·åŸå§‹ç¨‹åºçš„è¡Œæ•°

æœ‰å¾ˆå¤šå¥½çš„ç¼–ç æ–¹å¼å¯ä¾›é€‰æ‹©ï¼Œæˆ‘é€‰æ‹©èƒ½æƒ³åˆ°çš„æœ€ç®€å•çš„æ–¹å¼ï¼Œå°½ç®¡ï¼Œå®ƒåœ¨å†…å­˜ä½¿ç”¨æ–¹é¢ï¼Œæ•ˆç‡éå¸¸ä½ã€‚åœ¨å—ä¸­ï¼Œæˆ‘ä»¬å­˜å‚¨ä¸€ä¸ªä¸å­—èŠ‚ç å¯¹åº”çš„æ•´æ•°æ•°ç»„ï¼Œæ•°ç»„ä¸­çš„æ¯ä¸ªæ•°å­—éƒ½æ˜¯å¯¹åº”äºå­—èŠ‚ç ä¸­çš„å­—èŠ‚çš„è¡Œå·ï¼Œå½“è¿è¡ŒæŠ¥é”™æ—¶å€™ï¼Œæˆ‘ä»¬æŸ¥æ‰¾ä¸ä»£ç æ•°ç»„ä¸­ï¼Œå½“å‰æŒ‡ä»¤åç§»é‡ç›¸åŒç´¢å¼•å¤„çš„è¡Œå·

To implement this, we add another array to Chunk.

ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åœ¨chunkä¸­æ·»åŠ å¦ä¸€ä¸ªæ•°ç»„

```c

// chunk.h, in struct Chunk

  uint8_t* code;
  int* lines;
  ValueArray constants;
	
```

Since it exactly parallels the bytecode array, we donâ€™t need a separate count or capacity. Every time we touch the code array, we make a corresponding change to the line number array, starting with initialization.

ç”±äºå®ƒå’Œå­—èŠ‚ç æ•°ç»„å®Œå…¨ç›¸å¯¹åº”ï¼Œå› æ­¤æˆ‘ä»¬ä¸éœ€è¦å•ç‹¬çš„è®¡æ•°æˆ–è€…å®¹é‡å­—æ®µï¼Œæ¯ä¸€æ¬¡æˆ‘ä»¬æ“ä½œä»£ç æ•°ç»„æ—¶å€™ï¼Œéƒ½ä¼šè¿›è¡Œç›¸åº”çš„æ›´æ”¹ï¼Œæ›´æ–°è¡Œå·æ•°ç»„ï¼Œä»åˆå§‹åŒ–å¼€å§‹ã€‚

```c

// chunk.c, in initChunk()

  chunk->code = NULL;
  chunk->lines = NULL;
  initValueArray(&chunk->constants);
	
```

And likewise deallocation:

åŒæ ·ï¼Œåœ¨é‡Šæ”¾å†…å­˜æ—¶å€™

```c

// chunk.c, in freeChunk()

  FREE_ARRAY(uint8_t, chunk->code, chunk->capacity);
  FREE_ARRAY(int, chunk->lines, chunk->capacity);
  freeValueArray(&chunk->constants);
	
```

When we write a byte of code to the chunk, we need to know what source line it came from, so we add an extra parameter in the declaration of writeChunk().

å½“æˆ‘ä»¬åƒchunkä¸­å†™å…¥ä¸€ä¸ªå­—èŠ‚çš„ä»£ç æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒæ¥è‡ªäºå“ªä¸€è¡Œæºä»£ç ï¼Œå› æ­¤æˆ‘ä»¬åœ¨ï¼Œå£°æ˜writeChunk()æ—¶å€™ï¼Œæ·»åŠ äº†ä¸€ä¸ªé¢å¤–çš„å‚æ•°

```c

// chunk.h, function writeChunk(), replace 1 line

void freeChunk(Chunk* chunk);
void writeChunk(Chunk* chunk, uint8_t byte, int line);
int addConstant(Chunk* chunk, Value value);

```

And in the implementation:

```c

// chunk.c, function writeChunk(), replace 1 line

void writeChunk(Chunk* chunk, uint8_t byte, int line) {
  if (chunk->capacity < chunk->count + 1) {


```

When we allocate or grow the code array, we do the same for the line info too.

å½“æˆ‘ä»¬åˆ†é…æˆ–è€…æ‰©å±•ä»£ç æ•°ç»„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¼šå¯¹è¡Œä¿¡æ¯ï¼Œæä¾›ç›¸åŒçš„æ“ä½œ

```c

// chunk.c, in writeChunk()

    chunk->code = GROW_ARRAY(uint8_t, chunk->code,
        oldCapacity, chunk->capacity);
    chunk->lines = GROW_ARRAY(int, chunk->lines,
        oldCapacity, chunk->capacity);
  }


```

Finally, we store the line number in the array.

```c

// chunk.c, in writeChunk()

  chunk->code[chunk->count] = byte;
  chunk->lines[chunk->count] = line;
  chunk->count++;
	
```


### 6.1 Disassembling line information

åæ±‡ç¼–è¡Œä¿¡æ¯

Alright, letâ€™s try this out with our little, uh, artisanal chunk. First, since we added a new parameter to writeChunk(), we need to fix those calls to pass in someâ€”arbitrary at this pointâ€”line number.

å¥½çš„ï¼Œè®©æˆ‘ä»¬å®è·µä¸€ä¸‹è¡Œä¿¡æ¯ï¼Œé¦–å…ˆï¼Œç”±äºæˆ‘ä»¬éœ€è¦å‘wirteChunk() æ·»åŠ ä¸€ä¸ªæ–°å‚æ•°ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ›´æ–°ä¸€ä¸‹è°ƒç”¨ï¼Œä¼ é€’è¡Œå·ä¿¡æ¯ï¼ˆæ­¤æ—¶æ˜¯ä»»æ„çš„ï¼‰


```c

// main.c, in main(), replace 4 lines

  int constant = addConstant(&chunk, 1.2);
  writeChunk(&chunk, OP_CONSTANT, 123);
  writeChunk(&chunk, constant, 123);

  writeChunk(&chunk, OP_RETURN, 123);

  disassembleChunk(&chunk, "test chunk");


```

Once we have a real front end, of course, the compiler will track the current line as it parses and pass that in.

Now that we have line information for every instruction, letâ€™s put it to good use. In our disassembler, itâ€™s helpful to show which source line each instruction was compiled from. That gives us a way to map back to the original code when weâ€™re trying to figure out what some blob of bytecode is supposed to do. After printing the offset of the instructionâ€”the number of bytes from the beginning of the chunkâ€”we show its source line.

å½“ç„¶ï¼Œå½“æˆ‘ä»¬æ‹¥æœ‰äº†çœŸæ­£çš„å‰ç«¯ï¼Œç¼–è¯‘å™¨å°†ä¼šåœ¨è§£ææ—¶å€™ï¼Œè¿½è¸ªå½“å‰è¡Œå¹¶ä¼ é€’è¡Œå·ã€‚

ç°åœ¨æˆ‘ä»¬çš„æ¯ä¸€ä¸ªæŒ‡ä»¤éƒ½æœ‰äº†è¡Œå·ä¿¡æ¯ï¼Œè®©æˆ‘ä»¬å¥½å¥½åˆ©ç”¨å®ƒã€‚åœ¨æˆ‘ä»¬çš„åæ±‡ç¼–å™¨ä¸­ï¼Œæ˜¾ç¤ºæ¯ä¸ªæŒ‡ä»¤ç¼–è¯‘æºè‡ªå“ªä¸ªæºä»£ç è¡Œï¼Œæ˜¯æœ‰ç”¨çš„ã€‚è¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§ï¼Œåœ¨ç¡®å®šæŸä¸ªå­—èŠ‚ç åº”è¯¥æ‰§è¡ŒæŸäº›æ“ä½œæ—¶å€™ï¼Œå¯ä»¥æ˜ å°„å›åŸå§‹ä»£ç çš„æ–¹å¼ï¼Œåœ¨æ‰“å°æŒ‡ä»¤çš„åç§»é‡ï¼ˆä»å—çš„å¼€å¤´ç®—èµ·çš„å­—èŠ‚æ•°ï¼‰ä¹‹åï¼Œæˆ‘ä»¬å°†æ˜¾ç¤ºå®ƒçš„æºä»£ç è¡Œæ•°

```c

// debug.c, in disassembleInstruction()

int disassembleInstruction(Chunk* chunk, int offset) {
  printf("%04d ", offset);
  if (offset > 0 &&
      chunk->lines[offset] == chunk->lines[offset - 1]) {
    printf("   | ");
  } else {
    printf("%4d ", chunk->lines[offset]);
  }

  uint8_t instruction = chunk->code[offset];
	
```

Bytecode instructions tend to be pretty fine-grained. A single line of source code often compiles to a whole sequence of instructions. To make that more visually clear, we show a | for any instruction that comes from the same source line as the preceding one. The resulting output for our handwritten chunk looks like:

å­—èŠ‚ç æŒ‡ä»¤ï¼Œé€šå¸¸éå¸¸ç»†ç²’åº¦ï¼Œä¸€è¡Œæºä»£ç é€šå¸¸ç¼–è¯‘ä¸ºæ•´ä¸ªæŒ‡ä»¤åºåˆ—ã€‚ä¸ºäº†è®©è¡Œä¿¡æ¯ï¼Œæ›´åŠ æ¸…æ™°ï¼Œæˆ‘ä»¬åœ¨ä»»ä½•æ¥è‡ªä¸å‰ä¸€ä¸ªæŒ‡ä»¤ç›¸åŒæºä»£ç è¡Œæ•°çš„æŒ‡ä»¤ä¹‹é—´æ˜¾ç¤ºä¸€ä¸ª | ï¼Œä¸‹é¢æ˜¯ï¼Œæˆ‘ä»¬è¿è¡Œçš„ç»“æœ

```c

== test chunk ==
0000  123 OP_CONSTANT         0 '1.2'
0002   | OP_RETURN


```


We have a three-byte chunk. The first two bytes are a constant instruction that loads 1.2 from the chunkâ€™s constant pool. The first byte is the OP_CONSTANT opcode and the second is the index in the constant pool. The third byte (at offset 2) is a single-byte return instruction.

In the remaining chapters, we will flesh this out with lots more kinds of instructions. But the basic structure is here, and we have everything we need now to completely represent an executable piece of code at runtime in our virtual machine. Remember that whole family of AST classes we defined in jlox? In clox, weâ€™ve reduced that down to three arrays: bytes of code, constant values, and line information for debugging.

This reduction is a key reason why our new interpreter will be faster than jlox. You can think of bytecode as a sort of compact serialization of the AST, highly optimized for how the interpreter will deserialize it in the order it needs as it executes. In the next chapter, we will see how the virtual machine does exactly that.

æˆ‘ä»¬æœ‰ä¸€ä¸ªä¸‰å­—èŠ‚çš„chunkï¼Œå‰ä¸¤ä¸ªå­—èŠ‚æ˜¯ä¸€ä¸ªå¸¸é‡æŒ‡ä»¤ï¼Œå®ƒä»chunkçš„å¸¸é‡æ± ä¸­åŠ è½½1.2 ï¼Œ ç¬¬ä¸€ä¸ªå­—èŠ‚æ˜¯ OP_CONSTANT æ“ä½œç ï¼Œç¬¬äºŒä¸ªæ˜¯å¸¸é‡æ± ä¸­çš„ç´¢å¼•ï¼Œç¬¬ä¸‰ä¸ªå­—èŠ‚æ˜¯ï¼ˆåœ¨åç§»é‡2å¤„ï¼‰æ˜¯ä¸€ä¸ªå•å­—èŠ‚çš„è¿”å›æŒ‡ä»¤ã€‚

åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ›´å¤šç§ç±»çš„æŒ‡ä»¤æ¥æ‰©å±•å®ƒã€‚ä½†æ˜¯åŸºæœ¬ç»“æ„å·²ç»åœ¨è¿™é‡Œäº†ï¼Œæˆ‘ä»¬ç°åœ¨æ‹¥æœ‰äº†åœ¨è™šæ‹Ÿæœºä¸­å®Œå…¨è¡¨ç¤ºå¯æ‰§è¡Œä»£ç æ‰€éœ€çš„ä¸€åˆ‡ï¼Œè¿˜è®°å¾—æˆ‘ä»¬åœ¨jloxä¸­ï¼Œå®šä¹‰çš„æ•´ä¸ªASTç±»æ—å—ï¼Ÿåœ¨cloxä¸­ï¼Œæˆ‘ä»¬å°†å…¶ç®€åŒ–ä¸ºä¸‰ä¸ªæ•°ç»„: ä»£ç å­—èŠ‚æ•°ç»„ã€å¸¸é‡å€¼æ•°ç»„ã€ç”¨äºè°ƒè¯•çš„è¡Œä¿¡æ¯æ•°ç»„

è¿™ç§ç®€åŒ–æ˜¯æˆ‘ä»¬çš„æ–°è§£é‡Šå™¨ï¼Œæ¯”jloxæ›´å¿«çš„æœ€é‡è¦åŸå› ä¹‹ä¸€ï¼Œä½ å¯ä»¥å°†å­—èŠ‚ç è§†ä¸ºASTçš„ä¸€ç§ç´§å‡‘çš„åºåˆ—åŒ–å½¢å¼ï¼Œé«˜åº¦ä¼˜åŒ–ï¼Œä»¥ä¾¿äºè§£é‡Šå™¨æŒ‰ç…§éœ€è¦æ‰§è¡Œçš„é¡ºåºï¼Œååºåˆ—åŒ–å®ƒã€‚åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è™šæ‹Ÿæœºå¦‚ä½•å®Œå…¨åšåˆ°è¿™ä¸€ç‚¹ã€‚
