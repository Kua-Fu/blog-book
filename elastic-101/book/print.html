<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>elastic-101</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">简介</a></li><li class="chapter-item expanded affix "><li class="part-title">技术文章</li><li class="chapter-item expanded "><a href="article/office/blog.html"><strong aria-hidden="true">1.</strong> elasticsearch 官方博客</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="article/office/blog/bulk-reject.html"><strong aria-hidden="true">1.1.</strong> bulk 被拒绝</a></li></ol></li><li class="chapter-item expanded "><a href="article/office/api.html"><strong aria-hidden="true">2.</strong> elasticsearch 接口文档</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="article/office/ism.html"><strong aria-hidden="true">2.1.</strong> 华为云CSS生命周期管理</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">实际使用</li><li class="chapter-item expanded "><a href="use/backup/backup.html"><strong aria-hidden="true">3.</strong> elasticsearch集群备份</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="use/backup/snapshot.html"><strong aria-hidden="true">3.1.</strong> 使用快照备份</a></li><li class="chapter-item expanded "><a href="use/backup/meta.html"><strong aria-hidden="true">3.2.</strong> 只备份集群中的策略、模版等信息</a></li></ol></li><li class="chapter-item expanded "><a href="use/reindex/reindex.html"><strong aria-hidden="true">4.</strong> reindex 过程</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="use/reindex/add-field.html"><strong aria-hidden="true">4.1.</strong> reindex添加新字段</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">业务报错处理</li><li class="chapter-item expanded affix "><li class="part-title">原理源码</li><li class="chapter-item expanded "><a href="lucene/intro.html"><strong aria-hidden="true">5.</strong> lucene介绍</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">elastic-101</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="简介"><a class="header" href="#简介">简介</a></h1>
<p>elastic-101 将介绍一系列 elasticsearch 相关的技术概念、原理，总结自己开发过程中遇到的问题。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="官方博客"><a class="header" href="#官方博客">官方博客</a></h1>
<ol>
<li><a href="https://www.elastic.co/cn/blog/why-am-i-seeing-bulk-rejections-in-my-elasticsearch-cluster">Why am I seeing bulk rejections in my Elasticsearch cluster?</a></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bulk-被拒绝"><a class="header" href="#bulk-被拒绝">bulk 被拒绝</a></h1>
<p><a href="https://www.elastic.co/cn/blog/why-am-i-seeing-bulk-rejections-in-my-elasticsearch-cluster">原文: Why am I seeing bulk rejections in my Elasticsearch cluster?</a></p>
<p>Elasticsearch supports a wide range of use-cases across our user base, and more and more of these rely on fast indexing to quickly get large amounts of data into Elasticsearch. Even though Elasticsearch is fast and index performance is continually improved, it is still possible to overwhelm it. At that point you typically see parts of bulk requests getting rejected. In this blog post we will look at the causes and how to avoid it.</p>
<p>在我们的用户群了 elasticsearch 有广泛的使用管理，越来越多的客户依赖大量数据的快速索引。尽管 elasticsearch 速度很快，索引性能也在不断提高，仍然可能达到峰值。此时，通常可以看到部分写入请求被拒绝。下文将探讨原因和如何避免请求被拒绝。</p>
<p>This is the second installment in a series of blog posts where we look at and discuss your common questions. The first installment discussed and provided guidelines around &quot;How many shards one should aim to have in an Elasticsearch cluster?&quot;</p>
<p>这是一系列文章中的第二篇。第一部分文章可以详见 <a href="https://www.elastic.co/cn/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster">How many shards one should aim to have in an Elasticsearch cluster?</a></p>
<h2 id="what-happens-when-a-bulk-indexing-request-is-sent-to-elasticsearch"><a class="header" href="#what-happens-when-a-bulk-indexing-request-is-sent-to-elasticsearch">What happens when a bulk indexing request is sent to Elasticsearch?</a></h2>
<p>当一个 bulk 请求发送到elasticsearch, 请求后会发生什么?</p>
<p>Let’s start at the beginning and look at what happens behind the scenes when a bulk indexing request is sent to Elasticsearch.</p>
<p>让我们从头开始，看看当批量索引请求发送到 elasticsearch 时候，后台会发生什么?</p>
<p>When a bulk request arrives at a node in the cluster, it is, in its entirety, put on the bulk queue and processed by the threads in the bulk thread pool. The node that receives the request is referred to as the coordinating node as it manages the life of the request and assembles the response. This can be a node dedicated to just coordinating requests or one of the data nodes in the cluster.</p>
<p>当 bulk 请求到达集群中的某个节点时候，请求被添加到 bulk请求队列中，并且该请求会被 bulk线程池中的线程处理。接收请求的节点被称为协调节点，因为它会管理请求的生命周期并且响应客户端请求。协调节点可以是一个专有节点，也可以是集群中的一个数据节点，承担着协调功能。</p>
<p>A bulk request can contain documents destined for multiple indices and shards. The first processing step is therefore to split it up based on which shards the documents need to be routed to. Once this is done, each bulk sub-request is forwarded to the data node that holds the corresponding primary shard, and it is there enqueued on that node’s bulk queue. If there is no more space available on the queue, the coordinating node will be notified that the bulk sub-request has been rejected.</p>
<p>The bulk thread pool processes requests from the queue and documents are forwarded to replica shards as part of this processing. Once the sub-request has completed, a response is sent to the coordinating node.</p>
<p>Once all sub-requests have completed or been rejected, a response is created and returned to the client. It is possible, and even likely, that only a portion of the documents within a bulk request might have been rejected.</p>
<p>一个 bulk 请求可以包含指向多个索引多个分片的文档。bulk 请求</p>
<p>（1）第一个步骤会把请求拆分到不同的分片中，根据文档信息，计算路由到的分片；</p>
<p>（2）第二个步骤会把被拆分的子请求分发到主分片节点，子请求会被添加到对应节点的bulk请求队列；</p>
<p>（3）如果子请求所对应的节点 bulk请求队列已经占满，则协调节点会收到拒绝请求通知；</p>
<p>（4）主分片节点存在大容量的线程池，用于处理 bulk子请求，并且会将文档转发到副本节点，副本节点文档bulk也是bulk子请求的一部分，当bulk子请求处理完成，协调节点将收到响应；</p>
<p>（5）当所有的子请求都完成或者拒绝，客户端将接收到bulk响应。有可能的场景是，部分文档写入被拒绝，部分文档写入成功。</p>
<p>The reason Elasticsearch is designed with request queues of limited size is to protect the cluster from being overloaded, which increases stability and reliability. If there were no limits in place, clients could very easily bring a whole cluster down through bad or malicious behaviour. The limits that are in place have been set based on our extensive experience supporting Elasticsearch for different types of use-cases.</p>
<p>设计bulk请求队列，并且限制队列长度，是为了防止请求过多，导致集群过载，可以提高集群稳定性和可靠性。如果没有长度限制的请求队列机制，客户端很容易由于不合适操作，或者恶意操作，使得集群崩溃🐴。根据现有客户的实际使用场景经验，我们设置了现有的队列长度。</p>
<p>When using the HTTP interface, requests that results in at least a partial rejection will return with response code 429, 'Too many requests'. The principle also applies when the transport protocol is used, although the protocol and interface naturally is different. Applications and clients may report these errors back to the user in different ways, and some may even attempt to handle this automatically by retrying any rejected documents.</p>
<p>当通过 http协议发送bulk请求时，如果bulk请求中存在部分被拒绝的子请求，bulk请求的返回状态码是429，表示请求太多。当通过 tcp协议发送bulk请求时，这个原则也是一样，但是协议和接口会有不同表现。bulk请求的客户端（可能是某个应用）会将429报错以不同方式报告给用户。客户端程序可能会在接收到429报错后，自动重试，继续上传写入失败文档。</p>
<h2 id="how-can-we-test-this-in-practice"><a class="header" href="#how-can-we-test-this-in-practice">How can we test this in practice?</a></h2>
<p>如果实际测试bulk请求？</p>
<p>In order to illustrate the practical impact of this behaviour, we devised a simple test where we use our benchmarking tool Rally to run bulk indexing requests against a couple of Elastic Cloud clusters with varying number of data nodes. Configuration and instructions on how to run Rally is available in this gist.</p>
<p>The same indexing workload was run against three different Elastic Cloud clusters. We have been indexing with one replica shard configured wherever possible. The clusters consisted of one, two and three data nodes respectively, with each data node having 8GB RAM (4GB heap for Elasticsearch, 4GB native memory). Invoking the GET /_nodes/thread_pool API we could see that each data node by default had a fixed bulk thread pool size of two with a queue size of 200:</p>
<pre><code class="language-json">
%&gt; curl -XGET http://&lt;es_url&gt;:&lt;es_port&gt;/_nodes/thread_pool&lt;/es_port&gt;&lt;/es_url&gt;
&quot;bulk&quot;: {
&quot;type&quot;: &quot;fixed&quot;,
&quot;min&quot;: 2,
&quot;max&quot;: 2,
&quot;queue_size&quot;: 200
}

</code></pre>
<p>下面我们设计了一个简单的测试，测试bulk性能，测试工具是 <a href="https://github.com/elastic/rally">rally</a>，测试多个具有不同节点的集群。</p>
<p>在三个不同配置的ES实例，我们会执行相同的bulk请求测试。三个ES实例，分别是1个节点、2个节点、3个节点，其中每个节点配置都是相同的（ 8GB 内存，4G设置为ES 堆内存，4G设置为节点内存）。可以通过接口<code>GET /_nodes/thread_pool</code> 接口查看</p>
<pre><pre class="playground"><code class="language-rust">
<span class="boring">#![allow(unused)]
</span>
<span class="boring">fn main() {
</span>GET _nodes/thread_pool

<span class="boring">
</span><span class="boring">&quot;_nodes&quot;: {
</span><span class="boring">  &quot;total&quot;: 3,
</span><span class="boring">  &quot;successful&quot;: 3,
</span><span class="boring">  &quot;failed&quot;: 0
</span><span class="boring">},
</span><span class="boring">&quot;cluster_name&quot;: &quot;a2ff16d9aa2645dc87ab1714e6e16a84&quot;,
</span><span class="boring">&quot;nodes&quot;: {
</span><span class="boring">  &quot;juVnJa6TQ7a2c3v065Gz3w&quot;: {
</span><span class="boring">    &quot;name&quot;: &quot;instance-0000000000&quot;,
</span><span class="boring">    &quot;transport_address&quot;: &quot;10.42.10.154:19303&quot;,
</span><span class="boring">    &quot;host&quot;: &quot;10.42.10.154&quot;,
</span><span class="boring">    &quot;ip&quot;: &quot;10.42.10.154&quot;,
</span><span class="boring">    &quot;version&quot;: &quot;8.3.1&quot;,
</span><span class="boring">    &quot;build_flavor&quot;: &quot;default&quot;,
</span><span class="boring">    &quot;build_type&quot;: &quot;docker&quot;,
</span><span class="boring">    &quot;build_hash&quot;: &quot;b9a6b2867996ba92ceac66cb5bafc6db25e7910e&quot;,
</span><span class="boring">    &quot;roles&quot;: [
</span><span class="boring">      &quot;data_content&quot;,
</span><span class="boring">      &quot;data_hot&quot;,
</span><span class="boring">      &quot;ingest&quot;,
</span><span class="boring">      &quot;master&quot;,
</span><span class="boring">      &quot;remote_cluster_client&quot;,
</span><span class="boring">      &quot;transform&quot;
</span><span class="boring">    ],
</span><span class="boring">    &quot;attributes&quot;: {
</span><span class="boring">      &quot;logical_availability_zone&quot;: &quot;zone-0&quot;,
</span><span class="boring">      &quot;server_name&quot;: &quot;instance-0000000000.a2ff16d9aa2645dc87ab1714e6e16a84&quot;,
</span><span class="boring">      &quot;availability_zone&quot;: &quot;us-central1-a&quot;,
</span><span class="boring">      &quot;xpack.installed&quot;: &quot;true&quot;,
</span><span class="boring">      &quot;data&quot;: &quot;hot&quot;,
</span><span class="boring">      &quot;instance_configuration&quot;: &quot;gcp.es.datahot.n2.68x10x45&quot;,
</span><span class="boring">      &quot;region&quot;: &quot;unknown-region&quot;
</span><span class="boring">    },
</span><span class="boring">    &quot;thread_pool&quot;: {
</span><span class="boring">      &quot;force_merge&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;search_coordination&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: 1000
</span><span class="boring">      },
</span><span class="boring">      &quot;searchable_snapshots_cache_fetch_async&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 0,
</span><span class="boring">        &quot;max&quot;: 6,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;ml_datafeed&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 1,
</span><span class="boring">        &quot;max&quot;: 512,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;1m&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;snapshot_meta&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 1,
</span><span class="boring">        &quot;max&quot;: 6,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;fetch_shard_started&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 1,
</span><span class="boring">        &quot;max&quot;: 4,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;rollup_indexing&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;search&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 4,
</span><span class="boring">        &quot;queue_size&quot;: 1000
</span><span class="boring">      },
</span><span class="boring">      &quot;cluster_coordination&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;security-crypto&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: 1000
</span><span class="boring">      },
</span><span class="boring">      &quot;ccr&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 32,
</span><span class="boring">        &quot;queue_size&quot;: 100
</span><span class="boring">      },
</span><span class="boring">      &quot;flush&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 1,
</span><span class="boring">        &quot;max&quot;: 1,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;fetch_shard_store&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 1,
</span><span class="boring">        &quot;max&quot;: 4,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;ml_utility&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">        &quot;core&quot;: 1,
</span><span class="boring">        &quot;max&quot;: 2048,
</span><span class="boring">        &quot;keep_alive&quot;: &quot;10m&quot;,
</span><span class="boring">        &quot;queue_size&quot;: -1
</span><span class="boring">      },
</span><span class="boring">      &quot;get&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 2,
</span><span class="boring">        &quot;queue_size&quot;: 1000
</span><span class="boring">      },
</span><span class="boring">      &quot;system_read&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: 2000
</span><span class="boring">      },
</span><span class="boring">      &quot;system_critical_read&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: 2000
</span><span class="boring">      },
</span><span class="boring">      &quot;write&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 2,
</span><span class="boring">        &quot;queue_size&quot;: 10000
</span><span class="boring">      },
</span><span class="boring">      &quot;watcher&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 10,
</span><span class="boring">        &quot;queue_size&quot;: 1000
</span><span class="boring">      },
</span><span class="boring">      &quot;security-token-key&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: 1000
</span><span class="boring">      },
</span><span class="boring">      &quot;system_critical_write&quot;: {
</span><span class="boring">        &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">        &quot;size&quot;: 1,
</span><span class="boring">        &quot;queue_size&quot;: 1500
</span><span class="boring">      },
</span><span class="boring">      &quot;refresh&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;repository_azure&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 5,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;vector_tile_generation&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;system_write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;generic&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 4,
</span><span class="boring">   &quot;max&quot;: 128,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;warmer&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;auto_complete&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> },
</span><span class="boring"> &quot;azure_event_loop&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;management&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 2,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;analyze&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 16
</span><span class="boring"> },
</span><span class="boring"> &quot;searchable_snapshots_cache_prewarming&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 16,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_job_comms&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 4,
</span><span class="boring">   &quot;max&quot;: 2048,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;1m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;snapshot&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search_throttled&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> }
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">nEBN-aVTcKiJfoT87LgKA&quot;: {
</span><span class="boring">&quot;name&quot;: &quot;instance-0000000001&quot;,
</span><span class="boring">&quot;transport_address&quot;: &quot;10.42.0.133:19375&quot;,
</span><span class="boring">&quot;host&quot;: &quot;10.42.0.133&quot;,
</span><span class="boring">&quot;ip&quot;: &quot;10.42.0.133&quot;,
</span><span class="boring">&quot;version&quot;: &quot;8.3.1&quot;,
</span><span class="boring">&quot;build_flavor&quot;: &quot;default&quot;,
</span><span class="boring">&quot;build_type&quot;: &quot;docker&quot;,
</span><span class="boring">&quot;build_hash&quot;: &quot;b9a6b2867996ba92ceac66cb5bafc6db25e7910e&quot;,
</span><span class="boring">&quot;roles&quot;: [
</span><span class="boring"> &quot;data_content&quot;,
</span><span class="boring"> &quot;data_hot&quot;,
</span><span class="boring"> &quot;ingest&quot;,
</span><span class="boring"> &quot;master&quot;,
</span><span class="boring"> &quot;remote_cluster_client&quot;,
</span><span class="boring"> &quot;transform&quot;
</span><span class="boring">],
</span><span class="boring">&quot;attributes&quot;: {
</span><span class="boring"> &quot;data&quot;: &quot;hot&quot;,
</span><span class="boring"> &quot;server_name&quot;: &quot;instance-0000000001.a2ff16d9aa2645dc87ab1714e6e16a84&quot;,
</span><span class="boring"> &quot;instance_configuration&quot;: &quot;gcp.es.datahot.n2.68x10x45&quot;,
</span><span class="boring"> &quot;region&quot;: &quot;unknown-region&quot;,
</span><span class="boring"> &quot;availability_zone&quot;: &quot;us-central1-b&quot;,
</span><span class="boring"> &quot;logical_availability_zone&quot;: &quot;zone-1&quot;,
</span><span class="boring"> &quot;xpack.installed&quot;: &quot;true&quot;
</span><span class="boring">},
</span><span class="boring">&quot;thread_pool&quot;: {
</span><span class="boring"> &quot;force_merge&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search_coordination&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;searchable_snapshots_cache_fetch_async&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 6,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_datafeed&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 512,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;1m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;snapshot_meta&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 6,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;fetch_shard_started&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 4,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;rollup_indexing&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 4,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;cluster_coordination&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;security-crypto&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;ccr&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 32,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> },
</span><span class="boring"> &quot;flush&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;fetch_shard_store&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 4,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_utility&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 2048,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;10m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;get&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 2,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;system_read&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 2000
</span><span class="boring"> },
</span><span class="boring"> &quot;system_critical_read&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 2000
</span><span class="boring"> },
</span><span class="boring"> &quot;write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 2,
</span><span class="boring">   &quot;queue_size&quot;: 10000
</span><span class="boring"> },
</span><span class="boring"> &quot;watcher&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 10,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;security-token-key&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;system_critical_write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1500
</span><span class="boring"> },
</span><span class="boring"> &quot;refresh&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;repository_azure&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 5,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;vector_tile_generation&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;system_write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;generic&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 4,
</span><span class="boring">   &quot;max&quot;: 128,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;warmer&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;auto_complete&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> },
</span><span class="boring"> &quot;azure_event_loop&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;management&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 2,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;analyze&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 16
</span><span class="boring"> },
</span><span class="boring"> &quot;searchable_snapshots_cache_prewarming&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 16,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_job_comms&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 4,
</span><span class="boring">   &quot;max&quot;: 2048,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;1m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;snapshot&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search_throttled&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> }
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">MZABTmcQSG3PvMWtK_Sjg&quot;: {
</span><span class="boring">&quot;name&quot;: &quot;tiebreaker-0000000002&quot;,
</span><span class="boring">&quot;transport_address&quot;: &quot;10.42.5.215:19463&quot;,
</span><span class="boring">&quot;host&quot;: &quot;10.42.5.215&quot;,
</span><span class="boring">&quot;ip&quot;: &quot;10.42.5.215&quot;,
</span><span class="boring">&quot;version&quot;: &quot;8.3.1&quot;,
</span><span class="boring">&quot;build_flavor&quot;: &quot;default&quot;,
</span><span class="boring">&quot;build_type&quot;: &quot;docker&quot;,
</span><span class="boring">&quot;build_hash&quot;: &quot;b9a6b2867996ba92ceac66cb5bafc6db25e7910e&quot;,
</span><span class="boring">&quot;roles&quot;: [
</span><span class="boring"> &quot;master&quot;,
</span><span class="boring"> &quot;voting_only&quot;
</span><span class="boring">],
</span><span class="boring">&quot;attributes&quot;: {
</span><span class="boring"> &quot;logical_availability_zone&quot;: &quot;tiebreaker&quot;,
</span><span class="boring"> &quot;availability_zone&quot;: &quot;us-central1-c&quot;,
</span><span class="boring"> &quot;server_name&quot;: &quot;tiebreaker-0000000002.a2ff16d9aa2645dc87ab1714e6e16a84&quot;,
</span><span class="boring"> &quot;xpack.installed&quot;: &quot;true&quot;,
</span><span class="boring"> &quot;data&quot;: &quot;hot&quot;,
</span><span class="boring"> &quot;instance_configuration&quot;: &quot;gcp.es.master.n2.68x32x45&quot;,
</span><span class="boring"> &quot;region&quot;: &quot;unknown-region&quot;
</span><span class="boring">},
</span><span class="boring">&quot;thread_pool&quot;: {
</span><span class="boring"> &quot;force_merge&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search_coordination&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;searchable_snapshots_cache_fetch_async&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 6,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_datafeed&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 512,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;1m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;snapshot_meta&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 6,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;fetch_shard_started&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 4,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;rollup_indexing&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 4,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;cluster_coordination&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;security-crypto&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;ccr&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 32,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> },
</span><span class="boring"> &quot;flush&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;fetch_shard_store&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 4,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_utility&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 2048,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;10m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;get&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 2,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;system_read&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 2000
</span><span class="boring"> },
</span><span class="boring"> &quot;system_critical_read&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 2000
</span><span class="boring"> },
</span><span class="boring"> &quot;write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 2,
</span><span class="boring">   &quot;queue_size&quot;: 10000
</span><span class="boring"> },
</span><span class="boring"> &quot;watcher&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;security-token-key&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;system_critical_write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1500
</span><span class="boring"> },
</span><span class="boring"> &quot;refresh&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;repository_azure&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 5,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;vector_tile_generation&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;system_write&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 1000
</span><span class="boring"> },
</span><span class="boring"> &quot;generic&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 4,
</span><span class="boring">   &quot;max&quot;: 128,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;warmer&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;auto_complete&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> },
</span><span class="boring"> &quot;azure_event_loop&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;management&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 2,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;analyze&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 16
</span><span class="boring"> },
</span><span class="boring"> &quot;searchable_snapshots_cache_prewarming&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 0,
</span><span class="boring">   &quot;max&quot;: 16,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;30s&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;ml_job_comms&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 4,
</span><span class="boring">   &quot;max&quot;: 2048,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;1m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;snapshot&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;scaling&quot;,
</span><span class="boring">   &quot;core&quot;: 1,
</span><span class="boring">   &quot;max&quot;: 1,
</span><span class="boring">   &quot;keep_alive&quot;: &quot;5m&quot;,
</span><span class="boring">   &quot;queue_size&quot;: -1
</span><span class="boring"> },
</span><span class="boring"> &quot;search_throttled&quot;: {
</span><span class="boring">   &quot;type&quot;: &quot;fixed&quot;,
</span><span class="boring">   &quot;size&quot;: 1,
</span><span class="boring">   &quot;queue_size&quot;: 100
</span><span class="boring"> }
</span><span class="boring">}
</span>
<span class="boring">}
</span></code></pre></pre>
<p>During the test we indexed into a varying number of shards (2, 4, 8, 16, and 32) using a varying number of concurrent clients (8, 16, 24, 32, 48, and 64) for each cluster. For every combination of shard and client count we indexed 6.4 million documents with a batch size of 100 documents and another 6.4 million documents with a batch size of 200 documents. This means that in total we attempted to index 384 million documents per cluster.</p>
<p>For this test we treat the clusters as a black box, and perform the analysis from the client’s perspective. To limit the scope we will also not look at the impact of various configurations on performance as that is a quite large topic on its own.</p>
<p>在测试中，</p>
<p>（1）我们并发写入设置不同的并发客户端，分别为 8/16/24/32/48/64 个客户端，</p>
<p>（2）索引分别设置不同的分片数，分别为 2/4/8/16/32 个分片数。</p>
<p>（3）批量写入设置不同的文档数，分别为 100/200个文档，</p>
<p>对于不同的设置，写入文档总数量都是相同的，每个集群最终将写入接近4亿文档。</p>
<p>在此次测试中，我们将集群视为一个黑盒子，并从客户的角度进行分析。为了限制范围，我们也不会考虑各种配置对于性能的影响，因为这是一个非常大的主题。</p>
<p>All the generated, detailed metrics were sent to a separate Elastic Cloud instance for analysis using Kibana. For each request Rally measures how many the documents in the bulk request were rejected and successful. Based on this data we can classify each request as successful, partially rejected, and fully rejected. A few requests also timed out, and these have also been included for completeness.</p>
<p>Unlike Beats and Logstash, Rally does not retry failed indexing requests, so each has the same number of requests executed but the final number of documents indexed varied from run to run depending on the volume of rejections.</p>
<p>所有测试指标，都会发送到一个独立的集群，并且使用kibana可视化。对于每个客户端 bulk请求，<code>rally</code>可以记录请求是否成功，如果失败，拒绝写入的文档数。根据<code>rally</code>记录数据，可以区分bulk请求成功/完全拒绝/部分拒绝。另外，还有一些请求超时，为了完整性起见，统计数据也会包含超时的请求。</p>
<p>与 beats 和 logstash不同，<code>rally</code>写入失败不会重试。因此，最终落到ES中文档数也会不同，因为有部分请求被拒绝了。</p>
<h2 id="how-bulk-rejection-frequency-depend-on-shard-count-clients-count-and-data-node-count"><a class="header" href="#how-bulk-rejection-frequency-depend-on-shard-count-clients-count-and-data-node-count">How bulk rejection frequency depend on shard count, clients count, and data node count?</a></h2>
<p>bulk写入拒绝频率和分片数量、客户端并发量、数据节点数之间有什么关联？</p>
<p>Bulk rejections occur when the bulk queues fill up. The number of queue slots that get used depends both on the number of concurrent requests, and the number of shards being indexed into. To measure this correlation we have added a calculated metric, client shard concurrency, to each run. This is defined as the number of shards being indexed into, multiplied by the number of concurrent indexing threads, and indicates how many queue slots would be needed to hold all bulk sub-requests.</p>
<p>当bulk队列占满后，后入的bulk请求将被拒绝。写入请求会使用的请求队列大小，取决于客户端的并发量和索引的分片数设置。为了准确描述相关性，引入一个新的指标，称为客户端分片并发量 = 客户端并发量 * 索引分片数。</p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic/101/bulk-rejection-blog-1.png?raw=true" alt="客户端分片并发量" /></p>
<p>In the graph below, we show how the percentage of requests that result in partial or full rejections, depends on the client shard concurrency for the three different clusters.</p>
<p>For clusters with one or two nodes we can see that appearance of bulk rejections start when the client shard concurrency level is somewhere between 192 and 256. This makes sense as each node has a bulk queue size of 200. For the cluster with 3 nodes we can see that it is able to handle even higher level of client shard concurrency without any bulk rejections appearing. </p>
<p>Once we get over this limit, we start seeing partial bulk rejections, where at least one sub-request has managed to get queued and processed. A relatively small portion of requests also result on full rejections as the concurrency level increases, especially for the single node cluster. </p>
<p>When we compare the single and two node clusters, we can see that the percentage of fully successful requests increases slightly and that there are fewer full rejections. This is expected, as the total bulk queue across the cluster is twice as large and requests are sent to all data nodes. Even though the total bulk queue size is twice as large across the cluster, the 2 node cluster does not appear able to handle twice the client shard concurrency of the single node cluster. This is likely due to the fact that distribution is not perfect and that the introduction of replica shards have resulted in each indexing operation requiring more work and being slower as a result. An important thing to note is also that all partial rejections are treated as equals in this graph. The number of rejected documents is not shown and does indeed vary depending on the cluster size, but we will shortly look at that in greater detail. </p>
<p>由上图可以看到，我们展示了三个集群里面，不同类型响应占比（写入成功/部分写入成功/写入全部失败/写入超时）。对于具有一个节点和两个节点的集群，可以看到，当客户端分片并发量达到 192～256，开始出现拒绝请求。这个是有意义的，因为根据<code>_nodes/thread_pool/</code>，每个节点的bulk队列大小为200。对于3个节点的集群，因为客户端分片并发量更大，可以看到 192~256 范围内不会出现拒绝请求。</p>
<p>还可以看到，对于3节点集群，当达到256限制以上，开始出现部分拒绝。当客户端分片并发量继续增加后，完全拒绝类型请求开始变多。</p>
<p>如果我们只是比较单节点和双节点的集群，可以看到双节点集群，完成成功的百分比更高，完全失败的百分比更低。这个结果在意料之中，因为双节点集群，可以接受bulk请求的bulk队列是单节点集群的两倍，并且双节点集群，有两个数据节点，都会接收bulk请求。但是，从图中，可以看到，双节点集群的处理能力并不是单节点集群的两倍。可能的原因如下：</p>
<p>（1）分片分发不一定是完美的，即不一定，每个节点都接收正好一半的bulk请求；</p>
<p>（2）副本分片的设置，导致双节点集群，bulk请求处理更耗时；</p>
<p>（3）需要注意到，上图中，部分被拒绝的请求，并没有详细的被拒绝文档数量，我们把所有部分被拒绝请求当作相同的类型，实际上部分被拒绝请求，可能包含非常不一样的拒绝文档数量。</p>
<p>当继续查看3节点集群，可以看到，只有当客户端分片并发量到达非常高时候，才会出现完全拒绝请求。</p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic/101/bulk-rejection-blog-2.png?raw=true" alt="详细bulk信息" /></p>
<p>上图展示了部分bulk失败的详细信息，主要包含了bulk失败的文档数量。</p>
<p>可以看到，对于3种类型集群，随着客户端分片并发量的增加，被拒绝的比例变大；但是随着节点的变多，拒绝的级别（可以任务是拒绝的文档数量）变小。</p>
<p>对于单节点集群、双节点集群，部分拒绝几乎在相同的客户端分片并发量产生，但不相同的是，单节点集群被拒绝文档数量增加的更快。这意味着，即使不同类型集群都发生了部分拒绝请求，更多节点集群，实际上会写入更多的文档。</p>
<h2 id="cant-i-just-get-around-this-by-increasing-the-bulk-queue-size"><a class="header" href="#cant-i-just-get-around-this-by-increasing-the-bulk-queue-size">Can’t I just get around this by increasing the bulk queue size?</a></h2>
<p>可以通过增加bulk请求队列长度，解决bulk请求429问题吗？</p>
<p>One of the most common reactions when faced with bulk rejections is to increase the size of the bulk queue. Why not set it to a really large value so you do not have to worry about this again?</p>
<p>Increasing the size of the queue is not likely to improve the indexing performance or throughput of your cluster. Instead it would just make the cluster queue up more data in memory, which is likely to result in bulk requests taking longer to complete. The more bulk requests there are in the queue, the more precious heap space will be consumed. If the pressure on the heap gets too large, it can cause a lot of other performance problems and even cluster instability.</p>
<p>Adjusting the queue sizes is therefore strongly discouraged, as it is like putting a temporary band-aid on the problem rather than actually fixing the underlying issue. So what else can we do improve the situation?</p>
<p>当面临bulk请求被拒绝场景，最常见的反应是为什么不增加请求队列长度，设置一个非常大的值，这样就不用担心bulk请求被拒绝了？</p>
<p>需要明确的是，增加请求队列长度不等于增加索引的性能和吞吐量。相反，增加队列长度会使得集群内存中存在更多排队中的请求，这样可能导致bulk请求会经过更长时间才能完成。越多的bulk请求，越多宝贵的集群堆内存就会被消耗。如果堆内存占用过大，可能会导致其他的性能问题，甚至让集群变得不稳定。</p>
<p>因此，我们强烈建议不要调整队列大小，因为通常改变队列长度只会临时改变被拒绝请求数量，但是不会根本上改变bulk请求被拒绝问题。那么，我们应该如何做，根本上解决问题呢？</p>
<h2 id="can-coordinating-only-nodes-help"><a class="header" href="#can-coordinating-only-nodes-help">Can coordinating only nodes help?</a></h2>
<p>专有协调节点会有帮助吗？</p>
<p>By introducing coordinating only nodes, the data nodes will be able to focus on processing sub-requests, as the request itself will not take up a slot on their bulk queue. This is generally good, but the actual benefit of this arrangement is likely to vary from use-case to use-case. In many use cases it does relatively little difference, and we see lots of successful indexing heavy use cases that do not use dedicated coordinating nodes.</p>
<p>通过引入专有协调节点，数据节点可以更加专注于处理bulk子请求，bulk请求不会占用请求队列。通常情况下，引入专有协调节点可以改善bulk请求被拒绝问题，但实际上是否改善，还是因为不同实际使用场景会有不同的答案。在很多的案例中，引入专有协调节点，改善几乎没有发生，我们遇到过很多的索引数据量很大的集群，根本没有使用专有协调节点。</p>
<h2 id="what-conclusions-can-we-draw"><a class="header" href="#what-conclusions-can-we-draw">What conclusions can we draw?</a></h2>
<p>我们可以得出什么结论？</p>
<p>As always, there is not necessarily any good one-size-fits-all solution, and the way to address bulk rejections will vary from use-case to use-case. If you see bulk rejections, try to understand why they are taking place and whether it is a single node or the whole cluster that is affected.</p>
<p>一如既往的，我们无法得到一个万能方法，可以解决所有不同场景的bulk请求被拒绝问题。不同的用户使用场景，往往最终使用不同的解决方案。如果你发现了bulk请求失败，请（1）尝试排查发生拒绝的原因；（2）是单个节点、还是整个集群都发生了bulk请求被拒绝。</p>
<p>如果是整个集群处于过载状态，而不是单个节点承担了过多的写入压力，可能要考虑集群扩容（横向添加节点或者纵向升级配置）。扩容后，整个集群bulk请求队列的总长度将变大，可以承担更多的写入压力。如果只是简单添加现有集群节点bulk请求队列的长度，即使临时解决了问题，实际上后面可能会面临更多的其他性能问题。</p>
<p>最后，还需要记住的是，bulk被拒绝并不代表所有的文档都写入失败，程序代码中需要考虑到只有一部分文档写入失败，要考虑这一部分文档的重传机制。可以参考logstash,beats 中的重传逻辑。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="elasticsearch-接口文档"><a class="header" href="#elasticsearch-接口文档">elasticsearch 接口文档</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="华为云css生命周期管理"><a class="header" href="#华为云css生命周期管理">华为云CSS生命周期管理</a></h1>
<h2 id="参考"><a class="header" href="#参考">参考</a></h2>
<blockquote>
<p><a href="https://support.huaweicloud.com/css_faq/css_02_0119.html">如何更新CSS生命周期策略？</a></p>
<p><a href="https://opendistro.github.io/for-elasticsearch-docs/docs/im/ism/">opendistro Index State Management</a></p>
</blockquote>
<h2 id="一简介"><a class="header" href="#一简介">一、简介</a></h2>
<p>华为云CSS服务，对应的生命周期管理，使用<code>aws opendistro</code>对应的生命周期管理。</p>
<h2 id="二索引状态管理"><a class="header" href="#二索引状态管理">二、索引状态管理</a></h2>
<p>If you analyze time-series data, you likely prioritize new data over old data. You might periodically perform certain operations on older indices, such as reducing replica count or deleting them.</p>
<p>Index State Management (ISM) is a plugin that lets you automate these periodic, administrative operations by triggering them based on changes in the index age, index size, or number of documents. Using the ISM plugin, you can define policies that automatically handle index rollovers or deletions to fit your use case.</p>
<p>如果分析时间序列数据，我们往往更乐于分析最新的数据，相比较于之前的老数据。你可能会对旧数据进行某些操作，例如: 缩少副本、删除过期数据。</p>
<p>ISM是一个插件，它允许你根据索引时间、索引大小、索引文档数量，去触发一些预先定义的管理操作，从而实现这些操作的自动化。通过ISM, 可以根据自己实际使用场景，定义索引滚动、删除策略。</p>
<p>For example, you can define a policy that moves your index into a read_only state after 30 days and then deletes it after a set period of 90 days. You can also set up the policy to send you a notification message when the index is deleted.</p>
<p>You might want to perform an index rollover after a certain amount of time or run a force_merge operation on an index during off-peak hours to improve search performance during peak hours.</p>
<p>例如：你可以定义一个策略，在写入数据30天后，将索引设置为只读状态，然后，在经过90天后，删除该索引。你还可以设置策略，在删除索引的时候，发送一个通知信息。</p>
<p>你可能希望在一定的时间后，滚动索引，或者在非写入高峰期，对索引执行<code>force_merge</code>操作，从而提高索引搜索性能。</p>
<h2 id="三基本概念"><a class="header" href="#三基本概念">三、基本概念</a></h2>
<h3 id="31-状态-states"><a class="header" href="#31-状态-states">3.1 状态 states</a></h3>
<p>A state is the description of the status that the managed index is currently in. A managed index can be in only one state at a time. Each state has associated actions that are executed sequentially on entering a state and transitions that are checked after all the actions have been completed.</p>
<p>This table lists the parameters that you can define for a state.</p>
<table><thead><tr><th>Field</th><th>Description</th><th>Type</th><th>Required</th></tr></thead><tbody>
<tr><td>name</td><td>the name of state</td><td>string</td><td>yes</td></tr>
<tr><td>actions</td><td>The actions to execute after entering a state. For more information, see Actions.</td><td>nested list of objects</td><td>yes</td></tr>
<tr><td>transitions</td><td>The next states and the conditions required to transition to those states. If no transitions exist, the policy assumes that it’s complete and can now stop managing the index. For more information, see Transitions.</td><td>nested list of objects</td><td>yes</td></tr>
</tbody></table>
<p>状态是当前被托管索引所处状态的描述。托管的索引在某个时刻只能有一种状态，每个状态，都会在进入该状态时候，执行一系列关联操作，在执行关联操作后，还会有一系列的检查操作, 检查是否进入下一个状态。</p>
<p>下面的表格，包含了一个状态的定义:</p>
<table><thead><tr><th>字段名称</th><th>描述</th><th>字段类型</th><th>是否必须</th></tr></thead><tbody>
<tr><td>name</td><td>状态名称</td><td>string</td><td>是</td></tr>
<tr><td>actions</td><td>进入状态后，需要执行的操作</td><td>nested list of objects</td><td>是</td></tr>
<tr><td>transitions</td><td>接下来的状态，已经到达下一个状态的条件，如果该字段为空值，则表示该状态是索引最终状态，索引到达该状态不会进行索引管理</td><td>nested list of objects</td><td>是</td></tr>
</tbody></table>
<h3 id="32-操作-actions"><a class="header" href="#32-操作-actions">3.2 操作 actions</a></h3>
<p>Actions are the steps that the policy sequentially executes on entering a specific state.</p>
<p>They are executed in the order in which they are defined.</p>
<p>This table lists the parameters that you can define for an action.</p>
<table><thead><tr><th>Parameter</th><th>Description</th><th>Type</th><th>Required</th><th>Default</th></tr></thead><tbody>
<tr><td>timeout</td><td>The timeout period for the action. Accepts time units for minutes, hours, and days.</td><td>time unit</td><td>No</td><td>-</td></tr>
<tr><td>retry</td><td>The retry configuration for the action.</td><td>object</td><td>No</td><td>Specific to action</td></tr>
</tbody></table>
<p>The retry operation has the following parameters:</p>
<table><thead><tr><th>Parameter</th><th>Description</th><th>Type</th><th>Required</th><th>Default</th></tr></thead><tbody>
<tr><td>count</td><td>The number of retry counts.</td><td>number</td><td>Yes</td><td>-</td></tr>
<tr><td>backoff</td><td>The backoff policy type to use when retrying.</td><td>string</td><td>No</td><td>Exponential</td></tr>
<tr><td>delay</td><td>The time to wait between retries. Accepts time units for minutes, hours, and days.</td><td>time unit</td><td>No</td><td>1 minute</td></tr>
</tbody></table>
<p>操作是索引进入某个状态后，需要运行的一系列操作。</p>
<p>操作需要按照顺序依次执行。下面的表格，包含了一个操作的定义：</p>
<p>The following example action has a timeout period of one hour. The policy retries this action three times with an exponential backoff policy, with a delay of 10 minutes between each retry:</p>
<p>下面示例操作的超时时间为1个小时，该操作如果失败，会使用指数策略重试机制，每次重试的延迟为10分钟</p>
<pre><code class="language-json">
&quot;actions&quot;: {
  &quot;timeout&quot;: &quot;1h&quot;,
  &quot;retry&quot;: {
    &quot;count&quot;: 3,
    &quot;backoff&quot;: &quot;exponential&quot;,
    &quot;delay&quot;: &quot;10m&quot;
  }
}

</code></pre>
<h3 id="33-转换-transitions"><a class="header" href="#33-转换-transitions">3.3 转换 transitions</a></h3>
<p>Transitions define the conditions that need to be met for a state to change. After all actions in the current state are completed, the policy starts checking the conditions for transitions.</p>
<p>Transitions are evaluated in the order in which they are defined. For example, if the conditions for the first transition are met, then this transition takes place and the rest of the transitions are dismissed.</p>
<p>转换定义了状态修改所需要满足的条件，当前状态下所有的 <code>actions</code>都执行完成后，进入到转换条件的检查。</p>
<p>转换按照定义的顺序进行检查，例如：满足了定义中的第一个条件，则转换会进行；会忽略其他的条件。</p>
<p>If you don’t specify any conditions in a transition and leave it empty, then it’s assumed to be the equivalent of always true. This means that the policy transitions the index to this state the moment it checks.</p>
<p>This table lists the parameters you can define for transitions.</p>
<p>如果定义中没有指定任何条件，则等同于<code>always true</code>，在索引检查时候，会进行状态转换。</p>
<p>下面的表格，定义了转换:</p>
<table><thead><tr><th>Parameter</th><th>Description</th><th>Type</th><th>Required</th></tr></thead><tbody>
<tr><td>state_name</td><td>The name of the state to transition to if the conditions are met.</td><td>string</td><td>Yes</td></tr>
<tr><td>conditions</td><td>List the conditions for the transition.</td><td>list</td><td>Yes</td></tr>
</tbody></table>
<p>The conditions object has the following parameters:</p>
<p>|Parameter	Description	Type	Required
min_index_age	The minimum age of the index required to transition.	string	No
min_doc_count	The minimum document count of the index required to transition.	number	No
min_size	The minimum size of the total primary shard storage (not counting replicas). For example, if you set min_size to 100 GiB and your index has 5 primary shards and 5 replica shards of 20 GiB each, the total size of all primary shards is 100 GiB, so your index is transitioned to the next state.	string	No
cron	The cron job that triggers the transition if no other transition happens first.	object	No
cron.cron.expression	The cron expression that triggers the transition.	string	Yes
cron.cron.timezone	The timezone that triggers the transition.	string	Yes</p>
<h3 id="34-策略-policies"><a class="header" href="#34-策略-policies">3.4 策略 policies</a></h3>
<p>Policies are JSON documents that define the following:</p>
<ul>
<li>
<p>The states that an index can be in, including the default state for new indices. For example, you might name your states “hot,” “warm,” “delete,” and so on. For more information, see States.</p>
</li>
<li>
<p>Any actions that you want the plugin to take when an index enters a state, such as performing a rollover. For more information, see Actions.</p>
</li>
<li>
<p>The conditions that must be met for an index to move into a new state, known as transitions. For example, if an index is more than eight weeks old, you might want to move it to the “delete” state. For more information, see Transitions.</p>
</li>
</ul>
<p>In other words, a policy defines the states that an index can be in, the actions to perform when in a state, and the conditions that must be met to transition between states.</p>
<p>策略是一个JSON文档，里面定义了:</p>
<ul>
<li>
<p>状态，策略中需要指定状态，例如：索引创建后的默认状态，状态的可选值有 <code>hot/warm/cold</code>等</p>
</li>
<li>
<p>操作，当索引进入到新状态后，执行的一系列操作，例如：滚动索引等</p>
</li>
<li>
<p>转换，索引进入新状态需要满足的条件。例如：一个索引，超过8周，可能需要变更为 delete 状态。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="elasticsearch集群备份"><a class="header" href="#elasticsearch集群备份">elasticsearch集群备份</a></h1>
<ul>
<li>
<p><a href="use/backup/./snapshot.html">快照备份</a></p>
</li>
<li>
<p><a href="use/backup/./meta.html">只备份集群中的策略、模版等信息</a></p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="使用快照备份"><a class="header" href="#使用快照备份">使用快照备份</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="只备份集群中的策略模版等信息"><a class="header" href="#只备份集群中的策略模版等信息">只备份集群中的策略、模版等信息</a></h1>
<h2 id="参考-1"><a class="header" href="#参考-1">参考</a></h2>
<blockquote>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/security-api-put-user.html">用户管理</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/8.3/cluster-update-settings.html">集群配置</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/8.3/data-management.html">策略管理</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/8.3/index-templates.html">模版管理</a></p>
</blockquote>
<h2 id="一集群配置"><a class="header" href="#一集群配置">一、集群配置</a></h2>
<h3 id="11-从现有集群获取集群配置"><a class="header" href="#11-从现有集群获取集群配置">1.1 从现有集群获取集群配置</a></h3>
<pre><code>
GET _cluster/settings?flat_settings

curl -u elastic:xxx -XGET &quot;http://127.0.0.1:9200/_cluster/settings?flat_settings&quot;

</code></pre>
<p>返回值如下:</p>
<pre><code class="language-json">
{
  &quot;persistent&quot; : {
    &quot;action.auto_create_index&quot; : &quot;+.*,-*&quot;,
    &quot;action.destructive_requires_name&quot; : &quot;false&quot;,
    &quot;cluster.max_shards_per_node&quot; : &quot;5000&quot;,
    &quot;xpack.monitoring.collection.enabled&quot; : &quot;true&quot;
  },
  &quot;transient&quot; : { }
}

</code></pre>
<h3 id="12-将集群配置导入到新集群"><a class="header" href="#12-将集群配置导入到新集群">1.2 将集群配置导入到新集群</a></h3>
<pre><code>
PUT _cluster/settings
{
  &quot;persistent&quot; : {
    &quot;action.auto_create_index&quot; : &quot;+.*,-*&quot;,
    &quot;action.destructive_requires_name&quot; : &quot;false&quot;,
    &quot;cluster.max_shards_per_node&quot; : &quot;5000&quot;,
    &quot;xpack.monitoring.collection.enabled&quot; : &quot;true&quot;
  },
  &quot;transient&quot; : { }
}

curl -u elastic:xxx -XPUT &quot;http://127.0.0.l:9200/_cluster/settings&quot; -H 'Content-Type: application/json' -d'{  &quot;persistent&quot; : {    &quot;action.auto_create_index&quot; : &quot;+.*,-*&quot;,    &quot;action.destructive_requires_name&quot; : &quot;false&quot;,    &quot;cluster.max_shards_per_node&quot; : &quot;5000&quot;,    &quot;xpack.monitoring.collection.enabled&quot; : &quot;true&quot;  },  &quot;transient&quot; : { }}'

</code></pre>
<h2 id="二索引策略"><a class="header" href="#二索引策略">二、索引策略</a></h2>
<h3 id="21-从现有集群获取策略信息"><a class="header" href="#21-从现有集群获取策略信息">2.1 从现有集群获取策略信息</a></h3>
<pre><code>
GET _ilm/policy

curl -u elastic:xxx -XGET &quot;http://127.0.0.1:9200/_ilm/policy&quot;

</code></pre>
<p>返回值如下:</p>
<pre><code class="language-json">
{
  &quot;.items-default&quot; : {
    &quot;version&quot; : 1,
    &quot;modified_date&quot; : &quot;2021-12-30T06:02:12.763Z&quot;,
    &quot;policy&quot; : {
      &quot;phases&quot; : {
        &quot;hot&quot; : {
          &quot;min_age&quot; : &quot;0ms&quot;,
          &quot;actions&quot; : {
            &quot;rollover&quot; : {
              &quot;max_size&quot; : &quot;50gb&quot;
            }
          }
        }
      }
    }
  }
  ...
}

</code></pre>
<h3 id="22-将策略信息导入到新集群"><a class="header" href="#22-将策略信息导入到新集群">2.2 将策略信息导入到新集群</a></h3>
<p>⚠️ 一次只能导入一个策略, PUT body 不需要 version/modified_date 信息</p>
<pre><code>
PUT _ilm/policy/.items-default
{
  &quot;policy&quot;: {
    &quot;phases&quot;: {
      &quot;hot&quot;: {
        &quot;min_age&quot;: &quot;0ms&quot;,
        &quot;actions&quot;: {
          &quot;rollover&quot;: {
            &quot;max_size&quot;: &quot;50gb&quot;
          }
        }
      }
    }
  }
}

curl -u elastic:xxx -XPUT &quot;http://127.0.0.1:9200/_ilm/policy/.items-default&quot; -H 'Content-Type: application/json' -d'{  &quot;policy&quot;: {    &quot;phases&quot;: {      &quot;hot&quot;: {        &quot;min_age&quot;: &quot;0ms&quot;,        &quot;actions&quot;: {          &quot;rollover&quot;: {            &quot;max_size&quot;: &quot;50gb&quot;          }        }      }    }  }}'

</code></pre>
<h2 id="三索引模版"><a class="header" href="#三索引模版">三、索引模版</a></h2>
<h3 id="31-从现有集群获取索引模版"><a class="header" href="#31-从现有集群获取索引模版">3.1 从现有集群获取索引模版</a></h3>
<pre><code>
GET _template/*

curl -u elastic:xxx -XGET &quot;http://127.0.0.1:9200/_template/*&quot;

</code></pre>
<p>返回结果如下:</p>
<pre><code class="language-json">
{
  &quot;wksp_xxx_template&quot; : {
    &quot;order&quot; : 0,
    &quot;index_patterns&quot; : [
      &quot;wksp_xxx-*&quot;
    ],
    &quot;settings&quot; : {
      &quot;index&quot; : {
        &quot;lifecycle&quot; : {
          &quot;name&quot; : &quot;es_rp4&quot;,
          &quot;rollover_alias&quot; : &quot;wksp_xxx&quot;
        },
        &quot;number_of_shards&quot; : &quot;1&quot;,
        &quot;number_of_replicas&quot; : &quot;1&quot;
      }
    },
    &quot;mappings&quot; : {
      &quot;dynamic_templates&quot; : [
        {
          &quot;strings_as_keywords&quot; : {
            &quot;mapping&quot; : {
              &quot;type&quot; : &quot;keyword&quot;
            },
            &quot;match_mapping_type&quot; : &quot;string&quot;
          }
        }
      ],
      &quot;date_detection&quot; : false,
      &quot;properties&quot; : {
        &quot;message&quot; : {
          &quot;search_analyzer&quot; : &quot;ik_max_word&quot;,
          &quot;search_quote_analyzer&quot; : &quot;ik_max_word&quot;,
          &quot;analyzer&quot; : &quot;ik_max_word&quot;,
          &quot;type&quot; : &quot;text&quot;
        },
        &quot;title&quot; : {
          &quot;search_analyzer&quot; : &quot;ik_max_word&quot;,
          &quot;search_quote_analyzer&quot; : &quot;ik_max_word&quot;,
          &quot;analyzer&quot; : &quot;ik_max_word&quot;,
          &quot;type&quot; : &quot;text&quot;
        }
      }
    },
    &quot;aliases&quot; : { }
  }
  
  ...
}

</code></pre>
<h3 id="32-将索引模版导入到新集群"><a class="header" href="#32-将索引模版导入到新集群">3.2 将索引模版导入到新集群</a></h3>
<p>⚠️ 一次只能导入一个模版</p>
<pre><code>
PUT _template/wksp_xxx_template
{
  &quot;order&quot;: 0,
  &quot;index_patterns&quot;: [
    &quot;wksp_xxx-*&quot;
  ],
  &quot;settings&quot;: {
    &quot;index&quot;: {
      &quot;lifecycle&quot;: {
        &quot;name&quot;: &quot;es_rp4&quot;,
        &quot;rollover_alias&quot;: &quot;wksp_xxx&quot;
      },
      &quot;number_of_shards&quot;: &quot;1&quot;,
      &quot;number_of_replicas&quot;: &quot;1&quot;
    }
  },
  &quot;mappings&quot;: {
    &quot;dynamic_templates&quot;: [
      {
        &quot;strings_as_keywords&quot;: {
          &quot;mapping&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
          },
          &quot;match_mapping_type&quot;: &quot;string&quot;
        }
      }
    ],
    &quot;date_detection&quot;: false,
    &quot;properties&quot;: {
      &quot;message&quot;: {
        &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;search_quote_analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;type&quot;: &quot;text&quot;
      },
      &quot;title&quot;: {
        &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;search_quote_analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;analyzer&quot;: &quot;ik_max_word&quot;,
        &quot;type&quot;: &quot;text&quot;
      }
    }
  },
  &quot;aliases&quot;: {}
}

curl -u elastic:xxx -XPUT &quot;http://127.0.0.1:9200/_template/wksp_xxx_template&quot; -H 'Content-Type: application/json' -d'{  &quot;order&quot;: 0,  &quot;index_patterns&quot;: [    &quot;wksp_xxx-*&quot;  ],  &quot;settings&quot;: {    &quot;index&quot;: {      &quot;lifecycle&quot;: {        &quot;name&quot;: &quot;es_rp4&quot;,        &quot;rollover_alias&quot;: &quot;wksp_xxx&quot;      },      &quot;number_of_shards&quot;: &quot;1&quot;,      &quot;number_of_replicas&quot;: &quot;1&quot;    }  },  &quot;mappings&quot;: {    &quot;dynamic_templates&quot;: [      {        &quot;strings_as_keywords&quot;: {          &quot;mapping&quot;: {            &quot;type&quot;: &quot;keyword&quot;          },          &quot;match_mapping_type&quot;: &quot;string&quot;        }      }    ],    &quot;date_detection&quot;: false,    &quot;properties&quot;: {      &quot;message&quot;: {        &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,        &quot;search_quote_analyzer&quot;: &quot;ik_max_word&quot;,        &quot;analyzer&quot;: &quot;ik_max_word&quot;,        &quot;type&quot;: &quot;text&quot;      },      &quot;title&quot;: {        &quot;search_analyzer&quot;: &quot;ik_max_word&quot;,        &quot;search_quote_analyzer&quot;: &quot;ik_max_word&quot;,        &quot;analyzer&quot;: &quot;ik_max_word&quot;,        &quot;type&quot;: &quot;text&quot;      }    }  },  &quot;aliases&quot;: {}}'

</code></pre>
<h2 id="四用户"><a class="header" href="#四用户">四、用户</a></h2>
<p>elasticsearch 无法通过接口，获取用户密码，也就不存在用户密码备份</p>
<p>如果需要在新集群添加用户，或者重置（内置用户）密码，可以使用 <code>POST /_security/user/username</code> </p>
<pre><code>POST /_security/user/jacknich
{
  &quot;password&quot; : &quot;l0ng-r4nd0m-p@ssw0rd&quot;,
  &quot;roles&quot; : [ &quot;admin&quot;, &quot;other_role1&quot; ],
  &quot;full_name&quot; : &quot;Jack Nicholson&quot;,
  &quot;email&quot; : &quot;jacknich@example.com&quot;,
  &quot;metadata&quot; : {
    &quot;intelligence&quot; : 7
  }
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reindex-过程"><a class="header" href="#reindex-过程">reindex 过程</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="reindex添加新字段"><a class="header" href="#reindex添加新字段">reindex添加新字段</a></h1>
<blockquote>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting-fields.html#modules-scripting-doc-vals">Accessing document fields and special variables</a></p>
</blockquote>
<p>假设我们想要知道 之前索引中的日志大小，</p>
<p>可以在reindex阶段，使用script，计算每个doc 的_source长度</p>
<pre><code>POST _reindex
{
  &quot;source&quot;: {
    &quot;index&quot;: &quot;yztest-log&quot;
  },
  &quot;dest&quot;: {
    &quot;index&quot;: &quot;yztest-backup&quot;
  },
  &quot;script&quot;: {
    &quot;lang&quot;: &quot;painless&quot;,
    &quot;source&quot;: &quot;&quot;&quot;ctx._source.len = ctx._source.toString().length()&quot;&quot;&quot;
  }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lucene介绍"><a class="header" href="#lucene介绍">lucene介绍</a></h1>
<h2 id="一参考"><a class="header" href="#一参考">一、参考</a></h2>
<blockquote>
<p><a href="https://www.apache.org/">Apache</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.elastic.co/cn/celebrating-lucene">Celebrating 20 years of Apache Lucene</a></p>
</blockquote>
<blockquote>
<p><a href="https://book.douban.com/subject/3726306/">lucene in action, 2rd</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/foreword_id.html">Elasticsearch: 权威指南</a></p>
</blockquote>
<blockquote>
<p><a href="https://learning.oreilly.com/library/view/practical-apache-lucene/9781484263457/">Practical Apache Lucene 8: Uncover the Search Capabilities of Your Application</a></p>
</blockquote>
<blockquote>
<p><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/package-summary.html">Lucene 9.0 file format</a></p>
</blockquote>
<blockquote>
<p><a href="http://ddia.vonng.com/#/ch3?id=sstables%e5%92%8clsm%e6%a0%91">设计数据密集型应用-存储与检索</a></p>
</blockquote>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s/BsW_SeGdnMHfg1_bM_sgSQ">存储系统中的算法：LSM 树设计原理</a></p>
</blockquote>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s/GsnBpZPzizX9ODuQLT-uAg">LSM核心实现讲解</a></p>
</blockquote>
<blockquote>
<p><a href="https://github.com/facebook/rocksdb/wiki/RocksDB-Overview">RocksDB</a></p>
</blockquote>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/354105864">Lucene-文件格式</a></p>
</blockquote>
<blockquote>
<p><a href="https://blog.mikemccandless.com/2010/12/using-finite-state-transducers-in.html">Using Finite State Transducers in Lucene</a></p>
</blockquote>
<blockquote>
<p><a href="https://www.easyice.cn/archives/346">Elasticsearch 7.3 的 offheap 原理</a></p>
</blockquote>
<blockquote>
<p><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/search/similarities/Similarity.html">Similarity</a></p>
</blockquote>
<h2 id="一lucene-初识"><a class="header" href="#一lucene-初识">一、lucene 初识</a></h2>
<h3 id="11-lucene-是什么"><a class="header" href="#11-lucene-是什么">1.1 lucene 是什么？</a></h3>
<ul>
<li>
<p>lucene 是个 Java 搜索库，<a href="https://lucene.apache.org/core/">简单易用，功能强大</a></p>
</li>
<li>
<p>lucene 和 Elasticsearch 关系，可以类比为 发动机和汽车关系，lucene提供写入/查询核心功能，ES实现分布式/分析功能。</p>
</li>
<li>
<p>lucene 和 google 等搜索公司关系，</p>
<p>lucene 是开源软件，可以免费使用；google公司的搜索功能需要付费</p>
<p>它们之间的搜索能力不太好比较，lucene经过多年发展，已经成为信息检索领域的开源软件标准</p>
</li>
<li>
<p>lucene 与关系型数据库的区别</p>
<p>lucene基于文档索引和搜索，一般用于全文搜索，无法实现事务</p>
</li>
<li>
<p>基于lucene，实现搜索功能的公司或者产品有，github/ wiki/ twitter/ linkedin 等等</p>
</li>
</ul>
<h3 id="12-发展历程"><a class="header" href="#12-发展历程">1.2 发展历程</a></h3>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/cloudera-doug-cutting.png?raw=true" alt="Doug" /></p>
<h4 id="1--2000年3月doug-cutting-第一次发布开源版本-001"><a class="header" href="#1--2000年3月doug-cutting-第一次发布开源版本-001">（1）  2000年3月，<a href="https://en.wikipedia.org/wiki/Doug_Cutting">Doug Cutting</a> 第一次发布开源版本 0.01</a></h4>
<ul>
<li>
<p>1997年，Doug 因为工作不稳定和 Java 当时非常热门，所以，他想利用 Java 商业化一些自己的软件，但是后来放弃商业化想法，将 lucene 放到 SourceForge 上开源， Doug曾经是 Apache 基金会主席（2011年）</p>
</li>
<li>
<p>lucene 是 Doug 的第五个搜索引擎，之前在施乐PARC写过两个，一个在苹果，一个在Excite</p>
</li>
<li>
<p>lucene 是 Doug 老婆中间的名字</p>
</li>
</ul>
<h4 id="2-2000年10月发布-10"><a class="header" href="#2-2000年10月发布-10">（2） 2000年10月，发布 1.0</a></h4>
<ul>
<li>
<p>2001年9月，lucene 加入 <a href="https://jakarta.apache.org/">Apache Jakarta</a> 项目</p>
</li>
<li>
<p>2002年，1.2版本成为第一个 Apache 许可证的 lucene 版本</p>
</li>
<li>
<p>2004年，<a href="https://en.wikipedia.org/wiki/Elasticsearch">Shay Banon</a> 发布了Elasticsearch的前身-<a href="http://www.compass-project.org/overview.html">compass</a></p>
</li>
</ul>
<blockquote>
<p>许多年前，一个刚结婚的名叫 Shay Banon 的失业开发者，跟着他的妻子去了伦敦，他的妻子在那里学习厨师。 在寻找一个赚钱的工作的时候，为了给他的妻子做一个食谱搜索引擎，他开始使用 Lucene 的一个早期版本。
直接使用 Lucene 是很难的，因此 Shay 开始做一个抽象层，Java 开发者使用它可以很简单的给他们的程序添加搜索功能。 他发布了他的第一个开源项目 Compass。</p>
<p>后来 Shay 获得了一份工作，主要是高性能，分布式环境下的内存数据网格。这个对于高性能，实时，分布式搜索引擎的需求尤为突出， 他决定重写 Compass，把它变为一个独立的服务并取名 Elasticsearch。</p>
<p>第一个公开版本在2010年2月发布，从此以后，Elasticsearch 已经成为了 Github 上最活跃的项目之一，他拥有超过300名 contributors(目前736名 contributors )。 一家公司已经开始围绕 Elasticsearch 提供商业服务，并开发新的特性，但是，Elasticsearch 将永远开源并对所有人可用。</p>
<p>据说，Shay 的妻子还在等着她的食谱搜索引擎…​</p>
</blockquote>
<ul>
<li>2005年，lucene 成为 Apache 顶级项目</li>
</ul>
<h4 id="3-2006年5月发布-20"><a class="header" href="#3-2006年5月发布-20">（3） 2006年5月，发布 2.0</a></h4>
<h4 id="4-2009年11月发布-30"><a class="header" href="#4-2009年11月发布-30">（4） 2009年11月，发布 3.0</a></h4>
<ul>
<li>
<p>2010年2月7日，Elasticsearch 0.1.0 发布</p>
</li>
<li>
<p>2010年，solr 作为lucene子项目，合并入lucene</p>
</li>
<li>
<p>2011年，twitter 使用 lucene 实现实时搜索</p>
</li>
</ul>
<h3 id="5-2012年发布-40"><a class="header" href="#5-2012年发布-40">（5） 2012年，发布 4.0</a></h3>
<ul>
<li>
<p>是一个&quot;革命性&quot;版本，让lucene 进入严肃分析领域，(1) 添加编码/解码器; (2) 新增相似性分析模型(BM25, DFR)</p>
</li>
<li>
<p>2012年2月9日，Elastic公司成立</p>
</li>
</ul>
<h3 id="6-2015年发布-50"><a class="header" href="#6-2015年发布-50">（6） 2015年，发布 5.0</a></h3>
<h3 id="7-2016年发布-60"><a class="header" href="#7-2016年发布-60">（7） 2016年，发布 6.0</a></h3>
<ul>
<li>
<p>添加了对多维索引的支持 BKD树</p>
</li>
<li>
<p>将BM25 设置为默认相似性模型，之前是 TF/IDF</p>
</li>
<li>
<p>lucene 源码从 Subversion 转移到 git</p>
</li>
</ul>
<h3 id="8-2017年发布-70"><a class="header" href="#8-2017年发布-70">（8） 2017年，发布 7.0</a></h3>
<h3 id="9-2019年发布-80"><a class="header" href="#9-2019年发布-80">（9） 2019年，发布 8.0</a></h3>
<h3 id="10-2021年发布-90"><a class="header" href="#10-2021年发布-90">（10） 2021年，发布 9.0</a></h3>
<ul>
<li>solr 独立出 lucene，成为Apache 顶级项目</li>
</ul>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/shayBanon.png?raw=true" alt="elastic" /></p>
<h2 id="二写入索引"><a class="header" href="#二写入索引">二、写入（索引）</a></h2>
<h3 id="21-倒排索引-inverted-index"><a class="header" href="#21-倒排索引-inverted-index">2.1 倒排索引 Inverted index</a></h3>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/doc-index.png?raw=true" alt="index" /></p>
<p>⚠️ MySQL 8.0 也实现了倒排索引 （ 2018/4/19 ）</p>
<h3 id="22-索引流程"><a class="header" href="#22-索引流程">2.2 索引流程</a></h3>
<ul>
<li>
<p>一般先把不同格式的文本，先转变为特定格式文本(json)</p>
</li>
<li>
<p>每个文档要确定field结构，每个field都需要经过分析器分析后，最终持久化</p>
</li>
<li>
<p>分析器分析过程，会流式经过不同类型的分析器，产生token列表</p>
</li>
</ul>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/index-1.png?raw=true" alt="i1" /></p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/index-2.png?raw=true" alt="i2" /></p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/index-3.png?raw=true" alt="i3" /></p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/index-6.png?raw=true" alt="i6" /></p>
<table><thead><tr><th>术语</th><th>描述</th></tr></thead><tbody>
<tr><td>document</td><td>文档</td></tr>
<tr><td>field</td><td>文档中的字段</td></tr>
<tr><td>index</td><td>名词，lucene中文档保存的集合</td></tr>
<tr><td>segment</td><td>段，表示写入时候的commit点</td></tr>
<tr><td>term</td><td>lucene中存储和搜索的基本单元</td></tr>
<tr><td>token</td><td>经过分词器后，切分的最小单元</td></tr>
</tbody></table>
<p>term 可以理解为 token 加上 fieldName，例如： 文档中title字段，值为 hello world, 分析器分析后，生成 hello 和 world两个token，则 term也是两个, &lt;title, hello&gt;, &lt;title, world&gt;</p>
<h3 id="23-lsm树实现"><a class="header" href="#23-lsm树实现">2.3 LSM树实现</a></h3>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/lsm-10.png?raw=true" alt="lsm region" /></p>
<p><a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree">LSM tree (log-structured merge-tree) </a></p>
<p><a href="https://en.wikipedia.org/wiki/B-tree">B-tree</a></p>
<ul>
<li>
<p>是一种对频繁写操作非常友好的数据结构，同时兼顾了查询效率。</p>
</li>
<li>
<p>之所以有效是基于以下事实：磁盘或内存的连续读写性能远高于随机读写性能(局部性原理)</p>
</li>
<li>
<p>是许多 key-value 型或日志型数据库所依赖的核心数据结构，例如 BigTable、HBase、Cassandra、LevelDB、SQLite、Scylla、RocksDB 等。</p>
</li>
</ul>
<p>LSM树 三个主要组成部分: memtable，log，SSTable</p>
<ul>
<li>
<p>memtable</p>
<p>是红黑树或者跳表这样的有序内存数据结构，起到缓存和排序的作用，把新写入的数据按照键的大小进行排序。当memtable到达一定大小之后，会被转化成SSTable格式刷入磁盘持久化存储</p>
</li>
<li>
<p>SSTable（Sorted String Table）</p>
<p>说白了就是一个特殊格式的文件，其中的数据按照键的大小排列，你可以把它类比成一个有序数组。而 LSM 树，说白了就是若干SSTable的集合。</p>
</li>
<li>
<p>log</p>
<p>文件记录操作日志，在数据写入memtable的同时也会刷盘写入到log文件，作用是数据恢复。比如在memtable中的数据还没转化成SSTable持久化到磁盘时，如果突然断电，那么memtable里面的数据都会丢失，但有log文件在，就可以恢复这些数据。当然，等memtable中的数据成功转化成SSTable落盘之后，log文件中对应的操作日志就没必要存在了，可以被删除</p>
</li>
</ul>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/lsm-0.png?raw=true" alt="RocksDB" /></p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/lsm-5.png?raw=true" alt="lsm" /></p>
<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html">持久化变更</a></p>
<h3 id="24-索引文件"><a class="header" href="#24-索引文件">2.4 索引文件</a></h3>
<p>下面是<a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/package-summary.html">lucene9.3.0</a> 中的索引文件 </p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/lucene-file-format.png?raw=true" alt="file" /></p>
<table><thead><tr><th>序号</th><th>文件后缀</th><th>描述说明</th><th>示例</th></tr></thead><tbody>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90CompoundFormat.html">.cfs</a></td><td>An optional &quot;virtual&quot; file consisting of all the other index files for systems that frequently run out of file handles.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90CompoundFormat.html">.cfe</a></td><td>The &quot;virtual&quot; compound file's entry table holding all entries in the corresponding .cfs file.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PostingsFormat.html">.doc</a></td><td>Frequencies and Skip Data</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90DocValuesFormat.html">.dvd</a></td><td>DocValues data</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90DocValuesFormat.html">.dvm</a></td><td>DocValues metadata</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90StoredFieldsFormat.html">.fdt</a></td><td>This file stores a compact representation of documents in compressed blocks of 16KB or more. When writing a segment, documents are appended to an in-memory byte[] buffer. When its size reaches 16KB or more, some metadata about the documents is flushed to disk, immediately followed by a compressed representation of the buffer using the LZ4 compression format.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90StoredFieldsFormat.html">.fdx</a></td><td>This file stores two monotonic arrays, one for the first doc IDs of each block of compressed documents, and another one for the corresponding offsets on disk. At search time, the array containing doc IDs is binary-searched in order to find the block that contains the expected doc ID, and the associated offset on disk is retrieved from the second array.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90StoredFieldsFormat.html">.fdm</a></td><td>This file stores metadata about the monotonic arrays stored in the index file.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90FieldInfosFormat.html">.fnm</a></td><td>Field names are stored in the field info file</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PointsFormat.html">.kdm</a></td><td>A .kdm file that records metadata about the fields, such as numbers of dimensions or numbers of bytes per dimension.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PointsFormat.html">.kdi</a></td><td>A .kdi file that stores inner nodes of the tree.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PointsFormat.html">.kdd</a></td><td>A .kdd file that stores leaf nodes, where most of the data lives.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90LiveDocsFormat.html">.liv</a></td><td>The .liv file is optional, and only exists when a segment contains deletions.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90NormsFormat.html">.nvd</a></td><td>Norms data</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90NormsFormat.html">.nvm</a></td><td>Norms metadata</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PostingsFormat.html">.pay</a></td><td>Payloads and Offsets</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PostingsFormat.html">.pos</a></td><td>Positions</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90SegmentInfoFormat.html">.si</a></td><td>Header, SegVersion, SegSize, IsCompoundFile, Diagnostics, Files, Attributes, IndexSort, Footer</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PostingsFormat.html">.tim</a></td><td>Term Dictionary</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90PostingsFormat.html">.tip</a></td><td>Term Index</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90TermVectorsFormat.html">.tvm</a></td><td>A vector metadata file</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90TermVectorsFormat.html">.tvd</a></td><td>This file stores terms, frequencies, positions, offsets and payloads for every document. Upon writing a new segment, it accumulates data into memory until the buffer used to store terms and payloads grows beyond 4KB. Then it flushes all metadata, terms and positions to disk using LZ4 compression for terms and payloads and blocks of packed ints for positions.</td><td></td></tr>
<tr><td></td><td><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/lucene90/Lucene90TermVectorsFormat.html">.tvx</a></td><td>An index file</td><td></td></tr>
</tbody></table>
<p>⚠️ <a href="https://lucene.apache.org/core/3_0_3/fileformats.html">lucene3.0.3</a> 中的文件格式</p>
<table><thead><tr><th>Name</th><th>Extension</th><th>Brief Description</th></tr></thead><tbody>
<tr><td>Segments File</td><td>segments.gen, segments_N</td><td>Stores information about segments</td></tr>
<tr><td>Lock File</td><td>write.lock</td><td>The Write lock prevents multiple IndexWriters from writing to the same file.</td></tr>
<tr><td>Compound File</td><td>.cfs</td><td>An optional &quot;virtual&quot; file consisting of all the other index files for systems that frequently run out of file handles.</td></tr>
<tr><td>Fields</td><td>.fnm</td><td>Stores information about the fields</td></tr>
<tr><td>Field Index</td><td>.fdx</td><td>Contains pointers to field data</td></tr>
<tr><td>Field Data</td><td>.fdt</td><td>The stored fields for documents</td></tr>
<tr><td>Term Infos</td><td>.tis</td><td>Part of the term dictionary, stores term info</td></tr>
<tr><td>Term Info Index</td><td>.tii</td><td>The index into the Term Infos file</td></tr>
<tr><td>Frequencies</td><td>.frq</td><td>Contains the list of docs which contain each term along with frequency</td></tr>
<tr><td>Positions</td><td>.prx</td><td>Stores position information about where a term occurs in the index</td></tr>
<tr><td>Norms</td><td>.nrm</td><td>Encodes length and boost factors for docs and fields</td></tr>
<tr><td>Term Vector Index</td><td>.tvx</td><td>Stores offset into the document data file</td></tr>
<tr><td>Term Vector Documents</td><td>.tvd</td><td>Contains information about each document that has term vectors</td></tr>
<tr><td>Term Vector Fields</td><td>.tvf</td><td>The field level info about term vectors</td></tr>
<tr><td>Deleted Documents</td><td>.del</td><td>Info about what files are deleted</td></tr>
</tbody></table>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/file-format.png?raw=true" alt="file-format" /></p>
<p>客户实际示例</p>
<table><thead><tr><th>文件</th><th>大小</th><th>说明</th></tr></thead><tbody>
<tr><td>wksp_975d8bf6d6204f9ca72efb65eaee718c_tracing-000033</td><td>303.8gb</td><td>索引大小</td></tr>
<tr><td>fdt</td><td>154.2gb</td><td>保存每个文档的属性值对应关系</td></tr>
<tr><td>tim</td><td>57.8gb</td><td>term 词典</td></tr>
<tr><td>kdd</td><td>32.1gb</td><td><a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=173081898">多维数据结构</a>，叶节点信息</td></tr>
<tr><td>dvd</td><td>20.7gb</td><td>列式存储原始字段</td></tr>
<tr><td>doc</td><td>8.6gb</td><td>term出现的频率</td></tr>
<tr><td>tip</td><td>947.7mb</td><td>term词典的索引，实际上即是下章介绍的fst数据结构</td></tr>
</tbody></table>
<h3 id="25-fst数据结构"><a class="header" href="#25-fst数据结构">2.5 fst数据结构</a></h3>
<p><a href="https://blog.mikemccandless.com/2010/12/using-finite-state-transducers-in.html">Using Finite State Transducers in Lucene</a></p>
<p><a href="https://www.shenyanchao.cn/blog/2018/12/04/lucene-fst/">关于Lucene的词典FST深入剖析</a></p>
<h2 id="三查询"><a class="header" href="#三查询">三、查询</a></h2>
<h3 id="31-查询流程"><a class="header" href="#31-查询流程">3.1 查询流程</a></h3>
<ul>
<li>lucene查询语句，先经过解析器，然后再经过同样的分析器，最后查询</li>
</ul>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/search-1.png?raw=true" alt="s1" /></p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/search-2.png?raw=true" alt="s2" /></p>
<p><img src="https://github.com/Kua-Fu/blog-book-images/blob/main/elastic-101/lucene/search-3.png?raw=true" alt="s3" /></p>
<h3 id="32-相似度算法"><a class="header" href="#32-相似度算法">3.2 相似度算法</a></h3>
<p>(1)  TF/IDF</p>
<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/scoring-theory.html">相关度评分背后的理论</a></p>
<p>相关性判断三个元素</p>
<p>a. 检索词频率</p>
<p>检索词在该字段出现的频率？出现频率越高，相关性也越高。 字段中出现过 5 次要比只出现过 1 次的相关性高。</p>
<p>b. 反向文档频率</p>
<p>每个检索词在索引中出现的频率？频率越高，相关性越低。检索词出现在多数文档中会比出现在少数文档中的权重更低。</p>
<p>c. 字段长度准则</p>
<p>字段的长度是多少？长度越长，相关性越低。 检索词出现在一个短的 title 要比同样的词出现在一个长的 content 字段权重更大。</p>
<p>具体的计算公式 : <a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/search/similarities/TFIDFSimilarity.html">TFIDFSimilarity</a></p>
<p>(2) BM25 </p>
<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/pluggable-similarites.html">可插拔的相似度算法</a></p>
<p>具体实现方式: <a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/search/similarities/BM25Similarity.html">BM25Similarity</a></p>
<h2 id="四更多内容"><a class="header" href="#四更多内容">四、更多内容</a></h2>
<h3 id="41-lucene中的编码解码如何实现的"><a class="header" href="#41-lucene中的编码解码如何实现的">4.1 lucene中的编码/解码如何实现的?</a></h3>
<p><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/codecs/package-summary.html">Codec</a> </p>
<p>Codecs API: API for customization of the encoding and structure of the index.</p>
<p><a href="https://help.aliyun.com/document_detail/363036.html">使用aliyun-codec插件</a></p>
<h3 id="42-lucene中的存储类型"><a class="header" href="#42-lucene中的存储类型">4.2 lucene中的存储类型?</a></h3>
<p>NioFs（ 注：非阻塞文件系统）和 MMapFs （ 注：内存映射文件系统）零拷贝技术？</p>
<p><a href="https://lucene.apache.org/core/9_3_0/core/org/apache/lucene/store/FSDirectory.html">FSDirectory</a></p>
<h3 id="43-force-merge过程-lucene中的事务"><a class="header" href="#43-force-merge过程-lucene中的事务">4.3 force merge过程, lucene中的事务</a></h3>
<p><a href="https://blog.mikemccandless.com/2012/03/transactional-lucene.html">Transactional Lucene</a></p>
<h3 id="44-源码分析"><a class="header" href="#44-源码分析">4.4 源码分析</a></h3>
<h3 id="45-分布式架构--聚合分析--机器学习"><a class="header" href="#45-分布式架构--聚合分析--机器学习">4.5 分布式架构 / 聚合分析 / 机器学习</a></h3>
<h3 id="46-社区贡献-实际使用--开发新功能-等"><a class="header" href="#46-社区贡献-实际使用--开发新功能-等">4.6 社区贡献 （实际使用 / 开发新功能 等）</a></h3>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script type="text/javascript">
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->

        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
