# bulk è¢«æ‹’ç»

[åŸæ–‡: Why am I seeing bulk rejections in my Elasticsearch cluster?](https://www.elastic.co/cn/blog/why-am-i-seeing-bulk-rejections-in-my-elasticsearch-cluster)

Elasticsearch supports a wide range of use-cases across our user base, and more and more of these rely on fast indexing to quickly get large amounts of data into Elasticsearch. Even though Elasticsearch is fast and index performance is continually improved, it is still possible to overwhelm it. At that point you typically see parts of bulk requests getting rejected. In this blog post we will look at the causes and how to avoid it.

åœ¨æˆ‘ä»¬çš„ç”¨æˆ·ç¾¤äº† elasticsearch æœ‰å¹¿æ³›çš„ä½¿ç”¨ç®¡ç†ï¼Œè¶Šæ¥è¶Šå¤šçš„å®¢æˆ·ä¾èµ–å¤§é‡æ•°æ®çš„å¿«é€Ÿç´¢å¼•ã€‚å°½ç®¡ elasticsearch é€Ÿåº¦å¾ˆå¿«ï¼Œç´¢å¼•æ€§èƒ½ä¹Ÿåœ¨ä¸æ–­æé«˜ï¼Œä»ç„¶å¯èƒ½è¾¾åˆ°å³°å€¼ã€‚æ­¤æ—¶ï¼Œé€šå¸¸å¯ä»¥çœ‹åˆ°éƒ¨åˆ†å†™å…¥è¯·æ±‚è¢«æ‹’ç»ã€‚ä¸‹æ–‡å°†æ¢è®¨åŸå› å’Œå¦‚ä½•é¿å…è¯·æ±‚è¢«æ‹’ç»ã€‚

This is the second installment in a series of blog posts where we look at and discuss your common questions. The first installment discussed and provided guidelines around "How many shards one should aim to have in an Elasticsearch cluster?"

è¿™æ˜¯ä¸€ç³»åˆ—æ–‡ç« ä¸­çš„ç¬¬äºŒç¯‡ã€‚ç¬¬ä¸€éƒ¨åˆ†æ–‡ç« å¯ä»¥è¯¦è§ [How many shards one should aim to have in an Elasticsearch cluster?](https://www.elastic.co/cn/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster)

## What happens when a bulk indexing request is sent to Elasticsearch?

å½“ä¸€ä¸ª bulk è¯·æ±‚å‘é€åˆ°elasticsearch, è¯·æ±‚åä¼šå‘ç”Ÿä»€ä¹ˆ?

Letâ€™s start at the beginning and look at what happens behind the scenes when a bulk indexing request is sent to Elasticsearch.

è®©æˆ‘ä»¬ä»å¤´å¼€å§‹ï¼Œçœ‹çœ‹å½“æ‰¹é‡ç´¢å¼•è¯·æ±‚å‘é€åˆ° elasticsearch æ—¶å€™ï¼Œåå°ä¼šå‘ç”Ÿä»€ä¹ˆ?

When a bulk request arrives at a node in the cluster, it is, in its entirety, put on the bulk queue and processed by the threads in the bulk thread pool. The node that receives the request is referred to as the coordinating node as it manages the life of the request and assembles the response. This can be a node dedicated to just coordinating requests or one of the data nodes in the cluster.

å½“ bulk è¯·æ±‚åˆ°è¾¾é›†ç¾¤ä¸­çš„æŸä¸ªèŠ‚ç‚¹æ—¶å€™ï¼Œè¯·æ±‚è¢«æ·»åŠ åˆ° bulkè¯·æ±‚é˜Ÿåˆ—ä¸­ï¼Œå¹¶ä¸”è¯¥è¯·æ±‚ä¼šè¢« bulkçº¿ç¨‹æ± ä¸­çš„çº¿ç¨‹å¤„ç†ã€‚æ¥æ”¶è¯·æ±‚çš„èŠ‚ç‚¹è¢«ç§°ä¸ºåè°ƒèŠ‚ç‚¹ï¼Œå› ä¸ºå®ƒä¼šç®¡ç†è¯·æ±‚çš„ç”Ÿå‘½å‘¨æœŸå¹¶ä¸”å“åº”å®¢æˆ·ç«¯è¯·æ±‚ã€‚åè°ƒèŠ‚ç‚¹å¯ä»¥æ˜¯ä¸€ä¸ªä¸“æœ‰èŠ‚ç‚¹ï¼Œä¹Ÿå¯ä»¥æ˜¯é›†ç¾¤ä¸­çš„ä¸€ä¸ªæ•°æ®èŠ‚ç‚¹ï¼Œæ‰¿æ‹…ç€åè°ƒåŠŸèƒ½ã€‚

A bulk request can contain documents destined for multiple indices and shards. The first processing step is therefore to split it up based on which shards the documents need to be routed to. Once this is done, each bulk sub-request is forwarded to the data node that holds the corresponding primary shard, and it is there enqueued on that nodeâ€™s bulk queue. If there is no more space available on the queue, the coordinating node will be notified that the bulk sub-request has been rejected.

The bulk thread pool processes requests from the queue and documents are forwarded to replica shards as part of this processing. Once the sub-request has completed, a response is sent to the coordinating node.

Once all sub-requests have completed or been rejected, a response is created and returned to the client. It is possible, and even likely, that only a portion of the documents within a bulk request might have been rejected.


ä¸€ä¸ª bulk è¯·æ±‚å¯ä»¥åŒ…å«æŒ‡å‘å¤šä¸ªç´¢å¼•å¤šä¸ªåˆ†ç‰‡çš„æ–‡æ¡£ã€‚bulk è¯·æ±‚

ï¼ˆ1ï¼‰ç¬¬ä¸€ä¸ªæ­¥éª¤ä¼šæŠŠè¯·æ±‚æ‹†åˆ†åˆ°ä¸åŒçš„åˆ†ç‰‡ä¸­ï¼Œæ ¹æ®æ–‡æ¡£ä¿¡æ¯ï¼Œè®¡ç®—è·¯ç”±åˆ°çš„åˆ†ç‰‡ï¼›

ï¼ˆ2ï¼‰ç¬¬äºŒä¸ªæ­¥éª¤ä¼šæŠŠè¢«æ‹†åˆ†çš„å­è¯·æ±‚åˆ†å‘åˆ°ä¸»åˆ†ç‰‡èŠ‚ç‚¹ï¼Œå­è¯·æ±‚ä¼šè¢«æ·»åŠ åˆ°å¯¹åº”èŠ‚ç‚¹çš„bulkè¯·æ±‚é˜Ÿåˆ—ï¼›

ï¼ˆ3ï¼‰å¦‚æœå­è¯·æ±‚æ‰€å¯¹åº”çš„èŠ‚ç‚¹ bulkè¯·æ±‚é˜Ÿåˆ—å·²ç»å æ»¡ï¼Œåˆ™åè°ƒèŠ‚ç‚¹ä¼šæ”¶åˆ°æ‹’ç»è¯·æ±‚é€šçŸ¥ï¼›

ï¼ˆ4ï¼‰ä¸»åˆ†ç‰‡èŠ‚ç‚¹å­˜åœ¨å¤§å®¹é‡çš„çº¿ç¨‹æ± ï¼Œç”¨äºå¤„ç† bulkå­è¯·æ±‚ï¼Œå¹¶ä¸”ä¼šå°†æ–‡æ¡£è½¬å‘åˆ°å‰¯æœ¬èŠ‚ç‚¹ï¼Œå‰¯æœ¬èŠ‚ç‚¹æ–‡æ¡£bulkä¹Ÿæ˜¯bulkå­è¯·æ±‚çš„ä¸€éƒ¨åˆ†ï¼Œå½“bulkå­è¯·æ±‚å¤„ç†å®Œæˆï¼Œåè°ƒèŠ‚ç‚¹å°†æ”¶åˆ°å“åº”ï¼›

ï¼ˆ5ï¼‰å½“æ‰€æœ‰çš„å­è¯·æ±‚éƒ½å®Œæˆæˆ–è€…æ‹’ç»ï¼Œå®¢æˆ·ç«¯å°†æ¥æ”¶åˆ°bulkå“åº”ã€‚æœ‰å¯èƒ½çš„åœºæ™¯æ˜¯ï¼Œéƒ¨åˆ†æ–‡æ¡£å†™å…¥è¢«æ‹’ç»ï¼Œéƒ¨åˆ†æ–‡æ¡£å†™å…¥æˆåŠŸã€‚

The reason Elasticsearch is designed with request queues of limited size is to protect the cluster from being overloaded, which increases stability and reliability. If there were no limits in place, clients could very easily bring a whole cluster down through bad or malicious behaviour. The limits that are in place have been set based on our extensive experience supporting Elasticsearch for different types of use-cases.

è®¾è®¡bulkè¯·æ±‚é˜Ÿåˆ—ï¼Œå¹¶ä¸”é™åˆ¶é˜Ÿåˆ—é•¿åº¦ï¼Œæ˜¯ä¸ºäº†é˜²æ­¢è¯·æ±‚è¿‡å¤šï¼Œå¯¼è‡´é›†ç¾¤è¿‡è½½ï¼Œå¯ä»¥æé«˜é›†ç¾¤ç¨³å®šæ€§å’Œå¯é æ€§ã€‚å¦‚æœæ²¡æœ‰é•¿åº¦é™åˆ¶çš„è¯·æ±‚é˜Ÿåˆ—æœºåˆ¶ï¼Œå®¢æˆ·ç«¯å¾ˆå®¹æ˜“ç”±äºä¸åˆé€‚æ“ä½œï¼Œæˆ–è€…æ¶æ„æ“ä½œï¼Œä½¿å¾—é›†ç¾¤å´©æºƒğŸ´ã€‚æ ¹æ®ç°æœ‰å®¢æˆ·çš„å®é™…ä½¿ç”¨åœºæ™¯ç»éªŒï¼Œæˆ‘ä»¬è®¾ç½®äº†ç°æœ‰çš„é˜Ÿåˆ—é•¿åº¦ã€‚

When using the HTTP interface, requests that results in at least a partial rejection will return with response code 429, 'Too many requests'. The principle also applies when the transport protocol is used, although the protocol and interface naturally is different. Applications and clients may report these errors back to the user in different ways, and some may even attempt to handle this automatically by retrying any rejected documents.

å½“é€šè¿‡ httpåè®®å‘é€bulkè¯·æ±‚æ—¶ï¼Œå¦‚æœbulkè¯·æ±‚ä¸­å­˜åœ¨éƒ¨åˆ†è¢«æ‹’ç»çš„å­è¯·æ±‚ï¼Œbulkè¯·æ±‚çš„è¿”å›çŠ¶æ€ç æ˜¯429ï¼Œè¡¨ç¤ºè¯·æ±‚å¤ªå¤šã€‚å½“é€šè¿‡ tcpåè®®å‘é€bulkè¯·æ±‚æ—¶ï¼Œè¿™ä¸ªåŸåˆ™ä¹Ÿæ˜¯ä¸€æ ·ï¼Œä½†æ˜¯åè®®å’Œæ¥å£ä¼šæœ‰ä¸åŒè¡¨ç°ã€‚bulkè¯·æ±‚çš„å®¢æˆ·ç«¯ï¼ˆå¯èƒ½æ˜¯æŸä¸ªåº”ç”¨ï¼‰ä¼šå°†429æŠ¥é”™ä»¥ä¸åŒæ–¹å¼æŠ¥å‘Šç»™ç”¨æˆ·ã€‚å®¢æˆ·ç«¯ç¨‹åºå¯èƒ½ä¼šåœ¨æ¥æ”¶åˆ°429æŠ¥é”™åï¼Œè‡ªåŠ¨é‡è¯•ï¼Œç»§ç»­ä¸Šä¼ å†™å…¥å¤±è´¥æ–‡æ¡£ã€‚

## How can we test this in practice?

å¦‚æœå®é™…æµ‹è¯•bulkè¯·æ±‚ï¼Ÿ

In order to illustrate the practical impact of this behaviour, we devised a simple test where we use our benchmarking tool Rally to run bulk indexing requests against a couple of Elastic Cloud clusters with varying number of data nodes. Configuration and instructions on how to run Rally is available in this gist.

The same indexing workload was run against three different Elastic Cloud clusters. We have been indexing with one replica shard configured wherever possible. The clusters consisted of one, two and three data nodes respectively, with each data node having 8GB RAM (4GB heap for Elasticsearch, 4GB native memory). Invoking the GET /_nodes/thread_pool API we could see that each data node by default had a fixed bulk thread pool size of two with a queue size of 200:

```json

%> curl -XGET http://<es_url>:<es_port>/_nodes/thread_pool</es_port></es_url>
"bulk": {
"type": "fixed",
"min": 2,
"max": 2,
"queue_size": 200
}

```

ä¸‹é¢æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç®€å•çš„æµ‹è¯•ï¼Œæµ‹è¯•bulkæ€§èƒ½ï¼Œæµ‹è¯•å·¥å…·æ˜¯ [rally](https://github.com/elastic/rally)ï¼Œæµ‹è¯•å¤šä¸ªå…·æœ‰ä¸åŒèŠ‚ç‚¹çš„é›†ç¾¤ã€‚

åœ¨ä¸‰ä¸ªä¸åŒé…ç½®çš„ESå®ä¾‹ï¼Œæˆ‘ä»¬ä¼šæ‰§è¡Œç›¸åŒçš„bulkè¯·æ±‚æµ‹è¯•ã€‚ä¸‰ä¸ªESå®ä¾‹ï¼Œåˆ†åˆ«æ˜¯1ä¸ªèŠ‚ç‚¹ã€2ä¸ªèŠ‚ç‚¹ã€3ä¸ªèŠ‚ç‚¹ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹é…ç½®éƒ½æ˜¯ç›¸åŒçš„ï¼ˆ 8GB å†…å­˜ï¼Œ4Gè®¾ç½®ä¸ºES å †å†…å­˜ï¼Œ4Gè®¾ç½®ä¸ºèŠ‚ç‚¹å†…å­˜ï¼‰ã€‚å¯ä»¥é€šè¿‡æ¥å£`GET /_nodes/thread_pool` æ¥å£æŸ¥çœ‹

```json

GET _nodes/thread_pool

{
  "_nodes": {
    "total": 3,
    "successful": 3,
    "failed": 0
  },
  "cluster_name": "a2ff16d9aa2645dc87ab1714e6e16a84",
  "nodes": {
    "juVnJa6TQ7a2c3v065Gz3w": {
      "name": "instance-0000000000",
      "transport_address": "10.42.10.154:19303",
      "host": "10.42.10.154",
      "ip": "10.42.10.154",
      "version": "8.3.1",
      "build_flavor": "default",
      "build_type": "docker",
      "build_hash": "b9a6b2867996ba92ceac66cb5bafc6db25e7910e",
      "roles": [
        "data_content",
        "data_hot",
        "ingest",
        "master",
        "remote_cluster_client",
        "transform"
      ],
      "attributes": {
        "logical_availability_zone": "zone-0",
        "server_name": "instance-0000000000.a2ff16d9aa2645dc87ab1714e6e16a84",
        "availability_zone": "us-central1-a",
        "xpack.installed": "true",
        "data": "hot",
        "instance_configuration": "gcp.es.datahot.n2.68x10x45",
        "region": "unknown-region"
      },
      "thread_pool": {
        "force_merge": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "search_coordination": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "searchable_snapshots_cache_fetch_async": {
          "type": "scaling",
          "core": 0,
          "max": 6,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "ml_datafeed": {
          "type": "scaling",
          "core": 1,
          "max": 512,
          "keep_alive": "1m",
          "queue_size": -1
        },
        "snapshot_meta": {
          "type": "scaling",
          "core": 1,
          "max": 6,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "fetch_shard_started": {
          "type": "scaling",
          "core": 1,
          "max": 4,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "rollup_indexing": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "search": {
          "type": "fixed",
          "size": 4,
          "queue_size": 1000
        },
        "cluster_coordination": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "security-crypto": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "ccr": {
          "type": "fixed",
          "size": 32,
          "queue_size": 100
        },
        "flush": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "fetch_shard_store": {
          "type": "scaling",
          "core": 1,
          "max": 4,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "ml_utility": {
          "type": "scaling",
          "core": 1,
          "max": 2048,
          "keep_alive": "10m",
          "queue_size": -1
        },
        "get": {
          "type": "fixed",
          "size": 2,
          "queue_size": 1000
        },
        "system_read": {
          "type": "fixed",
          "size": 1,
          "queue_size": 2000
        },
        "system_critical_read": {
          "type": "fixed",
          "size": 1,
          "queue_size": 2000
        },
        "write": {
          "type": "fixed",
          "size": 2,
          "queue_size": 10000
        },
        "watcher": {
          "type": "fixed",
          "size": 10,
          "queue_size": 1000
        },
        "security-token-key": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "system_critical_write": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1500
        },
        "refresh": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "repository_azure": {
          "type": "scaling",
          "core": 0,
          "max": 5,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "vector_tile_generation": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "system_write": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "generic": {
          "type": "scaling",
          "core": 4,
          "max": 128,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "warmer": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "auto_complete": {
          "type": "fixed",
          "size": 1,
          "queue_size": 100
        },
        "azure_event_loop": {
          "type": "scaling",
          "core": 0,
          "max": 1,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "management": {
          "type": "scaling",
          "core": 1,
          "max": 2,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "analyze": {
          "type": "fixed",
          "size": 1,
          "queue_size": 16
        },
        "searchable_snapshots_cache_prewarming": {
          "type": "scaling",
          "core": 0,
          "max": 16,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "ml_job_comms": {
          "type": "scaling",
          "core": 4,
          "max": 2048,
          "keep_alive": "1m",
          "queue_size": -1
        },
        "snapshot": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "search_throttled": {
          "type": "fixed",
          "size": 1,
          "queue_size": 100
        }
      }
    },
    "snEBN-aVTcKiJfoT87LgKA": {
      "name": "instance-0000000001",
      "transport_address": "10.42.0.133:19375",
      "host": "10.42.0.133",
      "ip": "10.42.0.133",
      "version": "8.3.1",
      "build_flavor": "default",
      "build_type": "docker",
      "build_hash": "b9a6b2867996ba92ceac66cb5bafc6db25e7910e",
      "roles": [
        "data_content",
        "data_hot",
        "ingest",
        "master",
        "remote_cluster_client",
        "transform"
      ],
      "attributes": {
        "data": "hot",
        "server_name": "instance-0000000001.a2ff16d9aa2645dc87ab1714e6e16a84",
        "instance_configuration": "gcp.es.datahot.n2.68x10x45",
        "region": "unknown-region",
        "availability_zone": "us-central1-b",
        "logical_availability_zone": "zone-1",
        "xpack.installed": "true"
      },
      "thread_pool": {
        "force_merge": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "search_coordination": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "searchable_snapshots_cache_fetch_async": {
          "type": "scaling",
          "core": 0,
          "max": 6,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "ml_datafeed": {
          "type": "scaling",
          "core": 1,
          "max": 512,
          "keep_alive": "1m",
          "queue_size": -1
        },
        "snapshot_meta": {
          "type": "scaling",
          "core": 1,
          "max": 6,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "fetch_shard_started": {
          "type": "scaling",
          "core": 1,
          "max": 4,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "rollup_indexing": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "search": {
          "type": "fixed",
          "size": 4,
          "queue_size": 1000
        },
        "cluster_coordination": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "security-crypto": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "ccr": {
          "type": "fixed",
          "size": 32,
          "queue_size": 100
        },
        "flush": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "fetch_shard_store": {
          "type": "scaling",
          "core": 1,
          "max": 4,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "ml_utility": {
          "type": "scaling",
          "core": 1,
          "max": 2048,
          "keep_alive": "10m",
          "queue_size": -1
        },
        "get": {
          "type": "fixed",
          "size": 2,
          "queue_size": 1000
        },
        "system_read": {
          "type": "fixed",
          "size": 1,
          "queue_size": 2000
        },
        "system_critical_read": {
          "type": "fixed",
          "size": 1,
          "queue_size": 2000
        },
        "write": {
          "type": "fixed",
          "size": 2,
          "queue_size": 10000
        },
        "watcher": {
          "type": "fixed",
          "size": 10,
          "queue_size": 1000
        },
        "security-token-key": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "system_critical_write": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1500
        },
        "refresh": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "repository_azure": {
          "type": "scaling",
          "core": 0,
          "max": 5,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "vector_tile_generation": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "system_write": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "generic": {
          "type": "scaling",
          "core": 4,
          "max": 128,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "warmer": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "auto_complete": {
          "type": "fixed",
          "size": 1,
          "queue_size": 100
        },
        "azure_event_loop": {
          "type": "scaling",
          "core": 0,
          "max": 1,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "management": {
          "type": "scaling",
          "core": 1,
          "max": 2,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "analyze": {
          "type": "fixed",
          "size": 1,
          "queue_size": 16
        },
        "searchable_snapshots_cache_prewarming": {
          "type": "scaling",
          "core": 0,
          "max": 16,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "ml_job_comms": {
          "type": "scaling",
          "core": 4,
          "max": 2048,
          "keep_alive": "1m",
          "queue_size": -1
        },
        "snapshot": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "search_throttled": {
          "type": "fixed",
          "size": 1,
          "queue_size": 100
        }
      }
    },
    "4MZABTmcQSG3PvMWtK_Sjg": {
      "name": "tiebreaker-0000000002",
      "transport_address": "10.42.5.215:19463",
      "host": "10.42.5.215",
      "ip": "10.42.5.215",
      "version": "8.3.1",
      "build_flavor": "default",
      "build_type": "docker",
      "build_hash": "b9a6b2867996ba92ceac66cb5bafc6db25e7910e",
      "roles": [
        "master",
        "voting_only"
      ],
      "attributes": {
        "logical_availability_zone": "tiebreaker",
        "availability_zone": "us-central1-c",
        "server_name": "tiebreaker-0000000002.a2ff16d9aa2645dc87ab1714e6e16a84",
        "xpack.installed": "true",
        "data": "hot",
        "instance_configuration": "gcp.es.master.n2.68x32x45",
        "region": "unknown-region"
      },
      "thread_pool": {
        "force_merge": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "search_coordination": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "searchable_snapshots_cache_fetch_async": {
          "type": "scaling",
          "core": 0,
          "max": 6,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "ml_datafeed": {
          "type": "scaling",
          "core": 1,
          "max": 512,
          "keep_alive": "1m",
          "queue_size": -1
        },
        "snapshot_meta": {
          "type": "scaling",
          "core": 1,
          "max": 6,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "fetch_shard_started": {
          "type": "scaling",
          "core": 1,
          "max": 4,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "rollup_indexing": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "search": {
          "type": "fixed",
          "size": 4,
          "queue_size": 1000
        },
        "cluster_coordination": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "security-crypto": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "ccr": {
          "type": "fixed",
          "size": 32,
          "queue_size": 100
        },
        "flush": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "fetch_shard_store": {
          "type": "scaling",
          "core": 1,
          "max": 4,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "ml_utility": {
          "type": "scaling",
          "core": 1,
          "max": 2048,
          "keep_alive": "10m",
          "queue_size": -1
        },
        "get": {
          "type": "fixed",
          "size": 2,
          "queue_size": 1000
        },
        "system_read": {
          "type": "fixed",
          "size": 1,
          "queue_size": 2000
        },
        "system_critical_read": {
          "type": "fixed",
          "size": 1,
          "queue_size": 2000
        },
        "write": {
          "type": "fixed",
          "size": 2,
          "queue_size": 10000
        },
        "watcher": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "security-token-key": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "system_critical_write": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1500
        },
        "refresh": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "repository_azure": {
          "type": "scaling",
          "core": 0,
          "max": 5,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "vector_tile_generation": {
          "type": "fixed",
          "size": 1,
          "queue_size": -1
        },
        "system_write": {
          "type": "fixed",
          "size": 1,
          "queue_size": 1000
        },
        "generic": {
          "type": "scaling",
          "core": 4,
          "max": 128,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "warmer": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "auto_complete": {
          "type": "fixed",
          "size": 1,
          "queue_size": 100
        },
        "azure_event_loop": {
          "type": "scaling",
          "core": 0,
          "max": 1,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "management": {
          "type": "scaling",
          "core": 1,
          "max": 2,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "analyze": {
          "type": "fixed",
          "size": 1,
          "queue_size": 16
        },
        "searchable_snapshots_cache_prewarming": {
          "type": "scaling",
          "core": 0,
          "max": 16,
          "keep_alive": "30s",
          "queue_size": -1
        },
        "ml_job_comms": {
          "type": "scaling",
          "core": 4,
          "max": 2048,
          "keep_alive": "1m",
          "queue_size": -1
        },
        "snapshot": {
          "type": "scaling",
          "core": 1,
          "max": 1,
          "keep_alive": "5m",
          "queue_size": -1
        },
        "search_throttled": {
          "type": "fixed",
          "size": 1,
          "queue_size": 100
        }
      }
    }
  }
}

```

During the test we indexed into a varying number of shards (2, 4, 8, 16, and 32) using a varying number of concurrent clients (8, 16, 24, 32, 48, and 64) for each cluster. For every combination of shard and client count we indexed 6.4 million documents with a batch size of 100 documents and another 6.4 million documents with a batch size of 200 documents. This means that in total we attempted to index 384 million documents per cluster.

For this test we treat the clusters as a black box, and perform the analysis from the clientâ€™s perspective. To limit the scope we will also not look at the impact of various configurations on performance as that is a quite large topic on its own.

åœ¨æµ‹è¯•ä¸­ï¼Œ

ï¼ˆ1ï¼‰æˆ‘ä»¬å¹¶å‘å†™å…¥è®¾ç½®ä¸åŒçš„å¹¶å‘å®¢æˆ·ç«¯ï¼Œåˆ†åˆ«ä¸º 8/16/24/32/48/64 ä¸ªå®¢æˆ·ç«¯ï¼Œ

ï¼ˆ2ï¼‰ç´¢å¼•åˆ†åˆ«è®¾ç½®ä¸åŒçš„åˆ†ç‰‡æ•°ï¼Œåˆ†åˆ«ä¸º 2/4/8/16/32 ä¸ªåˆ†ç‰‡æ•°ã€‚

ï¼ˆ3ï¼‰æ‰¹é‡å†™å…¥è®¾ç½®ä¸åŒçš„æ–‡æ¡£æ•°ï¼Œåˆ†åˆ«ä¸º 100/200ä¸ªæ–‡æ¡£ï¼Œ

å¯¹äºä¸åŒçš„è®¾ç½®ï¼Œå†™å…¥æ–‡æ¡£æ€»æ•°é‡éƒ½æ˜¯ç›¸åŒçš„ï¼Œæ¯ä¸ªé›†ç¾¤æœ€ç»ˆå°†å†™å…¥æ¥è¿‘4äº¿æ–‡æ¡£ã€‚

åœ¨æ­¤æ¬¡æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å°†é›†ç¾¤è§†ä¸ºä¸€ä¸ªé»‘ç›’å­ï¼Œå¹¶ä»å®¢æˆ·çš„è§’åº¦è¿›è¡Œåˆ†æã€‚ä¸ºäº†é™åˆ¶èŒƒå›´ï¼Œæˆ‘ä»¬ä¹Ÿä¸ä¼šè€ƒè™‘å„ç§é…ç½®å¯¹äºæ€§èƒ½çš„å½±å“ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸å¤§çš„ä¸»é¢˜ã€‚

All the generated, detailed metrics were sent to a separate Elastic Cloud instance for analysis using Kibana. For each request Rally measures how many the documents in the bulk request were rejected and successful. Based on this data we can classify each request as successful, partially rejected, and fully rejected. A few requests also timed out, and these have also been included for completeness.

Unlike Beats and Logstash, Rally does not retry failed indexing requests, so each has the same number of requests executed but the final number of documents indexed varied from run to run depending on the volume of rejections.

æ‰€æœ‰æµ‹è¯•æŒ‡æ ‡ï¼Œéƒ½ä¼šå‘é€åˆ°ä¸€ä¸ªç‹¬ç«‹çš„é›†ç¾¤ï¼Œå¹¶ä¸”ä½¿ç”¨kibanaå¯è§†åŒ–ã€‚å¯¹äºæ¯ä¸ªå®¢æˆ·ç«¯ bulkè¯·æ±‚ï¼Œ`rally`å¯ä»¥è®°å½•è¯·æ±‚æ˜¯å¦æˆåŠŸï¼Œå¦‚æœå¤±è´¥ï¼Œæ‹’ç»å†™å…¥çš„æ–‡æ¡£æ•°ã€‚æ ¹æ®`rally`è®°å½•æ•°æ®ï¼Œå¯ä»¥åŒºåˆ†bulkè¯·æ±‚æˆåŠŸ/å®Œå…¨æ‹’ç»/éƒ¨åˆ†æ‹’ç»ã€‚å¦å¤–ï¼Œè¿˜æœ‰ä¸€äº›è¯·æ±‚è¶…æ—¶ï¼Œä¸ºäº†å®Œæ•´æ€§èµ·è§ï¼Œç»Ÿè®¡æ•°æ®ä¹Ÿä¼šåŒ…å«è¶…æ—¶çš„è¯·æ±‚ã€‚

ä¸ beats å’Œ logstashä¸åŒï¼Œ`rally`å†™å…¥å¤±è´¥ä¸ä¼šé‡è¯•ã€‚å› æ­¤ï¼Œæœ€ç»ˆè½åˆ°ESä¸­æ–‡æ¡£æ•°ä¹Ÿä¼šä¸åŒï¼Œå› ä¸ºæœ‰éƒ¨åˆ†è¯·æ±‚è¢«æ‹’ç»äº†ã€‚

## How bulk rejection frequency depend on shard count, clients count, and data node count?

bulkå†™å…¥æ‹’ç»é¢‘ç‡å’Œåˆ†ç‰‡æ•°é‡ã€å®¢æˆ·ç«¯å¹¶å‘é‡ã€æ•°æ®èŠ‚ç‚¹æ•°ä¹‹é—´æœ‰ä»€ä¹ˆå…³è”ï¼Ÿ

Bulk rejections occur when the bulk queues fill up. The number of queue slots that get used depends both on the number of concurrent requests, and the number of shards being indexed into. To measure this correlation we have added a calculated metric, client shard concurrency, to each run. This is defined as the number of shards being indexed into, multiplied by the number of concurrent indexing threads, and indicates how many queue slots would be needed to hold all bulk sub-requests.

å½“bulké˜Ÿåˆ—å æ»¡åï¼Œåå…¥çš„bulkè¯·æ±‚å°†è¢«æ‹’ç»ã€‚å†™å…¥è¯·æ±‚ä¼šä½¿ç”¨çš„è¯·æ±‚é˜Ÿåˆ—å¤§å°ï¼Œå–å†³äºå®¢æˆ·ç«¯çš„å¹¶å‘é‡å’Œç´¢å¼•çš„åˆ†ç‰‡æ•°è®¾ç½®ã€‚ä¸ºäº†å‡†ç¡®æè¿°ç›¸å…³æ€§ï¼Œå¼•å…¥ä¸€ä¸ªæ–°çš„æŒ‡æ ‡ï¼Œç§°ä¸ºå®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡ = å®¢æˆ·ç«¯å¹¶å‘é‡ * ç´¢å¼•åˆ†ç‰‡æ•°ã€‚


![å®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡](https://github.com/Kua-Fu/blog-book-images/blob/main/elastic/101/bulk-rejection-blog-1.png?raw=true)

In the graph below, we show how the percentage of requests that result in partial or full rejections, depends on the client shard concurrency for the three different clusters.

For clusters with one or two nodes we can see that appearance of bulk rejections start when the client shard concurrency level is somewhere between 192 and 256. This makes sense as each node has a bulk queue size of 200. For the cluster with 3 nodes we can see that it is able to handle even higher level of client shard concurrency without any bulk rejections appearing. 

Once we get over this limit, we start seeing partial bulk rejections, where at least one sub-request has managed to get queued and processed. A relatively small portion of requests also result on full rejections as the concurrency level increases, especially for the single node cluster. 

When we compare the single and two node clusters, we can see that the percentage of fully successful requests increases slightly and that there are fewer full rejections. This is expected, as the total bulk queue across the cluster is twice as large and requests are sent to all data nodes. Even though the total bulk queue size is twice as large across the cluster, the 2 node cluster does not appear able to handle twice the client shard concurrency of the single node cluster. This is likely due to the fact that distribution is not perfect and that the introduction of replica shards have resulted in each indexing operation requiring more work and being slower as a result. An important thing to note is also that all partial rejections are treated as equals in this graph. The number of rejected documents is not shown and does indeed vary depending on the cluster size, but we will shortly look at that in greater detail. 


ç”±ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸‰ä¸ªé›†ç¾¤é‡Œé¢ï¼Œä¸åŒç±»å‹å“åº”å æ¯”ï¼ˆå†™å…¥æˆåŠŸ/éƒ¨åˆ†å†™å…¥æˆåŠŸ/å†™å…¥å…¨éƒ¨å¤±è´¥/å†™å…¥è¶…æ—¶ï¼‰ã€‚å¯¹äºå…·æœ‰ä¸€ä¸ªèŠ‚ç‚¹å’Œä¸¤ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œå½“å®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡è¾¾åˆ° 192ï½256ï¼Œå¼€å§‹å‡ºç°æ‹’ç»è¯·æ±‚ã€‚è¿™ä¸ªæ˜¯æœ‰æ„ä¹‰çš„ï¼Œå› ä¸ºæ ¹æ®`_nodes/thread_pool/`ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„bulké˜Ÿåˆ—å¤§å°ä¸º200ã€‚å¯¹äº3ä¸ªèŠ‚ç‚¹çš„é›†ç¾¤ï¼Œå› ä¸ºå®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡æ›´å¤§ï¼Œå¯ä»¥çœ‹åˆ° 192~256 èŒƒå›´å†…ä¸ä¼šå‡ºç°æ‹’ç»è¯·æ±‚ã€‚

è¿˜å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äº3èŠ‚ç‚¹é›†ç¾¤ï¼Œå½“è¾¾åˆ°256é™åˆ¶ä»¥ä¸Šï¼Œå¼€å§‹å‡ºç°éƒ¨åˆ†æ‹’ç»ã€‚å½“å®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡ç»§ç»­å¢åŠ åï¼Œå®Œå…¨æ‹’ç»ç±»å‹è¯·æ±‚å¼€å§‹å˜å¤šã€‚

å¦‚æœæˆ‘ä»¬åªæ˜¯æ¯”è¾ƒå•èŠ‚ç‚¹å’ŒåŒèŠ‚ç‚¹çš„é›†ç¾¤ï¼Œå¯ä»¥çœ‹åˆ°åŒèŠ‚ç‚¹é›†ç¾¤ï¼Œå®ŒæˆæˆåŠŸçš„ç™¾åˆ†æ¯”æ›´é«˜ï¼Œå®Œå…¨å¤±è´¥çš„ç™¾åˆ†æ¯”æ›´ä½ã€‚è¿™ä¸ªç»“æœåœ¨æ„æ–™ä¹‹ä¸­ï¼Œå› ä¸ºåŒèŠ‚ç‚¹é›†ç¾¤ï¼Œå¯ä»¥æ¥å—bulkè¯·æ±‚çš„bulké˜Ÿåˆ—æ˜¯å•èŠ‚ç‚¹é›†ç¾¤çš„ä¸¤å€ï¼Œå¹¶ä¸”åŒèŠ‚ç‚¹é›†ç¾¤ï¼Œæœ‰ä¸¤ä¸ªæ•°æ®èŠ‚ç‚¹ï¼Œéƒ½ä¼šæ¥æ”¶bulkè¯·æ±‚ã€‚ä½†æ˜¯ï¼Œä»å›¾ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ï¼ŒåŒèŠ‚ç‚¹é›†ç¾¤çš„å¤„ç†èƒ½åŠ›å¹¶ä¸æ˜¯å•èŠ‚ç‚¹é›†ç¾¤çš„ä¸¤å€ã€‚å¯èƒ½çš„åŸå› å¦‚ä¸‹ï¼š

ï¼ˆ1ï¼‰åˆ†ç‰‡åˆ†å‘ä¸ä¸€å®šæ˜¯å®Œç¾çš„ï¼Œå³ä¸ä¸€å®šï¼Œæ¯ä¸ªèŠ‚ç‚¹éƒ½æ¥æ”¶æ­£å¥½ä¸€åŠçš„bulkè¯·æ±‚ï¼›

ï¼ˆ2ï¼‰å‰¯æœ¬åˆ†ç‰‡çš„è®¾ç½®ï¼Œå¯¼è‡´åŒèŠ‚ç‚¹é›†ç¾¤ï¼Œbulkè¯·æ±‚å¤„ç†æ›´è€—æ—¶ï¼›

ï¼ˆ3ï¼‰éœ€è¦æ³¨æ„åˆ°ï¼Œä¸Šå›¾ä¸­ï¼Œéƒ¨åˆ†è¢«æ‹’ç»çš„è¯·æ±‚ï¼Œå¹¶æ²¡æœ‰è¯¦ç»†çš„è¢«æ‹’ç»æ–‡æ¡£æ•°é‡ï¼Œæˆ‘ä»¬æŠŠæ‰€æœ‰éƒ¨åˆ†è¢«æ‹’ç»è¯·æ±‚å½“ä½œç›¸åŒçš„ç±»å‹ï¼Œå®é™…ä¸Šéƒ¨åˆ†è¢«æ‹’ç»è¯·æ±‚ï¼Œå¯èƒ½åŒ…å«éå¸¸ä¸ä¸€æ ·çš„æ‹’ç»æ–‡æ¡£æ•°é‡ã€‚

å½“ç»§ç»­æŸ¥çœ‹3èŠ‚ç‚¹é›†ç¾¤ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œåªæœ‰å½“å®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡åˆ°è¾¾éå¸¸é«˜æ—¶å€™ï¼Œæ‰ä¼šå‡ºç°å®Œå…¨æ‹’ç»è¯·æ±‚ã€‚

![è¯¦ç»†bulkä¿¡æ¯](https://github.com/Kua-Fu/blog-book-images/blob/main/elastic/101/bulk-rejection-blog-2.png?raw=true)

ä¸Šå›¾å±•ç¤ºäº†éƒ¨åˆ†bulkå¤±è´¥çš„è¯¦ç»†ä¿¡æ¯ï¼Œä¸»è¦åŒ…å«äº†bulkå¤±è´¥çš„æ–‡æ¡£æ•°é‡ã€‚

å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äº3ç§ç±»å‹é›†ç¾¤ï¼Œéšç€å®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡çš„å¢åŠ ï¼Œè¢«æ‹’ç»çš„æ¯”ä¾‹å˜å¤§ï¼›ä½†æ˜¯éšç€èŠ‚ç‚¹çš„å˜å¤šï¼Œæ‹’ç»çš„çº§åˆ«ï¼ˆå¯ä»¥ä»»åŠ¡æ˜¯æ‹’ç»çš„æ–‡æ¡£æ•°é‡ï¼‰å˜å°ã€‚

å¯¹äºå•èŠ‚ç‚¹é›†ç¾¤ã€åŒèŠ‚ç‚¹é›†ç¾¤ï¼Œéƒ¨åˆ†æ‹’ç»å‡ ä¹åœ¨ç›¸åŒçš„å®¢æˆ·ç«¯åˆ†ç‰‡å¹¶å‘é‡äº§ç”Ÿï¼Œä½†ä¸ç›¸åŒçš„æ˜¯ï¼Œå•èŠ‚ç‚¹é›†ç¾¤è¢«æ‹’ç»æ–‡æ¡£æ•°é‡å¢åŠ çš„æ›´å¿«ã€‚è¿™æ„å‘³ç€ï¼Œå³ä½¿ä¸åŒç±»å‹é›†ç¾¤éƒ½å‘ç”Ÿäº†éƒ¨åˆ†æ‹’ç»è¯·æ±‚ï¼Œæ›´å¤šèŠ‚ç‚¹é›†ç¾¤ï¼Œå®é™…ä¸Šä¼šå†™å…¥æ›´å¤šçš„æ–‡æ¡£ã€‚

## Canâ€™t I just get around this by increasing the bulk queue size?

å¯ä»¥é€šè¿‡å¢åŠ bulkè¯·æ±‚é˜Ÿåˆ—é•¿åº¦ï¼Œè§£å†³bulkè¯·æ±‚429é—®é¢˜å—ï¼Ÿ

One of the most common reactions when faced with bulk rejections is to increase the size of the bulk queue. Why not set it to a really large value so you do not have to worry about this again?

Increasing the size of the queue is not likely to improve the indexing performance or throughput of your cluster. Instead it would just make the cluster queue up more data in memory, which is likely to result in bulk requests taking longer to complete. The more bulk requests there are in the queue, the more precious heap space will be consumed. If the pressure on the heap gets too large, it can cause a lot of other performance problems and even cluster instability.

Adjusting the queue sizes is therefore strongly discouraged, as it is like putting a temporary band-aid on the problem rather than actually fixing the underlying issue. So what else can we do improve the situation?

å½“é¢ä¸´bulkè¯·æ±‚è¢«æ‹’ç»åœºæ™¯ï¼Œæœ€å¸¸è§çš„ååº”æ˜¯ä¸ºä»€ä¹ˆä¸å¢åŠ è¯·æ±‚é˜Ÿåˆ—é•¿åº¦ï¼Œè®¾ç½®ä¸€ä¸ªéå¸¸å¤§çš„å€¼ï¼Œè¿™æ ·å°±ä¸ç”¨æ‹…å¿ƒbulkè¯·æ±‚è¢«æ‹’ç»äº†ï¼Ÿ

éœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œå¢åŠ è¯·æ±‚é˜Ÿåˆ—é•¿åº¦ä¸ç­‰äºå¢åŠ ç´¢å¼•çš„æ€§èƒ½å’Œååé‡ã€‚ç›¸åï¼Œå¢åŠ é˜Ÿåˆ—é•¿åº¦ä¼šä½¿å¾—é›†ç¾¤å†…å­˜ä¸­å­˜åœ¨æ›´å¤šæ’é˜Ÿä¸­çš„è¯·æ±‚ï¼Œè¿™æ ·å¯èƒ½å¯¼è‡´bulkè¯·æ±‚ä¼šç»è¿‡æ›´é•¿æ—¶é—´æ‰èƒ½å®Œæˆã€‚è¶Šå¤šçš„bulkè¯·æ±‚ï¼Œè¶Šå¤šå®è´µçš„é›†ç¾¤å †å†…å­˜å°±ä¼šè¢«æ¶ˆè€—ã€‚å¦‚æœå †å†…å­˜å ç”¨è¿‡å¤§ï¼Œå¯èƒ½ä¼šå¯¼è‡´å…¶ä»–çš„æ€§èƒ½é—®é¢˜ï¼Œç”šè‡³è®©é›†ç¾¤å˜å¾—ä¸ç¨³å®šã€‚

å› æ­¤ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®ä¸è¦è°ƒæ•´é˜Ÿåˆ—å¤§å°ï¼Œå› ä¸ºé€šå¸¸æ”¹å˜é˜Ÿåˆ—é•¿åº¦åªä¼šä¸´æ—¶æ”¹å˜è¢«æ‹’ç»è¯·æ±‚æ•°é‡ï¼Œä½†æ˜¯ä¸ä¼šæ ¹æœ¬ä¸Šæ”¹å˜bulkè¯·æ±‚è¢«æ‹’ç»é—®é¢˜ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•åšï¼Œæ ¹æœ¬ä¸Šè§£å†³é—®é¢˜å‘¢ï¼Ÿ

## Can coordinating only nodes help?

ä¸“æœ‰åè°ƒèŠ‚ç‚¹ä¼šæœ‰å¸®åŠ©å—ï¼Ÿ

By introducing coordinating only nodes, the data nodes will be able to focus on processing sub-requests, as the request itself will not take up a slot on their bulk queue. This is generally good, but the actual benefit of this arrangement is likely to vary from use-case to use-case. In many use cases it does relatively little difference, and we see lots of successful indexing heavy use cases that do not use dedicated coordinating nodes.

é€šè¿‡å¼•å…¥ä¸“æœ‰åè°ƒèŠ‚ç‚¹ï¼Œæ•°æ®èŠ‚ç‚¹å¯ä»¥æ›´åŠ ä¸“æ³¨äºå¤„ç†bulkå­è¯·æ±‚ï¼Œbulkè¯·æ±‚ä¸ä¼šå ç”¨è¯·æ±‚é˜Ÿåˆ—ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œå¼•å…¥ä¸“æœ‰åè°ƒèŠ‚ç‚¹å¯ä»¥æ”¹å–„bulkè¯·æ±‚è¢«æ‹’ç»é—®é¢˜ï¼Œä½†å®é™…ä¸Šæ˜¯å¦æ”¹å–„ï¼Œè¿˜æ˜¯å› ä¸ºä¸åŒå®é™…ä½¿ç”¨åœºæ™¯ä¼šæœ‰ä¸åŒçš„ç­”æ¡ˆã€‚åœ¨å¾ˆå¤šçš„æ¡ˆä¾‹ä¸­ï¼Œå¼•å…¥ä¸“æœ‰åè°ƒèŠ‚ç‚¹ï¼Œæ”¹å–„å‡ ä¹æ²¡æœ‰å‘ç”Ÿï¼Œæˆ‘ä»¬é‡åˆ°è¿‡å¾ˆå¤šçš„ç´¢å¼•æ•°æ®é‡å¾ˆå¤§çš„é›†ç¾¤ï¼Œæ ¹æœ¬æ²¡æœ‰ä½¿ç”¨ä¸“æœ‰åè°ƒèŠ‚ç‚¹ã€‚

## What conclusions can we draw?

æˆ‘ä»¬å¯ä»¥å¾—å‡ºä»€ä¹ˆç»“è®ºï¼Ÿ

As always, there is not necessarily any good one-size-fits-all solution, and the way to address bulk rejections will vary from use-case to use-case. If you see bulk rejections, try to understand why they are taking place and whether it is a single node or the whole cluster that is affected.

ä¸€å¦‚æ—¢å¾€çš„ï¼Œæˆ‘ä»¬æ— æ³•å¾—åˆ°ä¸€ä¸ªä¸‡èƒ½æ–¹æ³•ï¼Œå¯ä»¥è§£å†³æ‰€æœ‰ä¸åŒåœºæ™¯çš„bulkè¯·æ±‚è¢«æ‹’ç»é—®é¢˜ã€‚ä¸åŒçš„ç”¨æˆ·ä½¿ç”¨åœºæ™¯ï¼Œå¾€å¾€æœ€ç»ˆä½¿ç”¨ä¸åŒçš„è§£å†³æ–¹æ¡ˆã€‚å¦‚æœä½ å‘ç°äº†bulkè¯·æ±‚å¤±è´¥ï¼Œè¯·ï¼ˆ1ï¼‰å°è¯•æ’æŸ¥å‘ç”Ÿæ‹’ç»çš„åŸå› ï¼›ï¼ˆ2ï¼‰æ˜¯å•ä¸ªèŠ‚ç‚¹ã€è¿˜æ˜¯æ•´ä¸ªé›†ç¾¤éƒ½å‘ç”Ÿäº†bulkè¯·æ±‚è¢«æ‹’ç»ã€‚

å¦‚æœæ˜¯æ•´ä¸ªé›†ç¾¤å¤„äºè¿‡è½½çŠ¶æ€ï¼Œè€Œä¸æ˜¯å•ä¸ªèŠ‚ç‚¹æ‰¿æ‹…äº†è¿‡å¤šçš„å†™å…¥å‹åŠ›ï¼Œå¯èƒ½è¦è€ƒè™‘é›†ç¾¤æ‰©å®¹ï¼ˆæ¨ªå‘æ·»åŠ èŠ‚ç‚¹æˆ–è€…çºµå‘å‡çº§é…ç½®ï¼‰ã€‚æ‰©å®¹åï¼Œæ•´ä¸ªé›†ç¾¤bulkè¯·æ±‚é˜Ÿåˆ—çš„æ€»é•¿åº¦å°†å˜å¤§ï¼Œå¯ä»¥æ‰¿æ‹…æ›´å¤šçš„å†™å…¥å‹åŠ›ã€‚å¦‚æœåªæ˜¯ç®€å•æ·»åŠ ç°æœ‰é›†ç¾¤èŠ‚ç‚¹bulkè¯·æ±‚é˜Ÿåˆ—çš„é•¿åº¦ï¼Œå³ä½¿ä¸´æ—¶è§£å†³äº†é—®é¢˜ï¼Œå®é™…ä¸Šåé¢å¯èƒ½ä¼šé¢ä¸´æ›´å¤šçš„å…¶ä»–æ€§èƒ½é—®é¢˜ã€‚

æœ€åï¼Œè¿˜éœ€è¦è®°ä½çš„æ˜¯ï¼Œbulkè¢«æ‹’ç»å¹¶ä¸ä»£è¡¨æ‰€æœ‰çš„æ–‡æ¡£éƒ½å†™å…¥å¤±è´¥ï¼Œç¨‹åºä»£ç ä¸­éœ€è¦è€ƒè™‘åˆ°åªæœ‰ä¸€éƒ¨åˆ†æ–‡æ¡£å†™å…¥å¤±è´¥ï¼Œè¦è€ƒè™‘è¿™ä¸€éƒ¨åˆ†æ–‡æ¡£çš„é‡ä¼ æœºåˆ¶ã€‚å¯ä»¥å‚è€ƒlogstash,beats ä¸­çš„é‡ä¼ é€»è¾‘ã€‚





